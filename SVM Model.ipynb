{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > model_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mm_train_df = pd.read_csv('data_smin_mm_train_csv')\n",
    "data_mm_test_df = pd.read_csv('data_mm_test_csv')\n",
    "data_mm_val_df = pd.read_csv('data_mm_val_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ss_train_df = pd.read_csv('data_smin_ss_train_csv')\n",
    "data_ss_test_df = pd.read_csv('data_ss_test_csv')\n",
    "data_ss_val_df = pd.read_csv('data_ss_val_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_train_df = pd.read_csv('data_smin_log_train_csv')\n",
    "data_log_test_df = pd.read_csv('data_test_csv')\n",
    "data_log_val_df = pd.read_csv('data_val_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_train: (288041, 10)\n",
      "Data_test: (27022, 10)\n",
      "Data_val: (54045, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data_train: {data_mm_train_df.shape}\")\n",
    "print(f\"Data_test: {data_mm_test_df.shape}\")\n",
    "print(f\"Data_val: {data_mm_val_df.shape}\")\n",
    "\n",
    "#Divide by 10 for the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#own module which takes in df for train, test and val and returns in x and y format.  Can also sample.\n",
    "from data_formatting import data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss_train_sample, X_ss_test_sample, X_ss_val_sample, y_ss_train_sample, y_ss_test_sample, y_ss_val_sample = data_format(data_ss_train_df, data_ss_test_df, data_ss_val_df, 'sample', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mm_train_sample, X_mm_test_sample, X_mm_val_sample, y_mm_train_sample, y_mm_test_sample, y_mm_val_sample = data_format(data_mm_train_df, data_mm_test_df, data_mm_val_df, 'sample', 20)\n",
    "X_ss_train_sample, X_ss_test_sample, X_ss_val_sample, y_ss_train_sample, y_ss_test_sample, y_ss_val_sample = data_format(data_ss_train_df, data_ss_test_df, data_ss_val_df, 'sample', 20)\n",
    "X_log_train_sample, X_log_test_sample, X_log_val_sample, y_log_train_sample, y_log_test_sample, y_log_val_sample = data_format(data_log_train_df, data_log_test_df, data_log_val_df, 'sample', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14402, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mm_train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_ss_train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss_train, X_ss_test, X_ss_val, y_ss_train, y_ss_test, y_ss_val = data_format(data_ss_train_df, data_ss_test_df, data_ss_val_df, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adfasdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Sophie Folder\\Birkbeck\\Project\\Git\\DLS_Project\\SVM Model.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/SVM%20Model.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m adfasdf\n",
      "\u001b[1;31mNameError\u001b[0m: name 'adfasdf' is not defined"
     ]
    }
   ],
   "source": [
    "adfasdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline one SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = SVC(kernel=\"linear\", random_state=7)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_ss_train_sample, y_ss_train_sample)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_ss_test_sample)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_ss_test_sample, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_ss_test_sample, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgdfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = ['linear', 'rbf', 'sigmoid']\n",
    "gamma_list = [0.001, 0.01, 0.1, 1, 10, 100,200, 300]\n",
    "c_list = [0.001, 0.01, 0.1, 1, 10, 100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MinMax\")\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in k_list:\n",
    "    for gamma in gamma_list:\n",
    "        for c in c_list:\n",
    "        # for each combination of parameters, train an SVC\n",
    "                \n",
    "            model = SVC(kernel=k, gamma=gamma, C=c, random_state = 7)\n",
    "            model.fit(X_mm_train_sample, y_mm_train_sample)\n",
    "            y_mm_pred = model.predict(X_mm_val_sample)\n",
    "            accuracy = accuracy_score(y_mm_val_sample, y_mm_pred)\n",
    "            print(f\"{k}, Gamma: {gamma}, C: {c}, Accuracy: {accuracy}\")\n",
    "\n",
    "        # if we got a better score, store the score and parameters\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_parameters = {'C': c, 'gamma': gamma, 'kernel': k}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_accuracy))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS\n",
      "linear, Gamma: 0.001, C: 0.001, Accuracy: 0.6032568467801629\n",
      "linear, Gamma: 0.001, C: 0.01, Accuracy: 0.5947446336047373\n",
      "linear, Gamma: 0.001, C: 0.1, Accuracy: 0.5862324204293117\n",
      "linear, Gamma: 0.001, C: 1, Accuracy: 0.5836417468541821\n",
      "linear, Gamma: 0.001, C: 10, Accuracy: 0.5766099185788305\n"
     ]
    }
   ],
   "source": [
    "print(\"SS\")\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in k_list:\n",
    "    for gamma in gamma_list:\n",
    "        for c in c_list:\n",
    "        # for each combination of parameters, train an SVC\n",
    "                \n",
    "            model = SVC(kernel=k, gamma=gamma, C=c, random_state = 7)\n",
    "            model.fit(X_ss_train_sample, y_ss_train_sample)\n",
    "            y_ss_pred = model.predict(X_ss_val_sample)\n",
    "            accuracy = accuracy_score(y_ss_val_sample, y_ss_pred)\n",
    "            print(f\"{k}, Gamma: {gamma}, C: {c}, Accuracy: {accuracy}\")\n",
    "\n",
    "        # if we got a better score, store the score and parameters\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_parameters = {'C': c, 'gamma': gamma, 'kernel': k}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_accuracy))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgkjjk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LogNorm\")\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in k_list:\n",
    "    for gamma in gamma_list:\n",
    "        for c in c_list:\n",
    "        # for each combination of parameters, train an SVC\n",
    "                \n",
    "            model = SVC(kernel=k, gamma=gamma, C=c, random_state = 7)\n",
    "            model.fit(X_log_train_sample, y_log_train_sample)\n",
    "            y_log_pred = model.predict(X_log_val_sample)\n",
    "            accuracy = accuracy_score(y_log_val_sample, y_log_pred)\n",
    "            print(f\"{k}, Gamma: {gamma}, C: {c}, Accuracy: {accuracy}\")\n",
    "\n",
    "        # if we got a better score, store the score and parameters\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_parameters = {'C': c, 'gamma': gamma, 'kernel': k}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_accuracy))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkhjhk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the SVM base classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Create the bagging classifier with SVM as the base estimator\n",
    "bagging_classifier = BaggingClassifier(estimator=svm_classifier, random_state=7)\n",
    "\n",
    "# Use the best parameters to create the final bagging classifier\n",
    "final_bagging_classifier = BaggingClassifier(estimator=SVC(C=10, gamma=10, kernel='rbf', random_state=7), \n",
    "                                             n_estimators=100,\n",
    "                                             random_state=7)\n",
    "\n",
    "# Train the final bagging classifier on the training data\n",
    "final_bagging_classifier.fit(X_ss_train_sample, y_ss_train_sample)\n",
    "\n",
    "# Evaluate the classifier on the validation set\n",
    "val_predictions = final_bagging_classifier.predict(X_ss_val_sample)\n",
    "val_accuracy = accuracy_score(y_ss_val_sample, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "#test_predictions = final_bagging_classifier.predict(X_test)\n",
    "#test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "#print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the SVM base classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Create the bagging classifier with SVM as the base estimator\n",
    "bagging_classifier = BaggingClassifier(estimator=svm_classifier, random_state=7)\n",
    "\n",
    "# Use the best parameters to create the final bagging classifier\n",
    "final_bagging_classifier = BaggingClassifier(estimator=SVC(C=10, gamma=10, kernel='rbf', random_state=7), \n",
    "                                             n_estimators=50,\n",
    "                                             random_state=7)\n",
    "\n",
    "# Train the final bagging classifier on the training data\n",
    "final_bagging_classifier.fit(X_ss_train_sample, y_ss_train_sample)\n",
    "\n",
    "# Evaluate the classifier on the validation set\n",
    "val_predictions = final_bagging_classifier.predict(X_ss_val_sample)\n",
    "val_accuracy = accuracy_score(y_ss_val_sample, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "#test_predictions = final_bagging_classifier.predict(X_test)\n",
    "#test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "#print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the SVM base classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Define the parameters to tune (you can customize this based on your needs)\n",
    "param_grid = {\n",
    "    'base_estimator__C': [0.1, 1, 10],\n",
    "    'base_estimator__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'base_estimator__gamma': ['scale', 'auto'],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "}\n",
    "\n",
    "# Create the bagging classifier with SVM as the base estimator\n",
    "bagging_classifier = BaggingClassifier(base_estimator=svm_classifier, random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object for hyperparameter tuning\n",
    "grid_search = GridSearchCV(bagging_classifier, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_ss_train_sample, y_ss_train_sample)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best parameters to create the final bagging classifier\n",
    "final_bagging_classifier = BaggingClassifier(base_estimator=SVC(**best_params['base_estimator']), \n",
    "                                             n_estimators=best_params['n_estimators'],\n",
    "                                             random_state=42)\n",
    "\n",
    "# Train the final bagging classifier on the training data\n",
    "final_bagging_classifier.fit(X_ss_train_sample, y_ss_train_sample)\n",
    "\n",
    "# Evaluate the classifier on the validation set\n",
    "val_predictions = final_bagging_classifier.predict(X_ss_val_sample)\n",
    "val_accuracy = accuracy_score(y_ss_val_sample, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "#test_predictions = final_bagging_classifier.predict(X_test)\n",
    "#test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "#print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/66216/gridsearch-without-cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = ['linear', 'rbf', 'sigmoid']\n",
    "gamma_list = [0.001, 0.01, 0.1, 1, 10, 100,200, 300]\n",
    "c_list = [0.001, 0.01, 0.1, 1, 10, 100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the architecture of the autoencoder\n",
    "input_dim = X_ss_train_sample.shape[1]\n",
    "encoding_dim = 10  # You can adjust this based on your preference\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_ss_train_sample, X_ss_train_sample, epochs=50, batch_size=32, shuffle=True, validation_data=(X_ss_test_sample, X_ss_test_sample))\n",
    "\n",
    "# Extract features using the encoder part of the autoencoder\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_features_train = encoder.predict(X_ss_train_sample)\n",
    "encoded_features_test = encoder.predict(X_ss_test_sample)\n",
    "\n",
    "best_accuracy = 0\n",
    "# Now use SVM as the classifier\n",
    "for k in k_list:\n",
    "    for c in c_list:\n",
    "        for g in gamma_list:\n",
    "            svm_classifier = SVC(C=c, gamma=g, kernel=k, random_state=7)  # You can adjust the kernel and C parameter based on your preference\n",
    "            svm_classifier.fit(encoded_features_train, y_ss_train_sample)\n",
    "\n",
    "            # Predict on the test set\n",
    "            svm_predictions = svm_classifier.predict(encoded_features_test)\n",
    "\n",
    "            # Evaluate accuracy\n",
    "            accuracy = accuracy_score(y_ss_test_sample, svm_predictions)\n",
    "            print(f'Kernel: {k}, C: {c}, Gamma: {g}, SVM Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_parameters = {'C': c, 'gamma': gamma, 'kernel': k}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_accuracy))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = ['rbf']\n",
    "gamma_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "c_list = [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Temp\\ipykernel_1396\\438131127.py\", line 25, in <module>\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py\", line 5777, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,8] and labels shape [256]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_2140]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Sophie Folder\\Birkbeck\\Project\\Git\\DLS_Project\\SVM Model.ipynb Cell 37\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/SVM%20Model.ipynb#X46sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m autoencoder\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/SVM%20Model.ipynb#X46sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Train the autoencoder\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/SVM%20Model.ipynb#X46sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(X_ss_train_sample, X_ss_train_sample, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, validation_data\u001b[39m=\u001b[39;49m(X_ss_test_sample, X_ss_test_sample))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/SVM%20Model.ipynb#X46sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Extract features using the encoder part of the autoencoder\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/SVM%20Model.ipynb#X46sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m encoder \u001b[39m=\u001b[39m Model(input_layer, encoded)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Temp\\ipykernel_1396\\438131127.py\", line 25, in <module>\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\carth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py\", line 5777, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,8] and labels shape [256]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_2140]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the architecture of the autoencoder\n",
    "input_dim = X_ss_train_sample.shape[1]\n",
    "encoding_dim = 10  # You can adjust this based on your preference\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_ss_train_sample, X_ss_train_sample, epochs=50, batch_size=32, shuffle=True, validation_data=(X_ss_test_sample, X_ss_test_sample))\n",
    "\n",
    "# Extract features using the encoder part of the autoencoder\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_features_train = encoder.predict(X_ss_train_sample)\n",
    "encoded_features_test = encoder.predict(X_ss_test_sample)\n",
    "\n",
    "best_accuracy = 0\n",
    "# Now use SVM as the classifier\n",
    "for k in k_list:\n",
    "    for c in c_list:\n",
    "        for g in gamma_list:\n",
    "            svm_classifier = SVC(C=c, gamma=g, kernel=k, random_state=7)  # You can adjust the kernel and C parameter based on your preference\n",
    "            svm_classifier.fit(encoded_features_train, y_ss_train_sample)\n",
    "\n",
    "            # Predict on the test set\n",
    "            svm_predictions = svm_classifier.predict(encoded_features_test)\n",
    "\n",
    "            # Evaluate accuracy\n",
    "            accuracy = accuracy_score(y_ss_test_sample, svm_predictions)\n",
    "            print(f'Kernel: {k}, C: {c}, Gamma: {g}, SVM Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_parameters = {'C': c, 'gamma': g, 'kernel': k}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_accuracy))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = ['linear', 'rbf', 'sigmoid']\n",
    "gamma_list = [0.001, 0.01, 0.1, 1, 10, 100,200, 300]\n",
    "c_list = [0.001, 0.01, 0.1, 1, 10, 100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the architecture of the autoencoder\n",
    "input_dim = X_ss_train_sample.shape[1]\n",
    "encoding_dim = 10  # You can adjust this based on your preference\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_ss_train_sample, X_ss_train_sample, epochs=150, batch_size=32, shuffle=True, validation_data=(X_ss_test_sample, X_ss_test_sample))\n",
    "\n",
    "# Extract features using the encoder part of the autoencoder\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_features_train = encoder.predict(X_ss_train_sample)\n",
    "encoded_features_test = encoder.predict(X_ss_test_sample)\n",
    "\n",
    "best_accuracy = 0\n",
    "# Now use SVM as the classifier\n",
    "for k in k_list:\n",
    "    for c in c_list:\n",
    "        for g in gamma_list:\n",
    "            svm_classifier = SVC(C=c, gamma=g, kernel=k, random_state=7)  # You can adjust the kernel and C parameter based on your preference\n",
    "            svm_classifier.fit(encoded_features_train, y_ss_train_sample)\n",
    "\n",
    "            # Predict on the test set\n",
    "            svm_predictions = svm_classifier.predict(encoded_features_test)\n",
    "\n",
    "            # Evaluate accuracy\n",
    "            accuracy = accuracy_score(y_ss_test_sample, svm_predictions)\n",
    "            print(f'Kernel: {k}, C: {c}, Gamma: {g}, SVM Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_parameters = {'C': c, 'gamma': g, 'kernel': k}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_accuracy))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder but with all 8 variables?\n",
    "PCA instead of autoencoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = ['rbf']\n",
    "gamma_list = [0.001, 0.01, 0.1, 1, 10, 100,200, 300]\n",
    "c_list = [0.001, 0.01, 0.1, 1, 10, 100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "for n in range(2,8):\n",
    "# Perform PCA to reduce dimensionality\n",
    "    #n_components = 2  # Number of principal components to keep\n",
    "    pca = PCA(n_components=n)\n",
    "    X_train_pca = pca.fit_transform(X_ss_train_sample)\n",
    "    X_test_pca = pca.transform(X_ss_test_sample)\n",
    "\n",
    "    for k in k_list:\n",
    "        for c in c_list:\n",
    "            for g in gamma_list:\n",
    "                svm_classifier = SVC(C=c, gamma=g, kernel=k, random_state=7)  # You can adjust the kernel and C parameter based on your preference\n",
    "                svm_classifier.fit(X_train_pca, y_ss_train_sample)\n",
    "\n",
    "                y_pred = svm_classifier.predict(X_test_pca)\n",
    "\n",
    "                accuracy = accuracy_score(y_ss_test_sample, y_pred)\n",
    "                print(f'PCs: {n}, Kernel: {k}, C: {c}, Gamma: {g}, SVM Accuracy: {accuracy}')\n",
    "                \n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_parameters = {'PCs': n, 'C': c, 'gamma': g, 'kernel': k}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_accuracy))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SS\")\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in k_list:\n",
    "    for gamma in gamma_list:\n",
    "        for c in c_list:\n",
    "        # for each combination of parameters, train an SVC\n",
    "                \n",
    "            model = SVC(kernel=k, gamma=gamma, C=c, random_state = 7)\n",
    "            model.fit(X_ss_train_sample, y_ss_train_sample)\n",
    "            y_ss_pred = model.predict(X_ss_val_sample)\n",
    "            accuracy = accuracy_score(y_ss_val_sample, y_ss_pred)\n",
    "            print(f\"{k}, Gamma: {gamma}, C: {c}, Accuracy: {accuracy}\")\n",
    "\n",
    "        # if we got a better score, store the score and parameters\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_parameters = {'C': c, 'gamma': gamma, 'kernel': k}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_accuracy))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used SS scaled data, best parameters as chosen above and all of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = SVC(kernel=\"rbf\", random_state=10, C=10, gamma=1)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_ss_train, y_ss_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_ss_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_ss_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
