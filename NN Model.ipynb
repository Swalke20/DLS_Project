{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ss_train_df = pd.read_csv('data_smin_ss_train_csv')\n",
    "data_ss_test_df = pd.read_csv('data_ss_test_csv')\n",
    "data_ss_val_df = pd.read_csv('data_ss_val_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Wickets taken</th>\n",
       "      <th>Remaining Team Value</th>\n",
       "      <th>Remaining Average Team Value</th>\n",
       "      <th>Start Team Value</th>\n",
       "      <th>Ground RPO</th>\n",
       "      <th>Ground RPW</th>\n",
       "      <th>Remaining overs and balls</th>\n",
       "      <th>Remainder</th>\n",
       "      <th>Winner_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.643491</td>\n",
       "      <td>0.670651</td>\n",
       "      <td>0.601874</td>\n",
       "      <td>-0.114034</td>\n",
       "      <td>-0.367329</td>\n",
       "      <td>-0.290906</td>\n",
       "      <td>1.607451</td>\n",
       "      <td>1.585879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.643491</td>\n",
       "      <td>0.670651</td>\n",
       "      <td>0.601874</td>\n",
       "      <td>-0.114034</td>\n",
       "      <td>-0.367329</td>\n",
       "      <td>-0.290906</td>\n",
       "      <td>1.567007</td>\n",
       "      <td>1.561594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.643491</td>\n",
       "      <td>0.670651</td>\n",
       "      <td>0.601874</td>\n",
       "      <td>-0.114034</td>\n",
       "      <td>-0.367329</td>\n",
       "      <td>-0.290906</td>\n",
       "      <td>1.546786</td>\n",
       "      <td>1.549451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.643491</td>\n",
       "      <td>0.670651</td>\n",
       "      <td>0.601874</td>\n",
       "      <td>-0.114034</td>\n",
       "      <td>-0.367329</td>\n",
       "      <td>-0.290906</td>\n",
       "      <td>1.506342</td>\n",
       "      <td>1.525166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.643491</td>\n",
       "      <td>0.670651</td>\n",
       "      <td>0.601874</td>\n",
       "      <td>-0.114034</td>\n",
       "      <td>-0.367329</td>\n",
       "      <td>-0.290906</td>\n",
       "      <td>1.486121</td>\n",
       "      <td>1.464454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288036</th>\n",
       "      <td>288036</td>\n",
       "      <td>0.302034</td>\n",
       "      <td>-0.073756</td>\n",
       "      <td>0.601874</td>\n",
       "      <td>1.055524</td>\n",
       "      <td>1.659558</td>\n",
       "      <td>1.371243</td>\n",
       "      <td>-1.405570</td>\n",
       "      <td>-1.380938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288037</th>\n",
       "      <td>288037</td>\n",
       "      <td>1.720323</td>\n",
       "      <td>-1.562571</td>\n",
       "      <td>-1.525800</td>\n",
       "      <td>-0.114034</td>\n",
       "      <td>-0.120935</td>\n",
       "      <td>0.381440</td>\n",
       "      <td>-1.708894</td>\n",
       "      <td>-1.716881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288038</th>\n",
       "      <td>288038</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>-0.073756</td>\n",
       "      <td>-0.083139</td>\n",
       "      <td>-1.283592</td>\n",
       "      <td>-0.031933</td>\n",
       "      <td>0.138307</td>\n",
       "      <td>0.475040</td>\n",
       "      <td>0.474810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288039</th>\n",
       "      <td>288039</td>\n",
       "      <td>-1.116254</td>\n",
       "      <td>0.856753</td>\n",
       "      <td>0.275274</td>\n",
       "      <td>-0.698813</td>\n",
       "      <td>-0.742092</td>\n",
       "      <td>-0.810383</td>\n",
       "      <td>1.486121</td>\n",
       "      <td>1.464454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288040</th>\n",
       "      <td>288040</td>\n",
       "      <td>-0.643491</td>\n",
       "      <td>0.484549</td>\n",
       "      <td>0.202935</td>\n",
       "      <td>-0.114034</td>\n",
       "      <td>2.993037</td>\n",
       "      <td>2.456672</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.274529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288041 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Wickets taken  Remaining Team Value   \n",
       "0                0      -0.643491              0.670651  \\\n",
       "1                1      -0.643491              0.670651   \n",
       "2                2      -0.643491              0.670651   \n",
       "3                3      -0.643491              0.670651   \n",
       "4                4      -0.643491              0.670651   \n",
       "...            ...            ...                   ...   \n",
       "288036      288036       0.302034             -0.073756   \n",
       "288037      288037       1.720323             -1.562571   \n",
       "288038      288038      -0.170728             -0.073756   \n",
       "288039      288039      -1.116254              0.856753   \n",
       "288040      288040      -0.643491              0.484549   \n",
       "\n",
       "        Remaining Average Team Value  Start Team Value  Ground RPO   \n",
       "0                           0.601874         -0.114034   -0.367329  \\\n",
       "1                           0.601874         -0.114034   -0.367329   \n",
       "2                           0.601874         -0.114034   -0.367329   \n",
       "3                           0.601874         -0.114034   -0.367329   \n",
       "4                           0.601874         -0.114034   -0.367329   \n",
       "...                              ...               ...         ...   \n",
       "288036                      0.601874          1.055524    1.659558   \n",
       "288037                     -1.525800         -0.114034   -0.120935   \n",
       "288038                     -0.083139         -1.283592   -0.031933   \n",
       "288039                      0.275274         -0.698813   -0.742092   \n",
       "288040                      0.202935         -0.114034    2.993037   \n",
       "\n",
       "        Ground RPW  Remaining overs and balls  Remainder  Winner_num  \n",
       "0        -0.290906                   1.607451   1.585879           0  \n",
       "1        -0.290906                   1.567007   1.561594           0  \n",
       "2        -0.290906                   1.546786   1.549451           0  \n",
       "3        -0.290906                   1.506342   1.525166           0  \n",
       "4        -0.290906                   1.486121   1.464454           0  \n",
       "...            ...                        ...        ...         ...  \n",
       "288036    1.371243                  -1.405570  -1.380938           1  \n",
       "288037    0.381440                  -1.708894  -1.716881           1  \n",
       "288038    0.138307                   0.475040   0.474810           1  \n",
       "288039   -0.810383                   1.486121   1.464454           1  \n",
       "288040    2.456672                   1.243461   1.274529           1  \n",
       "\n",
       "[288041 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ss_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_format(train_df, test_df, val_df, sample):\n",
    "    train_df = train_df.drop(['Unnamed: 0'], axis=1)\n",
    "    test_df = test_df.drop(['Unnamed: 0'], axis=1)\n",
    "    val_df = val_df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    if sample!=None:\n",
    "        train_df = train_df.sample(n=14402, replace=False, random_state=7, axis=0)\n",
    "        test_df = test_df.sample(n=1351, replace=False, random_state=7, axis=0)\n",
    "        val_df = val_df.sample(n=2702, replace=False, random_state=7, axis=0)\n",
    "\n",
    "    X_train = train_df.drop('Winner_num',axis=1)\n",
    "    y_train = train_df['Winner_num']\n",
    "\n",
    "    X_test= test_df.drop('Winner_num',axis=1) \n",
    "    y_test = test_df['Winner_num']\n",
    "\n",
    "    X_val= val_df.drop('Winner_num',axis=1) \n",
    "    y_val = val_df['Winner_num']\n",
    "    return(X_train, X_test, X_val, y_train, y_test, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss_train, X_ss_test, X_ss_val, y_ss_train, y_ss_test, y_ss_val = data_format(data_ss_train_df, data_ss_test_df, data_ss_val_df, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_mm_train_sample, X_mm_test_sample, X_mm_val_sample, y_mm_train_sample, y_mm_test_sample, y_mm_val_sample = data_format(data_mm_train_df, data_mm_test_df, data_mm_val_df, 'sample')\n",
    "X_ss_train_sample, X_ss_test_sample, X_ss_val_sample, y_ss_train_sample, y_ss_test_sample, y_ss_val_sample = data_format(data_ss_train_df, data_ss_test_df, data_ss_val_df, 'sample')\n",
    "#X_log_train_sample, X_log_test_sample, X_log_val_sample, y_log_train_sample, y_log_test_sample, y_log_val_sample = data_format(data_log_train_df, data_log_test_df, data_log_val_df, 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\carth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 64)                576       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2755 (10.76 KB)\n",
      "Trainable params: 2755 (10.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential()\n",
    "\n",
    "X_train_dim = X_ss_train.shape[1]\n",
    "\n",
    "# Add input layer and hidden layers\n",
    "model.add(layers.Dense(64, activation='relu', input_dim=X_train_dim))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add output layer with softmax activation for multi-class classification\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',  # Use categorical crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8890/9002 [============================>.] - ETA: 0s - loss: 1.0790 - accuracy: 0.3359"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Sophie Folder\\Birkbeck\\Project\\Git\\DLS_Project\\NN Model.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/NN%20Model.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/NN%20Model.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_ss_train, y_ss_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_ss_val, y_ss_val))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/NN%20Model.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Sophie%20Folder/Birkbeck/Project/Git/DLS_Project/NN%20Model.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_ss_test, y_ss_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_ss_train, y_ss_train, epochs=30, batch_size=32, validation_data=(X_ss_val, y_ss_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_ss_test, y_ss_test)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# You can use the model for predictions\n",
    "predictions = model.predict(X_ss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning learning_rate=1e-06, epochs=10\n",
      "Epoch 1/10\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 1.1597 - accuracy: 0.3539 - val_loss: 1.0066 - val_accuracy: 0.6116\n",
      "Epoch 2/10\n",
      "9002/9002 [==============================] - 30s 3ms/step - loss: 1.1122 - accuracy: 0.3879 - val_loss: 1.0068 - val_accuracy: 0.6214\n",
      "Epoch 3/10\n",
      "9002/9002 [==============================] - 30s 3ms/step - loss: 1.0825 - accuracy: 0.4138 - val_loss: 1.0020 - val_accuracy: 0.6011\n",
      "Epoch 4/10\n",
      "9002/9002 [==============================] - 35s 4ms/step - loss: 1.0639 - accuracy: 0.4318 - val_loss: 0.9952 - val_accuracy: 0.5901\n",
      "Epoch 5/10\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 1.0493 - accuracy: 0.4457 - val_loss: 0.9871 - val_accuracy: 0.5881\n",
      "Epoch 6/10\n",
      "9002/9002 [==============================] - 30s 3ms/step - loss: 1.0387 - accuracy: 0.4556 - val_loss: 0.9809 - val_accuracy: 0.5868\n",
      "Epoch 7/10\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 1.0300 - accuracy: 0.4641 - val_loss: 0.9750 - val_accuracy: 0.5859\n",
      "Epoch 8/10\n",
      "9002/9002 [==============================] - 31s 3ms/step - loss: 1.0222 - accuracy: 0.4725 - val_loss: 0.9692 - val_accuracy: 0.5870\n",
      "Epoch 9/10\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 1.0160 - accuracy: 0.4776 - val_loss: 0.9643 - val_accuracy: 0.5880\n",
      "Epoch 10/10\n",
      "9002/9002 [==============================] - 31s 3ms/step - loss: 1.0111 - accuracy: 0.4820 - val_loss: 0.9607 - val_accuracy: 0.5878\n",
      "1689/1689 [==============================] - 4s 2ms/step - loss: 0.9607 - accuracy: 0.5878\n",
      "Learning rate: 1e-06, Epoch: 10 Validation accuracy: 0.5878064632415771\n",
      "Tuning learning_rate=1e-06, epochs=20\n",
      "Epoch 1/20\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 1.1766 - accuracy: 0.3308 - val_loss: 1.0722 - val_accuracy: 0.3929\n",
      "Epoch 2/20\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 1.1202 - accuracy: 0.3753 - val_loss: 1.0419 - val_accuracy: 0.5262\n",
      "Epoch 3/20\n",
      "9002/9002 [==============================] - 33s 4ms/step - loss: 1.0872 - accuracy: 0.4069 - val_loss: 1.0186 - val_accuracy: 0.5522\n",
      "Epoch 4/20\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 1.0646 - accuracy: 0.4311 - val_loss: 1.0013 - val_accuracy: 0.5618\n",
      "Epoch 5/20\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 1.0466 - accuracy: 0.4482 - val_loss: 0.9869 - val_accuracy: 0.5689\n",
      "Epoch 6/20\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 1.0347 - accuracy: 0.4607 - val_loss: 0.9754 - val_accuracy: 0.5739\n",
      "Epoch 7/20\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 1.0237 - accuracy: 0.4705 - val_loss: 0.9664 - val_accuracy: 0.5771\n",
      "Epoch 8/20\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 1.0153 - accuracy: 0.4794 - val_loss: 0.9587 - val_accuracy: 0.5803\n",
      "Epoch 9/20\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 1.0098 - accuracy: 0.4831 - val_loss: 0.9529 - val_accuracy: 0.5828\n",
      "Epoch 10/20\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 1.0032 - accuracy: 0.4902 - val_loss: 0.9481 - val_accuracy: 0.5845\n",
      "Epoch 11/20\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.9992 - accuracy: 0.4943 - val_loss: 0.9443 - val_accuracy: 0.5860\n",
      "Epoch 12/20\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.9933 - accuracy: 0.4979 - val_loss: 0.9406 - val_accuracy: 0.5872\n",
      "Epoch 13/20\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.9904 - accuracy: 0.5020 - val_loss: 0.9381 - val_accuracy: 0.5885\n",
      "Epoch 14/20\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9863 - accuracy: 0.5055 - val_loss: 0.9353 - val_accuracy: 0.5902\n",
      "Epoch 15/20\n",
      "9002/9002 [==============================] - 24s 3ms/step - loss: 0.9836 - accuracy: 0.5084 - val_loss: 0.9330 - val_accuracy: 0.5913\n",
      "Epoch 16/20\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.9798 - accuracy: 0.5108 - val_loss: 0.9308 - val_accuracy: 0.5922\n",
      "Epoch 17/20\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.9768 - accuracy: 0.5145 - val_loss: 0.9290 - val_accuracy: 0.5932\n",
      "Epoch 18/20\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.9746 - accuracy: 0.5155 - val_loss: 0.9277 - val_accuracy: 0.5939\n",
      "Epoch 19/20\n",
      "9002/9002 [==============================] - 44s 5ms/step - loss: 0.9715 - accuracy: 0.5192 - val_loss: 0.9261 - val_accuracy: 0.5946\n",
      "Epoch 20/20\n",
      "9002/9002 [==============================] - 44s 5ms/step - loss: 0.9689 - accuracy: 0.5214 - val_loss: 0.9245 - val_accuracy: 0.5958\n",
      "1689/1689 [==============================] - 4s 2ms/step - loss: 0.9245 - accuracy: 0.5958\n",
      "Learning rate: 1e-06, Epoch: 20 Validation accuracy: 0.595818281173706\n",
      "Tuning learning_rate=1e-06, epochs=30\n",
      "Epoch 1/30\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 1.2428 - accuracy: 0.3269 - val_loss: 1.1957 - val_accuracy: 0.1599\n",
      "Epoch 2/30\n",
      "9002/9002 [==============================] - 35s 4ms/step - loss: 1.1615 - accuracy: 0.3498 - val_loss: 1.0961 - val_accuracy: 0.3938\n",
      "Epoch 3/30\n",
      "9002/9002 [==============================] - 28s 3ms/step - loss: 1.1136 - accuracy: 0.3773 - val_loss: 1.0349 - val_accuracy: 0.5472\n",
      "Epoch 4/30\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 1.0830 - accuracy: 0.4064 - val_loss: 0.9951 - val_accuracy: 0.6043\n",
      "Epoch 5/30\n",
      "9002/9002 [==============================] - 36s 4ms/step - loss: 1.0627 - accuracy: 0.4277 - val_loss: 0.9687 - val_accuracy: 0.6305\n",
      "Epoch 6/30\n",
      "9002/9002 [==============================] - 52s 6ms/step - loss: 1.0458 - accuracy: 0.4460 - val_loss: 0.9502 - val_accuracy: 0.6404\n",
      "Epoch 7/30\n",
      "9002/9002 [==============================] - 52s 6ms/step - loss: 1.0351 - accuracy: 0.4570 - val_loss: 0.9371 - val_accuracy: 0.6461\n",
      "Epoch 8/30\n",
      "9002/9002 [==============================] - 51s 6ms/step - loss: 1.0248 - accuracy: 0.4674 - val_loss: 0.9275 - val_accuracy: 0.6486\n",
      "Epoch 9/30\n",
      "9002/9002 [==============================] - 35s 4ms/step - loss: 1.0167 - accuracy: 0.4751 - val_loss: 0.9205 - val_accuracy: 0.6483\n",
      "Epoch 10/30\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 1.0115 - accuracy: 0.4791 - val_loss: 0.9146 - val_accuracy: 0.6488\n",
      "Epoch 11/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.0045 - accuracy: 0.4861 - val_loss: 0.9097 - val_accuracy: 0.6493\n",
      "Epoch 12/30\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9998 - accuracy: 0.4911 - val_loss: 0.9064 - val_accuracy: 0.6485\n",
      "Epoch 13/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9957 - accuracy: 0.4950 - val_loss: 0.9037 - val_accuracy: 0.6478\n",
      "Epoch 14/30\n",
      "9002/9002 [==============================] - 33s 4ms/step - loss: 0.9919 - accuracy: 0.4986 - val_loss: 0.9013 - val_accuracy: 0.6479\n",
      "Epoch 15/30\n",
      "9002/9002 [==============================] - 28s 3ms/step - loss: 0.9874 - accuracy: 0.5028 - val_loss: 0.8992 - val_accuracy: 0.6473\n",
      "Epoch 16/30\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9846 - accuracy: 0.5060 - val_loss: 0.8975 - val_accuracy: 0.6478\n",
      "Epoch 17/30\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.9817 - accuracy: 0.5088 - val_loss: 0.8959 - val_accuracy: 0.6485\n",
      "Epoch 18/30\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.9783 - accuracy: 0.5107 - val_loss: 0.8947 - val_accuracy: 0.6486\n",
      "Epoch 19/30\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.9766 - accuracy: 0.5142 - val_loss: 0.8936 - val_accuracy: 0.6485\n",
      "Epoch 20/30\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.9746 - accuracy: 0.5155 - val_loss: 0.8926 - val_accuracy: 0.6484\n",
      "Epoch 21/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9725 - accuracy: 0.5173 - val_loss: 0.8916 - val_accuracy: 0.6482\n",
      "Epoch 22/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9691 - accuracy: 0.5200 - val_loss: 0.8907 - val_accuracy: 0.6482\n",
      "Epoch 23/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9686 - accuracy: 0.5229 - val_loss: 0.8897 - val_accuracy: 0.6485\n",
      "Epoch 24/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9668 - accuracy: 0.5241 - val_loss: 0.8890 - val_accuracy: 0.6482\n",
      "Epoch 25/30\n",
      "9002/9002 [==============================] - 37s 4ms/step - loss: 0.9649 - accuracy: 0.5246 - val_loss: 0.8879 - val_accuracy: 0.6483\n",
      "Epoch 26/30\n",
      "9002/9002 [==============================] - 49s 5ms/step - loss: 0.9623 - accuracy: 0.5276 - val_loss: 0.8875 - val_accuracy: 0.6480\n",
      "Epoch 27/30\n",
      "9002/9002 [==============================] - 49s 5ms/step - loss: 0.9614 - accuracy: 0.5283 - val_loss: 0.8868 - val_accuracy: 0.6482\n",
      "Epoch 28/30\n",
      "9002/9002 [==============================] - 47s 5ms/step - loss: 0.9589 - accuracy: 0.5309 - val_loss: 0.8862 - val_accuracy: 0.6482\n",
      "Epoch 29/30\n",
      "9002/9002 [==============================] - 48s 5ms/step - loss: 0.9575 - accuracy: 0.5328 - val_loss: 0.8858 - val_accuracy: 0.6474\n",
      "Epoch 30/30\n",
      "9002/9002 [==============================] - 46s 5ms/step - loss: 0.9565 - accuracy: 0.5338 - val_loss: 0.8852 - val_accuracy: 0.6474\n",
      "1689/1689 [==============================] - 6s 3ms/step - loss: 0.8852 - accuracy: 0.6474\n",
      "Learning rate: 1e-06, Epoch: 30 Validation accuracy: 0.6474049687385559\n",
      "Tuning learning_rate=1e-05, epochs=10\n",
      "Epoch 1/10\n",
      "9002/9002 [==============================] - 50s 5ms/step - loss: 1.0525 - accuracy: 0.4358 - val_loss: 0.9390 - val_accuracy: 0.6270\n",
      "Epoch 2/10\n",
      "9002/9002 [==============================] - 48s 5ms/step - loss: 0.9852 - accuracy: 0.5071 - val_loss: 0.9215 - val_accuracy: 0.6253\n",
      "Epoch 3/10\n",
      "9002/9002 [==============================] - 48s 5ms/step - loss: 0.9650 - accuracy: 0.5278 - val_loss: 0.9114 - val_accuracy: 0.6216\n",
      "Epoch 4/10\n",
      "9002/9002 [==============================] - 47s 5ms/step - loss: 0.9497 - accuracy: 0.5401 - val_loss: 0.9040 - val_accuracy: 0.6169\n",
      "Epoch 5/10\n",
      "9002/9002 [==============================] - 48s 5ms/step - loss: 0.9388 - accuracy: 0.5507 - val_loss: 0.8955 - val_accuracy: 0.6126\n",
      "Epoch 6/10\n",
      "9002/9002 [==============================] - 48s 5ms/step - loss: 0.9277 - accuracy: 0.5594 - val_loss: 0.8899 - val_accuracy: 0.6087\n",
      "Epoch 7/10\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.9180 - accuracy: 0.5662 - val_loss: 0.8830 - val_accuracy: 0.6071\n",
      "Epoch 8/10\n",
      "9002/9002 [==============================] - 23s 3ms/step - loss: 0.9091 - accuracy: 0.5719 - val_loss: 0.8755 - val_accuracy: 0.6068\n",
      "Epoch 9/10\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.9013 - accuracy: 0.5764 - val_loss: 0.8740 - val_accuracy: 0.6050\n",
      "Epoch 10/10\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.8920 - accuracy: 0.5833 - val_loss: 0.8645 - val_accuracy: 0.6090\n",
      "1689/1689 [==============================] - 5s 3ms/step - loss: 0.8645 - accuracy: 0.6090\n",
      "Learning rate: 1e-05, Epoch: 10 Validation accuracy: 0.6089555025100708\n",
      "Tuning learning_rate=1e-05, epochs=20\n",
      "Epoch 1/20\n",
      "9002/9002 [==============================] - 44s 5ms/step - loss: 1.0609 - accuracy: 0.4350 - val_loss: 0.9663 - val_accuracy: 0.5612\n",
      "Epoch 2/20\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.9821 - accuracy: 0.5058 - val_loss: 0.9451 - val_accuracy: 0.5713\n",
      "Epoch 3/20\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.9617 - accuracy: 0.5258 - val_loss: 0.9346 - val_accuracy: 0.5727\n",
      "Epoch 4/20\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.9455 - accuracy: 0.5399 - val_loss: 0.9263 - val_accuracy: 0.5681\n",
      "Epoch 5/20\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.9338 - accuracy: 0.5517 - val_loss: 0.9207 - val_accuracy: 0.5605\n",
      "Epoch 6/20\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.9213 - accuracy: 0.5614 - val_loss: 0.9149 - val_accuracy: 0.5549\n",
      "Epoch 7/20\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.9120 - accuracy: 0.5678 - val_loss: 0.9083 - val_accuracy: 0.5561\n",
      "Epoch 8/20\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.9019 - accuracy: 0.5747 - val_loss: 0.9013 - val_accuracy: 0.5567\n",
      "Epoch 9/20\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.8926 - accuracy: 0.5823 - val_loss: 0.8921 - val_accuracy: 0.5606\n",
      "Epoch 10/20\n",
      "9002/9002 [==============================] - 47s 5ms/step - loss: 0.8832 - accuracy: 0.5882 - val_loss: 0.8848 - val_accuracy: 0.5636\n",
      "Epoch 11/20\n",
      "9002/9002 [==============================] - 44s 5ms/step - loss: 0.8750 - accuracy: 0.5941 - val_loss: 0.8753 - val_accuracy: 0.5697\n",
      "Epoch 12/20\n",
      "9002/9002 [==============================] - 45s 5ms/step - loss: 0.8660 - accuracy: 0.5998 - val_loss: 0.8697 - val_accuracy: 0.5717\n",
      "Epoch 13/20\n",
      "9002/9002 [==============================] - 47s 5ms/step - loss: 0.8561 - accuracy: 0.6059 - val_loss: 0.8653 - val_accuracy: 0.5731\n",
      "Epoch 14/20\n",
      "9002/9002 [==============================] - 47s 5ms/step - loss: 0.8474 - accuracy: 0.6126 - val_loss: 0.8535 - val_accuracy: 0.5795\n",
      "Epoch 15/20\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.8382 - accuracy: 0.6181 - val_loss: 0.8472 - val_accuracy: 0.5804\n",
      "Epoch 16/20\n",
      "9002/9002 [==============================] - 21s 2ms/step - loss: 0.8293 - accuracy: 0.6242 - val_loss: 0.8419 - val_accuracy: 0.5815\n",
      "Epoch 17/20\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.8207 - accuracy: 0.6303 - val_loss: 0.8340 - val_accuracy: 0.5859\n",
      "Epoch 18/20\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.8123 - accuracy: 0.6354 - val_loss: 0.8279 - val_accuracy: 0.5888\n",
      "Epoch 19/20\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.8059 - accuracy: 0.6401 - val_loss: 0.8206 - val_accuracy: 0.5932\n",
      "Epoch 20/20\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.7976 - accuracy: 0.6454 - val_loss: 0.8151 - val_accuracy: 0.5960\n",
      "1689/1689 [==============================] - 5s 3ms/step - loss: 0.8151 - accuracy: 0.5960\n",
      "Learning rate: 1e-05, Epoch: 20 Validation accuracy: 0.5959848165512085\n",
      "Tuning learning_rate=1e-05, epochs=30\n",
      "Epoch 1/30\n",
      "9002/9002 [==============================] - 44s 5ms/step - loss: 1.0519 - accuracy: 0.4381 - val_loss: 0.9405 - val_accuracy: 0.6068\n",
      "Epoch 2/30\n",
      "9002/9002 [==============================] - 44s 5ms/step - loss: 0.9835 - accuracy: 0.5081 - val_loss: 0.9242 - val_accuracy: 0.6058\n",
      "Epoch 3/30\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.9627 - accuracy: 0.5258 - val_loss: 0.9103 - val_accuracy: 0.6114\n",
      "Epoch 4/30\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.9469 - accuracy: 0.5406 - val_loss: 0.9031 - val_accuracy: 0.6099\n",
      "Epoch 5/30\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.9358 - accuracy: 0.5503 - val_loss: 0.8960 - val_accuracy: 0.6081\n",
      "Epoch 6/30\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.9231 - accuracy: 0.5595 - val_loss: 0.8879 - val_accuracy: 0.6076\n",
      "Epoch 7/30\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.9139 - accuracy: 0.5665 - val_loss: 0.8810 - val_accuracy: 0.6075\n",
      "Epoch 8/30\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.9058 - accuracy: 0.5721 - val_loss: 0.8748 - val_accuracy: 0.6061\n",
      "Epoch 9/30\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.8967 - accuracy: 0.5792 - val_loss: 0.8699 - val_accuracy: 0.6042\n",
      "Epoch 10/30\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.8879 - accuracy: 0.5843 - val_loss: 0.8639 - val_accuracy: 0.6039\n",
      "Epoch 11/30\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.8802 - accuracy: 0.5904 - val_loss: 0.8595 - val_accuracy: 0.6038\n",
      "Epoch 12/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8714 - accuracy: 0.5960 - val_loss: 0.8519 - val_accuracy: 0.6061\n",
      "Epoch 13/30\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.8628 - accuracy: 0.6018 - val_loss: 0.8470 - val_accuracy: 0.6056\n",
      "Epoch 14/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8543 - accuracy: 0.6083 - val_loss: 0.8436 - val_accuracy: 0.6047\n",
      "Epoch 15/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8479 - accuracy: 0.6127 - val_loss: 0.8393 - val_accuracy: 0.6056\n",
      "Epoch 16/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8396 - accuracy: 0.6173 - val_loss: 0.8313 - val_accuracy: 0.6094\n",
      "Epoch 17/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8315 - accuracy: 0.6227 - val_loss: 0.8241 - val_accuracy: 0.6115\n",
      "Epoch 18/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8259 - accuracy: 0.6264 - val_loss: 0.8211 - val_accuracy: 0.6110\n",
      "Epoch 19/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8177 - accuracy: 0.6319 - val_loss: 0.8139 - val_accuracy: 0.6138\n",
      "Epoch 20/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8113 - accuracy: 0.6366 - val_loss: 0.8125 - val_accuracy: 0.6124\n",
      "Epoch 21/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8042 - accuracy: 0.6408 - val_loss: 0.8063 - val_accuracy: 0.6157\n",
      "Epoch 22/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7973 - accuracy: 0.6458 - val_loss: 0.8025 - val_accuracy: 0.6168\n",
      "Epoch 23/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7925 - accuracy: 0.6485 - val_loss: 0.7946 - val_accuracy: 0.6207\n",
      "Epoch 24/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7856 - accuracy: 0.6538 - val_loss: 0.7927 - val_accuracy: 0.6210\n",
      "Epoch 25/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7795 - accuracy: 0.6574 - val_loss: 0.7893 - val_accuracy: 0.6219\n",
      "Epoch 26/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7744 - accuracy: 0.6609 - val_loss: 0.7866 - val_accuracy: 0.6225\n",
      "Epoch 27/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7676 - accuracy: 0.6643 - val_loss: 0.7810 - val_accuracy: 0.6256\n",
      "Epoch 28/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7614 - accuracy: 0.6686 - val_loss: 0.7776 - val_accuracy: 0.6273\n",
      "Epoch 29/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7554 - accuracy: 0.6718 - val_loss: 0.7722 - val_accuracy: 0.6306\n",
      "Epoch 30/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7490 - accuracy: 0.6755 - val_loss: 0.7665 - val_accuracy: 0.6339\n",
      "1689/1689 [==============================] - 1s 810us/step - loss: 0.7665 - accuracy: 0.6339\n",
      "Learning rate: 1e-05, Epoch: 30 Validation accuracy: 0.6339161992073059\n",
      "Tuning learning_rate=0.0001, epochs=10\n",
      "Epoch 1/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9471 - accuracy: 0.5384 - val_loss: 0.8654 - val_accuracy: 0.6186\n",
      "Epoch 2/10\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.8518 - accuracy: 0.6116 - val_loss: 0.8203 - val_accuracy: 0.6146\n",
      "Epoch 3/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7798 - accuracy: 0.6584 - val_loss: 0.7624 - val_accuracy: 0.6429\n",
      "Epoch 4/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7206 - accuracy: 0.6912 - val_loss: 0.7272 - val_accuracy: 0.6621\n",
      "Epoch 5/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6759 - accuracy: 0.7137 - val_loss: 0.7092 - val_accuracy: 0.6685\n",
      "Epoch 6/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6422 - accuracy: 0.7280 - val_loss: 0.6888 - val_accuracy: 0.6786\n",
      "Epoch 7/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6158 - accuracy: 0.7395 - val_loss: 0.6675 - val_accuracy: 0.6877\n",
      "Epoch 8/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5952 - accuracy: 0.7482 - val_loss: 0.6484 - val_accuracy: 0.6965\n",
      "Epoch 9/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5809 - accuracy: 0.7542 - val_loss: 0.6394 - val_accuracy: 0.7004\n",
      "Epoch 10/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5696 - accuracy: 0.7592 - val_loss: 0.6356 - val_accuracy: 0.7026\n",
      "1689/1689 [==============================] - 1s 809us/step - loss: 0.6356 - accuracy: 0.7026\n",
      "Learning rate: 0.0001, Epoch: 10 Validation accuracy: 0.7025997042655945\n",
      "Tuning learning_rate=0.0001, epochs=20\n",
      "Epoch 1/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9394 - accuracy: 0.5427 - val_loss: 0.8694 - val_accuracy: 0.6045\n",
      "Epoch 2/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8406 - accuracy: 0.6170 - val_loss: 0.8118 - val_accuracy: 0.6133\n",
      "Epoch 3/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7678 - accuracy: 0.6647 - val_loss: 0.7560 - val_accuracy: 0.6416\n",
      "Epoch 4/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7077 - accuracy: 0.6970 - val_loss: 0.7211 - val_accuracy: 0.6575\n",
      "Epoch 5/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6662 - accuracy: 0.7171 - val_loss: 0.6905 - val_accuracy: 0.6700\n",
      "Epoch 6/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6359 - accuracy: 0.7300 - val_loss: 0.6732 - val_accuracy: 0.6775\n",
      "Epoch 7/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6137 - accuracy: 0.7399 - val_loss: 0.6603 - val_accuracy: 0.6831\n",
      "Epoch 8/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5978 - accuracy: 0.7464 - val_loss: 0.6576 - val_accuracy: 0.6857\n",
      "Epoch 9/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5824 - accuracy: 0.7521 - val_loss: 0.6377 - val_accuracy: 0.6947\n",
      "Epoch 10/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5708 - accuracy: 0.7559 - val_loss: 0.6384 - val_accuracy: 0.6955\n",
      "Epoch 11/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5616 - accuracy: 0.7599 - val_loss: 0.6264 - val_accuracy: 0.7010\n",
      "Epoch 12/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5566 - accuracy: 0.7623 - val_loss: 0.6244 - val_accuracy: 0.7017\n",
      "Epoch 13/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5491 - accuracy: 0.7646 - val_loss: 0.6176 - val_accuracy: 0.7042\n",
      "Epoch 14/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5435 - accuracy: 0.7670 - val_loss: 0.6166 - val_accuracy: 0.7059\n",
      "Epoch 15/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5389 - accuracy: 0.7683 - val_loss: 0.6096 - val_accuracy: 0.7074\n",
      "Epoch 16/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5356 - accuracy: 0.7697 - val_loss: 0.6093 - val_accuracy: 0.7090\n",
      "Epoch 17/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5321 - accuracy: 0.7707 - val_loss: 0.6036 - val_accuracy: 0.7109\n",
      "Epoch 18/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5275 - accuracy: 0.7723 - val_loss: 0.6040 - val_accuracy: 0.7112\n",
      "Epoch 19/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5246 - accuracy: 0.7740 - val_loss: 0.5943 - val_accuracy: 0.7165\n",
      "Epoch 20/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5228 - accuracy: 0.7739 - val_loss: 0.6005 - val_accuracy: 0.7144\n",
      "1689/1689 [==============================] - 1s 789us/step - loss: 0.6005 - accuracy: 0.7144\n",
      "Learning rate: 0.0001, Epoch: 20 Validation accuracy: 0.7143861651420593\n",
      "Tuning learning_rate=0.0001, epochs=30\n",
      "Epoch 1/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9484 - accuracy: 0.5385 - val_loss: 0.8770 - val_accuracy: 0.6056\n",
      "Epoch 2/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8536 - accuracy: 0.6095 - val_loss: 0.8112 - val_accuracy: 0.6206\n",
      "Epoch 3/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7761 - accuracy: 0.6591 - val_loss: 0.7572 - val_accuracy: 0.6393\n",
      "Epoch 4/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7188 - accuracy: 0.6898 - val_loss: 0.7224 - val_accuracy: 0.6576\n",
      "Epoch 5/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6782 - accuracy: 0.7111 - val_loss: 0.6977 - val_accuracy: 0.6681\n",
      "Epoch 6/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6467 - accuracy: 0.7255 - val_loss: 0.6828 - val_accuracy: 0.6730\n",
      "Epoch 7/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6229 - accuracy: 0.7348 - val_loss: 0.6652 - val_accuracy: 0.6808\n",
      "Epoch 8/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6048 - accuracy: 0.7424 - val_loss: 0.6541 - val_accuracy: 0.6863\n",
      "Epoch 9/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5904 - accuracy: 0.7482 - val_loss: 0.6429 - val_accuracy: 0.6918\n",
      "Epoch 10/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5780 - accuracy: 0.7538 - val_loss: 0.6338 - val_accuracy: 0.6967\n",
      "Epoch 11/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5688 - accuracy: 0.7565 - val_loss: 0.6288 - val_accuracy: 0.6985\n",
      "Epoch 12/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5599 - accuracy: 0.7606 - val_loss: 0.6198 - val_accuracy: 0.7045\n",
      "Epoch 13/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5513 - accuracy: 0.7636 - val_loss: 0.6171 - val_accuracy: 0.7053\n",
      "Epoch 14/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5451 - accuracy: 0.7659 - val_loss: 0.6106 - val_accuracy: 0.7075\n",
      "Epoch 15/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5394 - accuracy: 0.7682 - val_loss: 0.6119 - val_accuracy: 0.7077\n",
      "Epoch 16/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5348 - accuracy: 0.7704 - val_loss: 0.6104 - val_accuracy: 0.7085\n",
      "Epoch 17/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5293 - accuracy: 0.7722 - val_loss: 0.6041 - val_accuracy: 0.7118\n",
      "Epoch 18/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5252 - accuracy: 0.7734 - val_loss: 0.5993 - val_accuracy: 0.7140\n",
      "Epoch 19/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5219 - accuracy: 0.7752 - val_loss: 0.5953 - val_accuracy: 0.7156\n",
      "Epoch 20/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5180 - accuracy: 0.7757 - val_loss: 0.5887 - val_accuracy: 0.7186\n",
      "Epoch 21/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5151 - accuracy: 0.7767 - val_loss: 0.5904 - val_accuracy: 0.7173\n",
      "Epoch 22/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5125 - accuracy: 0.7780 - val_loss: 0.5875 - val_accuracy: 0.7185\n",
      "Epoch 23/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5105 - accuracy: 0.7785 - val_loss: 0.5929 - val_accuracy: 0.7164\n",
      "Epoch 24/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5094 - accuracy: 0.7788 - val_loss: 0.5850 - val_accuracy: 0.7196\n",
      "Epoch 25/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5052 - accuracy: 0.7797 - val_loss: 0.5832 - val_accuracy: 0.7203\n",
      "Epoch 26/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5035 - accuracy: 0.7804 - val_loss: 0.5808 - val_accuracy: 0.7213\n",
      "Epoch 27/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5020 - accuracy: 0.7815 - val_loss: 0.5819 - val_accuracy: 0.7206\n",
      "Epoch 28/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5012 - accuracy: 0.7819 - val_loss: 0.5854 - val_accuracy: 0.7198\n",
      "Epoch 29/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4971 - accuracy: 0.7837 - val_loss: 0.5775 - val_accuracy: 0.7229\n",
      "Epoch 30/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4978 - accuracy: 0.7830 - val_loss: 0.5747 - val_accuracy: 0.7240\n",
      "1689/1689 [==============================] - 1s 789us/step - loss: 0.5747 - accuracy: 0.7240\n",
      "Learning rate: 0.0001, Epoch: 30 Validation accuracy: 0.7240262627601624\n",
      "Tuning learning_rate=0.001, epochs=10\n",
      "Epoch 1/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7227 - accuracy: 0.6801 - val_loss: 0.6808 - val_accuracy: 0.6684\n",
      "Epoch 2/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5786 - accuracy: 0.7502 - val_loss: 0.6359 - val_accuracy: 0.6946\n",
      "Epoch 3/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5496 - accuracy: 0.7618 - val_loss: 0.6102 - val_accuracy: 0.7045\n",
      "Epoch 4/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5373 - accuracy: 0.7667 - val_loss: 0.6118 - val_accuracy: 0.7030\n",
      "Epoch 5/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5284 - accuracy: 0.7694 - val_loss: 0.6075 - val_accuracy: 0.7085\n",
      "Epoch 6/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5239 - accuracy: 0.7717 - val_loss: 0.6153 - val_accuracy: 0.7054\n",
      "Epoch 7/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5187 - accuracy: 0.7732 - val_loss: 0.5871 - val_accuracy: 0.7150\n",
      "Epoch 8/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5143 - accuracy: 0.7757 - val_loss: 0.5944 - val_accuracy: 0.7136\n",
      "Epoch 9/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5104 - accuracy: 0.7767 - val_loss: 0.5900 - val_accuracy: 0.7154\n",
      "Epoch 10/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5094 - accuracy: 0.7769 - val_loss: 0.5906 - val_accuracy: 0.7135\n",
      "1689/1689 [==============================] - 1s 794us/step - loss: 0.5871 - accuracy: 0.7150\n",
      "Learning rate: 0.001, Epoch: 10 Validation accuracy: 0.715033769607544\n",
      "Tuning learning_rate=0.001, epochs=20\n",
      "Epoch 1/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7227 - accuracy: 0.6809 - val_loss: 0.6798 - val_accuracy: 0.6743\n",
      "Epoch 2/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5819 - accuracy: 0.7500 - val_loss: 0.6164 - val_accuracy: 0.7029\n",
      "Epoch 3/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5507 - accuracy: 0.7618 - val_loss: 0.6006 - val_accuracy: 0.7109\n",
      "Epoch 4/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5364 - accuracy: 0.7679 - val_loss: 0.5951 - val_accuracy: 0.7167\n",
      "Epoch 5/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5301 - accuracy: 0.7706 - val_loss: 0.6067 - val_accuracy: 0.7098\n",
      "Epoch 6/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5220 - accuracy: 0.7730 - val_loss: 0.6041 - val_accuracy: 0.7130\n",
      "Epoch 7/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5162 - accuracy: 0.7755 - val_loss: 0.5832 - val_accuracy: 0.7217\n",
      "Epoch 8/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5138 - accuracy: 0.7763 - val_loss: 0.5927 - val_accuracy: 0.7172\n",
      "Epoch 9/20\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5115 - accuracy: 0.7772 - val_loss: 0.5765 - val_accuracy: 0.7211\n",
      "Epoch 10/20\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.5079 - accuracy: 0.7781 - val_loss: 0.5745 - val_accuracy: 0.7233\n",
      "Epoch 11/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5069 - accuracy: 0.7789 - val_loss: 0.5724 - val_accuracy: 0.7236\n",
      "Epoch 12/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5018 - accuracy: 0.7799 - val_loss: 0.5748 - val_accuracy: 0.7243\n",
      "Epoch 13/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5025 - accuracy: 0.7802 - val_loss: 0.5797 - val_accuracy: 0.7233\n",
      "Epoch 14/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5016 - accuracy: 0.7802 - val_loss: 0.5683 - val_accuracy: 0.7281\n",
      "Epoch 15/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5002 - accuracy: 0.7813 - val_loss: 0.5685 - val_accuracy: 0.7260\n",
      "Epoch 16/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4980 - accuracy: 0.7823 - val_loss: 0.5680 - val_accuracy: 0.7252\n",
      "Epoch 17/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4978 - accuracy: 0.7816 - val_loss: 0.5665 - val_accuracy: 0.7281\n",
      "Epoch 18/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4967 - accuracy: 0.7821 - val_loss: 0.5756 - val_accuracy: 0.7232\n",
      "Epoch 19/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4976 - accuracy: 0.7819 - val_loss: 0.5566 - val_accuracy: 0.7299\n",
      "Epoch 20/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4950 - accuracy: 0.7821 - val_loss: 0.5660 - val_accuracy: 0.7276\n",
      "1689/1689 [==============================] - 1s 798us/step - loss: 0.5660 - accuracy: 0.7276\n",
      "Learning rate: 0.001, Epoch: 20 Validation accuracy: 0.7275603413581848\n",
      "Tuning learning_rate=0.001, epochs=30\n",
      "Epoch 1/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7156 - accuracy: 0.6850 - val_loss: 0.6745 - val_accuracy: 0.6764\n",
      "Epoch 2/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5693 - accuracy: 0.7537 - val_loss: 0.6274 - val_accuracy: 0.6974\n",
      "Epoch 3/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5430 - accuracy: 0.7650 - val_loss: 0.6135 - val_accuracy: 0.7037\n",
      "Epoch 4/30\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5291 - accuracy: 0.7695 - val_loss: 0.5961 - val_accuracy: 0.7105\n",
      "Epoch 5/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5215 - accuracy: 0.7728 - val_loss: 0.5948 - val_accuracy: 0.7128\n",
      "Epoch 6/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5161 - accuracy: 0.7751 - val_loss: 0.5849 - val_accuracy: 0.7156\n",
      "Epoch 7/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5115 - accuracy: 0.7755 - val_loss: 0.5910 - val_accuracy: 0.7148\n",
      "Epoch 8/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5088 - accuracy: 0.7768 - val_loss: 0.5745 - val_accuracy: 0.7218\n",
      "Epoch 9/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5053 - accuracy: 0.7777 - val_loss: 0.5876 - val_accuracy: 0.7166\n",
      "Epoch 10/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5029 - accuracy: 0.7786 - val_loss: 0.5790 - val_accuracy: 0.7170\n",
      "Epoch 11/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5010 - accuracy: 0.7798 - val_loss: 0.5798 - val_accuracy: 0.7195\n",
      "1689/1689 [==============================] - 1s 812us/step - loss: 0.5745 - accuracy: 0.7218\n",
      "Learning rate: 0.001, Epoch: 30 Validation accuracy: 0.7218244075775146\n",
      "Tuning learning_rate=0.01, epochs=10\n",
      "Epoch 1/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7896 - accuracy: 0.6440 - val_loss: 0.7732 - val_accuracy: 0.5973\n",
      "Epoch 2/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7249 - accuracy: 0.6781 - val_loss: 0.7273 - val_accuracy: 0.6372\n",
      "Epoch 3/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7089 - accuracy: 0.6836 - val_loss: 0.7531 - val_accuracy: 0.5976\n",
      "Epoch 4/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7083 - accuracy: 0.6834 - val_loss: 0.7216 - val_accuracy: 0.6253\n",
      "Epoch 5/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7000 - accuracy: 0.6866 - val_loss: 0.7223 - val_accuracy: 0.6274\n",
      "Epoch 6/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6974 - accuracy: 0.6857 - val_loss: 0.6895 - val_accuracy: 0.6310\n",
      "Epoch 7/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6970 - accuracy: 0.6870 - val_loss: 0.7166 - val_accuracy: 0.6226\n",
      "Epoch 8/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6970 - accuracy: 0.6871 - val_loss: 0.7363 - val_accuracy: 0.6123\n",
      "Epoch 9/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6937 - accuracy: 0.6873 - val_loss: 0.6712 - val_accuracy: 0.6589\n",
      "Epoch 10/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6922 - accuracy: 0.6886 - val_loss: 0.7026 - val_accuracy: 0.6421\n",
      "1689/1689 [==============================] - 1s 803us/step - loss: 0.7026 - accuracy: 0.6421\n",
      "Learning rate: 0.01, Epoch: 10 Validation accuracy: 0.6421130299568176\n",
      "Tuning learning_rate=0.01, epochs=20\n",
      "Epoch 1/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7908 - accuracy: 0.6412 - val_loss: 0.7413 - val_accuracy: 0.6146\n",
      "Epoch 2/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7270 - accuracy: 0.6770 - val_loss: 0.7487 - val_accuracy: 0.6173\n",
      "Epoch 3/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7191 - accuracy: 0.6809 - val_loss: 0.6969 - val_accuracy: 0.6370\n",
      "Epoch 4/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7105 - accuracy: 0.6851 - val_loss: 0.7153 - val_accuracy: 0.6257\n",
      "Epoch 5/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7033 - accuracy: 0.6885 - val_loss: 0.7147 - val_accuracy: 0.6225\n",
      "Epoch 6/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7001 - accuracy: 0.6893 - val_loss: 0.7322 - val_accuracy: 0.6206\n",
      "1689/1689 [==============================] - 1s 799us/step - loss: 0.6969 - accuracy: 0.6370\n",
      "Learning rate: 0.01, Epoch: 20 Validation accuracy: 0.6369876861572266\n",
      "Tuning learning_rate=0.01, epochs=30\n",
      "Epoch 1/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7918 - accuracy: 0.6412 - val_loss: 0.7257 - val_accuracy: 0.6290\n",
      "Epoch 2/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7286 - accuracy: 0.6765 - val_loss: 0.7646 - val_accuracy: 0.5881\n",
      "Epoch 3/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7178 - accuracy: 0.6815 - val_loss: 0.7491 - val_accuracy: 0.6063\n",
      "Epoch 4/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7109 - accuracy: 0.6862 - val_loss: 0.7331 - val_accuracy: 0.6222\n",
      "1689/1689 [==============================] - 1s 783us/step - loss: 0.7257 - accuracy: 0.6290\n",
      "Learning rate: 0.01, Epoch: 30 Validation accuracy: 0.6289758682250977\n",
      "Tuning learning_rate=0.1, epochs=10\n",
      "Epoch 1/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1148 - accuracy: 0.3347 - val_loss: 1.0155 - val_accuracy: 0.5082\n",
      "Epoch 2/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1043 - accuracy: 0.3364 - val_loss: 1.1847 - val_accuracy: 0.0130\n",
      "Epoch 3/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1166 - accuracy: 0.3356 - val_loss: 1.1221 - val_accuracy: 0.0130\n",
      "Epoch 4/10\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1040 - accuracy: 0.3355 - val_loss: 1.1919 - val_accuracy: 0.0130\n",
      "1689/1689 [==============================] - 1s 809us/step - loss: 1.0155 - accuracy: 0.5082\n",
      "Learning rate: 0.1, Epoch: 10 Validation accuracy: 0.5081691145896912\n",
      "Tuning learning_rate=0.1, epochs=20\n",
      "Epoch 1/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1153 - accuracy: 0.3352 - val_loss: 1.0744 - val_accuracy: 0.5082\n",
      "Epoch 2/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1167 - accuracy: 0.3359 - val_loss: 1.1257 - val_accuracy: 0.5082\n",
      "Epoch 3/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1062 - accuracy: 0.3370 - val_loss: 1.1807 - val_accuracy: 0.0130\n",
      "Epoch 4/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1041 - accuracy: 0.3347 - val_loss: 1.1487 - val_accuracy: 0.0130\n",
      "1689/1689 [==============================] - 1s 794us/step - loss: 1.0744 - accuracy: 0.5082\n",
      "Learning rate: 0.1, Epoch: 20 Validation accuracy: 0.5081691145896912\n",
      "Tuning learning_rate=0.1, epochs=30\n",
      "Epoch 1/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1141 - accuracy: 0.3362 - val_loss: 1.0800 - val_accuracy: 0.5082\n",
      "Epoch 2/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1098 - accuracy: 0.3353 - val_loss: 1.0808 - val_accuracy: 0.5082\n",
      "Epoch 3/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1239 - accuracy: 0.3345 - val_loss: 1.0975 - val_accuracy: 0.5082\n",
      "Epoch 4/30\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 1.1061 - accuracy: 0.3360 - val_loss: 1.1852 - val_accuracy: 0.0130\n",
      "1689/1689 [==============================] - 1s 811us/step - loss: 1.0800 - accuracy: 0.5082\n",
      "Learning rate: 0.1, Epoch: 30 Validation accuracy: 0.5081691145896912\n",
      "Epoch 1/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7200 - accuracy: 0.6823 - val_loss: 0.6631 - val_accuracy: 0.6837\n",
      "Epoch 2/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5740 - accuracy: 0.7538 - val_loss: 0.6359 - val_accuracy: 0.6975\n",
      "Epoch 3/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5452 - accuracy: 0.7643 - val_loss: 0.6156 - val_accuracy: 0.7096\n",
      "Epoch 4/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5327 - accuracy: 0.7693 - val_loss: 0.6117 - val_accuracy: 0.7075\n",
      "Epoch 5/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5233 - accuracy: 0.7724 - val_loss: 0.5948 - val_accuracy: 0.7163\n",
      "Epoch 6/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5187 - accuracy: 0.7737 - val_loss: 0.5951 - val_accuracy: 0.7110\n",
      "Epoch 7/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5161 - accuracy: 0.7757 - val_loss: 0.5878 - val_accuracy: 0.7163\n",
      "Epoch 8/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5118 - accuracy: 0.7762 - val_loss: 0.5945 - val_accuracy: 0.7138\n",
      "Epoch 9/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5091 - accuracy: 0.7772 - val_loss: 0.5744 - val_accuracy: 0.7215\n",
      "Epoch 10/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5063 - accuracy: 0.7784 - val_loss: 0.5675 - val_accuracy: 0.7236\n",
      "Epoch 11/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5053 - accuracy: 0.7784 - val_loss: 0.5806 - val_accuracy: 0.7180\n",
      "Epoch 12/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5032 - accuracy: 0.7794 - val_loss: 0.5719 - val_accuracy: 0.7223\n",
      "Epoch 13/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5017 - accuracy: 0.7804 - val_loss: 0.5801 - val_accuracy: 0.7183\n",
      "Epoch 14/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4977 - accuracy: 0.7822 - val_loss: 0.5751 - val_accuracy: 0.7210\n",
      "Epoch 15/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4982 - accuracy: 0.7807 - val_loss: 0.5847 - val_accuracy: 0.7157\n",
      "Epoch 16/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4959 - accuracy: 0.7818 - val_loss: 0.5643 - val_accuracy: 0.7246\n",
      "Epoch 17/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4956 - accuracy: 0.7821 - val_loss: 0.5671 - val_accuracy: 0.7227\n",
      "Epoch 18/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4943 - accuracy: 0.7837 - val_loss: 0.5638 - val_accuracy: 0.7262\n",
      "Epoch 19/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4932 - accuracy: 0.7829 - val_loss: 0.5692 - val_accuracy: 0.7247\n",
      "Epoch 20/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4916 - accuracy: 0.7840 - val_loss: 0.5662 - val_accuracy: 0.7230\n",
      "Learning rate: 0.001, Best epochs: 20\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assuming you have X_train, y_train, X_val, y_val as your data splits\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def create_model(learning_rate):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu', input_shape=(input_dim,)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Set hyperparameter values to tune\n",
    "learning_rates = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "epochs_values = [100]\n",
    "\n",
    "# Assuming input_dim is the size of your input features\n",
    "input_dim = X_ss_train.shape[1]\n",
    "\n",
    "# Iterate over hyperparameters\n",
    "for learning_rate in learning_rates:\n",
    "    for epochs_value in epochs_values:\n",
    "        print(f'Tuning learning_rate={learning_rate}, epochs={epochs_value}')\n",
    "        \n",
    "        # Create and compile the model\n",
    "        model = create_model(learning_rate)\n",
    "        \n",
    "        # Use early stopping to prevent overfitting\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(X_ss_train, y_ss_train, epochs=epochs_value, batch_size=32,\n",
    "                            validation_data=(X_ss_val, y_ss_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Evaluate on the validation set\n",
    "        val_loss, val_acc = model.evaluate(X_ss_val, y_ss_val)\n",
    "        print(f'Learning rate: {learning_rate}, Epoch: {epochs_value} Validation accuracy: {val_acc}')\n",
    "\n",
    "        if val_acc> best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_learning_rate = learning_rate\n",
    "            best_epochs = epochs_value\n",
    "\n",
    "# Choose the best hyperparameters based on validation performance\n",
    "# Train the final model with the selected hyperparameters\n",
    "final_model = create_model(learning_rate=best_learning_rate)\n",
    "final_history = final_model.fit(X_ss_train, y_ss_train, epochs=best_epochs, batch_size=32, validation_data=(X_ss_val, y_ss_val))\n",
    "print(f'Learning rate: {best_learning_rate}, Best epochs: {best_epochs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is the object returned by model.fit()\n",
    "plt.plot(final_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(final_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7294 - accuracy: 0.6762 - val_loss: 0.6816 - val_accuracy: 0.6677\n",
      "Epoch 2/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5811 - accuracy: 0.7504 - val_loss: 0.6259 - val_accuracy: 0.6959\n",
      "Epoch 3/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5506 - accuracy: 0.7623 - val_loss: 0.6263 - val_accuracy: 0.6993\n",
      "Epoch 4/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5367 - accuracy: 0.7674 - val_loss: 0.5967 - val_accuracy: 0.7118\n",
      "Epoch 5/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5276 - accuracy: 0.7713 - val_loss: 0.6049 - val_accuracy: 0.7097\n",
      "Epoch 6/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5210 - accuracy: 0.7733 - val_loss: 0.5833 - val_accuracy: 0.7197\n",
      "Epoch 7/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5152 - accuracy: 0.7763 - val_loss: 0.5920 - val_accuracy: 0.7174\n",
      "Epoch 8/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5121 - accuracy: 0.7775 - val_loss: 0.5888 - val_accuracy: 0.7193\n",
      "Epoch 9/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5108 - accuracy: 0.7779 - val_loss: 0.5896 - val_accuracy: 0.7200\n",
      "Epoch 10/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5074 - accuracy: 0.7792 - val_loss: 0.5818 - val_accuracy: 0.7194\n",
      "Epoch 11/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5049 - accuracy: 0.7794 - val_loss: 0.5779 - val_accuracy: 0.7199\n",
      "Epoch 12/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5044 - accuracy: 0.7805 - val_loss: 0.5824 - val_accuracy: 0.7223\n",
      "Epoch 13/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5037 - accuracy: 0.7808 - val_loss: 0.5716 - val_accuracy: 0.7240\n",
      "Epoch 14/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5004 - accuracy: 0.7815 - val_loss: 0.5736 - val_accuracy: 0.7220\n",
      "Epoch 15/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4993 - accuracy: 0.7820 - val_loss: 0.5733 - val_accuracy: 0.7259\n",
      "Epoch 16/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4970 - accuracy: 0.7831 - val_loss: 0.5691 - val_accuracy: 0.7243\n",
      "Epoch 17/20\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4970 - accuracy: 0.7819 - val_loss: 0.5743 - val_accuracy: 0.7228\n",
      "Epoch 18/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4958 - accuracy: 0.7829 - val_loss: 0.5728 - val_accuracy: 0.7243\n",
      "Epoch 19/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4940 - accuracy: 0.7834 - val_loss: 0.5640 - val_accuracy: 0.7281\n",
      "Epoch 20/20\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4921 - accuracy: 0.7839 - val_loss: 0.5798 - val_accuracy: 0.7248\n",
      "Learning rate: 0.001, Best epochs: 20\n"
     ]
    }
   ],
   "source": [
    "final_model = create_model(learning_rate=best_learning_rate)\n",
    "final_history = final_model.fit(X_ss_train, y_ss_train, epochs=best_epochs, batch_size=32, validation_data=(X_ss_val, y_ss_val))\n",
    "print(f'Learning rate: {best_learning_rate}, Best epochs: {best_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845/845 [==============================] - 1s 780us/step - loss: 0.5788 - accuracy: 0.7277\n",
      "Test accuracy: 0.7277403473854065\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = final_model.evaluate(X_ss_test, y_ss_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/#:~:text=in%20general%2C%20it%20is%20not,greater%20than%2010%5E%2D6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should I use categorical crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW ATTEMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 1 hidden layers, 64 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.9281 - accuracy: 0.5528 - val_loss: 0.8773 - val_accuracy: 0.6238\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8614 - accuracy: 0.6060 - val_loss: 0.8503 - val_accuracy: 0.6279\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8235 - accuracy: 0.6327 - val_loss: 0.8180 - val_accuracy: 0.6427\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7956 - accuracy: 0.6519 - val_loss: 0.8063 - val_accuracy: 0.6431\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7742 - accuracy: 0.6661 - val_loss: 0.7873 - val_accuracy: 0.6497\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7555 - accuracy: 0.6779 - val_loss: 0.7753 - val_accuracy: 0.6532\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7390 - accuracy: 0.6863 - val_loss: 0.7573 - val_accuracy: 0.6637\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7237 - accuracy: 0.6932 - val_loss: 0.7538 - val_accuracy: 0.6638\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7145 - accuracy: 0.6973 - val_loss: 0.7475 - val_accuracy: 0.6654\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7054 - accuracy: 0.7013 - val_loss: 0.7301 - val_accuracy: 0.6754\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6991 - accuracy: 0.7044 - val_loss: 0.7361 - val_accuracy: 0.6693\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6906 - accuracy: 0.7083 - val_loss: 0.7243 - val_accuracy: 0.6757\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6866 - accuracy: 0.7095 - val_loss: 0.7171 - val_accuracy: 0.6797\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6800 - accuracy: 0.7119 - val_loss: 0.7175 - val_accuracy: 0.6767\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6772 - accuracy: 0.7129 - val_loss: 0.7049 - val_accuracy: 0.6825\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6722 - accuracy: 0.7154 - val_loss: 0.7070 - val_accuracy: 0.6812\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6690 - accuracy: 0.7170 - val_loss: 0.7076 - val_accuracy: 0.6806\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6647 - accuracy: 0.7177 - val_loss: 0.7077 - val_accuracy: 0.6796\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6601 - accuracy: 0.7201 - val_loss: 0.6997 - val_accuracy: 0.6834\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6580 - accuracy: 0.7207 - val_loss: 0.6951 - val_accuracy: 0.6845\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6532 - accuracy: 0.7230 - val_loss: 0.6936 - val_accuracy: 0.6861\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6512 - accuracy: 0.7234 - val_loss: 0.7028 - val_accuracy: 0.6797\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6501 - accuracy: 0.7248 - val_loss: 0.6958 - val_accuracy: 0.6849\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6470 - accuracy: 0.7253 - val_loss: 0.6942 - val_accuracy: 0.6853\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6441 - accuracy: 0.7272 - val_loss: 0.6879 - val_accuracy: 0.6894\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6439 - accuracy: 0.7273 - val_loss: 0.6949 - val_accuracy: 0.6843\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6409 - accuracy: 0.7284 - val_loss: 0.6878 - val_accuracy: 0.6878\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6380 - accuracy: 0.7307 - val_loss: 0.6822 - val_accuracy: 0.6904\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6369 - accuracy: 0.7311 - val_loss: 0.6858 - val_accuracy: 0.6890\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6345 - accuracy: 0.7320 - val_loss: 0.6873 - val_accuracy: 0.6891\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6323 - accuracy: 0.7339 - val_loss: 0.6785 - val_accuracy: 0.6940\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6295 - accuracy: 0.7347 - val_loss: 0.6852 - val_accuracy: 0.6900\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6266 - accuracy: 0.7377 - val_loss: 0.6834 - val_accuracy: 0.6909\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6254 - accuracy: 0.7372 - val_loss: 0.6815 - val_accuracy: 0.6905\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6217 - accuracy: 0.7387 - val_loss: 0.6756 - val_accuracy: 0.6936\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6201 - accuracy: 0.7395 - val_loss: 0.6736 - val_accuracy: 0.6932\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6177 - accuracy: 0.7403 - val_loss: 0.6716 - val_accuracy: 0.6948\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6149 - accuracy: 0.7427 - val_loss: 0.6725 - val_accuracy: 0.6941\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6140 - accuracy: 0.7427 - val_loss: 0.6701 - val_accuracy: 0.6947\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6122 - accuracy: 0.7439 - val_loss: 0.6686 - val_accuracy: 0.6948\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6090 - accuracy: 0.7450 - val_loss: 0.6695 - val_accuracy: 0.6956\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6090 - accuracy: 0.7451 - val_loss: 0.6621 - val_accuracy: 0.6983\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6075 - accuracy: 0.7448 - val_loss: 0.6667 - val_accuracy: 0.6961\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6062 - accuracy: 0.7459 - val_loss: 0.6630 - val_accuracy: 0.6968\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6056 - accuracy: 0.7463 - val_loss: 0.6626 - val_accuracy: 0.6980\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6034 - accuracy: 0.7477 - val_loss: 0.6608 - val_accuracy: 0.6972\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6024 - accuracy: 0.7474 - val_loss: 0.6620 - val_accuracy: 0.6962\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6015 - accuracy: 0.7490 - val_loss: 0.6647 - val_accuracy: 0.6962\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6006 - accuracy: 0.7481 - val_loss: 0.6597 - val_accuracy: 0.6980\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6000 - accuracy: 0.7480 - val_loss: 0.6567 - val_accuracy: 0.6982\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5994 - accuracy: 0.7488 - val_loss: 0.6596 - val_accuracy: 0.6976\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5986 - accuracy: 0.7495 - val_loss: 0.6569 - val_accuracy: 0.6994\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5970 - accuracy: 0.7495 - val_loss: 0.6621 - val_accuracy: 0.6974\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5966 - accuracy: 0.7505 - val_loss: 0.6551 - val_accuracy: 0.6995\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5974 - accuracy: 0.7505 - val_loss: 0.6589 - val_accuracy: 0.6975\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5959 - accuracy: 0.7510 - val_loss: 0.6574 - val_accuracy: 0.6977\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5960 - accuracy: 0.7504 - val_loss: 0.6528 - val_accuracy: 0.6995\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5950 - accuracy: 0.7508 - val_loss: 0.6564 - val_accuracy: 0.6984\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5943 - accuracy: 0.7512 - val_loss: 0.6594 - val_accuracy: 0.6965\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5964 - accuracy: 0.7495 - val_loss: 0.6504 - val_accuracy: 0.6999\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5946 - accuracy: 0.7511 - val_loss: 0.6578 - val_accuracy: 0.6970\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5944 - accuracy: 0.7517 - val_loss: 0.6604 - val_accuracy: 0.6957\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5931 - accuracy: 0.7516 - val_loss: 0.6539 - val_accuracy: 0.6987\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5924 - accuracy: 0.7518 - val_loss: 0.6463 - val_accuracy: 0.7022\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5917 - accuracy: 0.7522 - val_loss: 0.6455 - val_accuracy: 0.7034\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5910 - accuracy: 0.7516 - val_loss: 0.6502 - val_accuracy: 0.7003\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5917 - accuracy: 0.7519 - val_loss: 0.6487 - val_accuracy: 0.7018\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5906 - accuracy: 0.7523 - val_loss: 0.6504 - val_accuracy: 0.7011\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5899 - accuracy: 0.7530 - val_loss: 0.6502 - val_accuracy: 0.7006\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5898 - accuracy: 0.7528 - val_loss: 0.6535 - val_accuracy: 0.6990\n",
      "Early stopped after 70 epochs.\n",
      "1689/1689 [==============================] - 1s 773us/step - loss: 0.6455 - accuracy: 0.7034\n",
      "Validation accuracy: 0.7033582925796509\n",
      "\n",
      "Training model with 1 hidden layers, 64 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7941 - accuracy: 0.6483 - val_loss: 0.7533 - val_accuracy: 0.6603\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6785 - accuracy: 0.7109 - val_loss: 0.7066 - val_accuracy: 0.6783\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6383 - accuracy: 0.7297 - val_loss: 0.6555 - val_accuracy: 0.6994\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6159 - accuracy: 0.7405 - val_loss: 0.6541 - val_accuracy: 0.6965\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6024 - accuracy: 0.7461 - val_loss: 0.6570 - val_accuracy: 0.6943\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5941 - accuracy: 0.7490 - val_loss: 0.6497 - val_accuracy: 0.7005\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5862 - accuracy: 0.7522 - val_loss: 0.6535 - val_accuracy: 0.6959\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5814 - accuracy: 0.7543 - val_loss: 0.6506 - val_accuracy: 0.6993\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5737 - accuracy: 0.7580 - val_loss: 0.6438 - val_accuracy: 0.7013\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5693 - accuracy: 0.7600 - val_loss: 0.6272 - val_accuracy: 0.7075\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5669 - accuracy: 0.7609 - val_loss: 0.6445 - val_accuracy: 0.7007\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5644 - accuracy: 0.7622 - val_loss: 0.6365 - val_accuracy: 0.7030\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5635 - accuracy: 0.7623 - val_loss: 0.6351 - val_accuracy: 0.7031\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5607 - accuracy: 0.7636 - val_loss: 0.6245 - val_accuracy: 0.7073\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5607 - accuracy: 0.7637 - val_loss: 0.6186 - val_accuracy: 0.7091\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5579 - accuracy: 0.7650 - val_loss: 0.6330 - val_accuracy: 0.7053\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5569 - accuracy: 0.7652 - val_loss: 0.6262 - val_accuracy: 0.7059\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5551 - accuracy: 0.7653 - val_loss: 0.6194 - val_accuracy: 0.7096\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5544 - accuracy: 0.7656 - val_loss: 0.6211 - val_accuracy: 0.7095\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5546 - accuracy: 0.7659 - val_loss: 0.6305 - val_accuracy: 0.7058\n",
      "Early stopped after 20 epochs.\n",
      "1689/1689 [==============================] - 1s 759us/step - loss: 0.6186 - accuracy: 0.7091\n",
      "Validation accuracy: 0.7091313004493713\n",
      "\n",
      "Training model with 1 hidden layers, 64 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6715 - accuracy: 0.7123 - val_loss: 0.6968 - val_accuracy: 0.6727\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5972 - accuracy: 0.7479 - val_loss: 0.6627 - val_accuracy: 0.6914\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5784 - accuracy: 0.7559 - val_loss: 0.6130 - val_accuracy: 0.7146\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5699 - accuracy: 0.7600 - val_loss: 0.6155 - val_accuracy: 0.7111\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5670 - accuracy: 0.7614 - val_loss: 0.6787 - val_accuracy: 0.6889\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5645 - accuracy: 0.7629 - val_loss: 0.6295 - val_accuracy: 0.7109\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5618 - accuracy: 0.7636 - val_loss: 0.6347 - val_accuracy: 0.7116\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.5598 - accuracy: 0.7657 - val_loss: 0.6491 - val_accuracy: 0.7007\n",
      "Early stopped after 8 epochs.\n",
      "1689/1689 [==============================] - 1s 762us/step - loss: 0.6130 - accuracy: 0.7146\n",
      "Validation accuracy: 0.7146081924438477\n",
      "\n",
      "Training model with 1 hidden layers, 64 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.9710 - accuracy: 0.5199 - val_loss: 0.8892 - val_accuracy: 0.6219\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.9039 - accuracy: 0.5754 - val_loss: 0.8714 - val_accuracy: 0.6277\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.8769 - accuracy: 0.5938 - val_loss: 0.8583 - val_accuracy: 0.6260\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8576 - accuracy: 0.6078 - val_loss: 0.8376 - val_accuracy: 0.6303\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8422 - accuracy: 0.6180 - val_loss: 0.8273 - val_accuracy: 0.6343\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.8278 - accuracy: 0.6285 - val_loss: 0.8122 - val_accuracy: 0.6382\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.8160 - accuracy: 0.6366 - val_loss: 0.8056 - val_accuracy: 0.6401\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.8070 - accuracy: 0.6437 - val_loss: 0.7964 - val_accuracy: 0.6426\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7982 - accuracy: 0.6491 - val_loss: 0.7952 - val_accuracy: 0.6431\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7894 - accuracy: 0.6541 - val_loss: 0.7778 - val_accuracy: 0.6551\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7783 - accuracy: 0.6605 - val_loss: 0.7723 - val_accuracy: 0.6582\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7713 - accuracy: 0.6651 - val_loss: 0.7641 - val_accuracy: 0.6628\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7668 - accuracy: 0.6681 - val_loss: 0.7601 - val_accuracy: 0.6634\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7617 - accuracy: 0.6708 - val_loss: 0.7572 - val_accuracy: 0.6645\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7574 - accuracy: 0.6728 - val_loss: 0.7514 - val_accuracy: 0.6665\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7543 - accuracy: 0.6744 - val_loss: 0.7474 - val_accuracy: 0.6692\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7514 - accuracy: 0.6771 - val_loss: 0.7443 - val_accuracy: 0.6702\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7484 - accuracy: 0.6781 - val_loss: 0.7445 - val_accuracy: 0.6702\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7454 - accuracy: 0.6802 - val_loss: 0.7322 - val_accuracy: 0.6780\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7443 - accuracy: 0.6816 - val_loss: 0.7318 - val_accuracy: 0.6787\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7407 - accuracy: 0.6829 - val_loss: 0.7313 - val_accuracy: 0.6785\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7400 - accuracy: 0.6829 - val_loss: 0.7349 - val_accuracy: 0.6742\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7361 - accuracy: 0.6858 - val_loss: 0.7354 - val_accuracy: 0.6736\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7353 - accuracy: 0.6852 - val_loss: 0.7315 - val_accuracy: 0.6751\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7319 - accuracy: 0.6874 - val_loss: 0.7295 - val_accuracy: 0.6748\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7293 - accuracy: 0.6885 - val_loss: 0.7226 - val_accuracy: 0.6807\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7280 - accuracy: 0.6899 - val_loss: 0.7205 - val_accuracy: 0.6821\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7262 - accuracy: 0.6905 - val_loss: 0.7220 - val_accuracy: 0.6789\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7253 - accuracy: 0.6901 - val_loss: 0.7230 - val_accuracy: 0.6786\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7237 - accuracy: 0.6920 - val_loss: 0.7195 - val_accuracy: 0.6795\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7226 - accuracy: 0.6919 - val_loss: 0.7155 - val_accuracy: 0.6822\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7207 - accuracy: 0.6918 - val_loss: 0.7156 - val_accuracy: 0.6814\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7204 - accuracy: 0.6941 - val_loss: 0.7127 - val_accuracy: 0.6830\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7186 - accuracy: 0.6942 - val_loss: 0.7157 - val_accuracy: 0.6808\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7183 - accuracy: 0.6938 - val_loss: 0.7134 - val_accuracy: 0.6832\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7184 - accuracy: 0.6948 - val_loss: 0.7105 - val_accuracy: 0.6837\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7161 - accuracy: 0.6956 - val_loss: 0.7116 - val_accuracy: 0.6831\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7151 - accuracy: 0.6965 - val_loss: 0.7116 - val_accuracy: 0.6821\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7146 - accuracy: 0.6968 - val_loss: 0.7110 - val_accuracy: 0.6813\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7150 - accuracy: 0.6967 - val_loss: 0.7084 - val_accuracy: 0.6845\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7146 - accuracy: 0.6957 - val_loss: 0.7094 - val_accuracy: 0.6834\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7127 - accuracy: 0.6968 - val_loss: 0.7084 - val_accuracy: 0.6825\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7100 - accuracy: 0.6986 - val_loss: 0.7076 - val_accuracy: 0.6830\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7108 - accuracy: 0.6985 - val_loss: 0.7073 - val_accuracy: 0.6829\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7106 - accuracy: 0.6980 - val_loss: 0.7074 - val_accuracy: 0.6831\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7093 - accuracy: 0.6992 - val_loss: 0.6997 - val_accuracy: 0.6879\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7084 - accuracy: 0.6989 - val_loss: 0.7024 - val_accuracy: 0.6854\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7080 - accuracy: 0.6997 - val_loss: 0.7064 - val_accuracy: 0.6822\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7070 - accuracy: 0.6997 - val_loss: 0.7022 - val_accuracy: 0.6859\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7061 - accuracy: 0.7005 - val_loss: 0.6996 - val_accuracy: 0.6857\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7069 - accuracy: 0.7003 - val_loss: 0.7024 - val_accuracy: 0.6845\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7045 - accuracy: 0.7013 - val_loss: 0.7055 - val_accuracy: 0.6827\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7042 - accuracy: 0.7018 - val_loss: 0.7011 - val_accuracy: 0.6843\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7055 - accuracy: 0.7014 - val_loss: 0.7003 - val_accuracy: 0.6846\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7049 - accuracy: 0.7010 - val_loss: 0.7037 - val_accuracy: 0.6835\n",
      "Early stopped after 55 epochs.\n",
      "1689/1689 [==============================] - 1s 759us/step - loss: 0.6996 - accuracy: 0.6857\n",
      "Validation accuracy: 0.6856508255004883\n",
      "\n",
      "Training model with 1 hidden layers, 64 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8559 - accuracy: 0.6098 - val_loss: 0.8073 - val_accuracy: 0.6327\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7652 - accuracy: 0.6692 - val_loss: 0.7329 - val_accuracy: 0.6763\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7264 - accuracy: 0.6910 - val_loss: 0.7066 - val_accuracy: 0.6846\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7095 - accuracy: 0.6988 - val_loss: 0.7138 - val_accuracy: 0.6787\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7012 - accuracy: 0.7041 - val_loss: 0.7211 - val_accuracy: 0.6694\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6961 - accuracy: 0.7057 - val_loss: 0.6905 - val_accuracy: 0.6897\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6909 - accuracy: 0.7089 - val_loss: 0.6973 - val_accuracy: 0.6819\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6896 - accuracy: 0.7098 - val_loss: 0.6963 - val_accuracy: 0.6828\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6840 - accuracy: 0.7126 - val_loss: 0.6948 - val_accuracy: 0.6832\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6795 - accuracy: 0.7144 - val_loss: 0.6828 - val_accuracy: 0.6888\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6770 - accuracy: 0.7152 - val_loss: 0.6884 - val_accuracy: 0.6861\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6745 - accuracy: 0.7164 - val_loss: 0.6838 - val_accuracy: 0.6858\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6712 - accuracy: 0.7176 - val_loss: 0.6691 - val_accuracy: 0.6956\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6716 - accuracy: 0.7178 - val_loss: 0.6810 - val_accuracy: 0.6912\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6703 - accuracy: 0.7182 - val_loss: 0.6855 - val_accuracy: 0.6863\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6675 - accuracy: 0.7193 - val_loss: 0.6841 - val_accuracy: 0.6877\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6665 - accuracy: 0.7211 - val_loss: 0.6730 - val_accuracy: 0.6926\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6640 - accuracy: 0.7213 - val_loss: 0.6669 - val_accuracy: 0.6952\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6637 - accuracy: 0.7218 - val_loss: 0.6659 - val_accuracy: 0.6967\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6643 - accuracy: 0.7229 - val_loss: 0.6702 - val_accuracy: 0.6942\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6623 - accuracy: 0.7230 - val_loss: 0.6682 - val_accuracy: 0.6949\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6605 - accuracy: 0.7222 - val_loss: 0.6703 - val_accuracy: 0.6935\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6620 - accuracy: 0.7227 - val_loss: 0.6656 - val_accuracy: 0.6985\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6617 - accuracy: 0.7218 - val_loss: 0.6828 - val_accuracy: 0.6866\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6622 - accuracy: 0.7230 - val_loss: 0.6752 - val_accuracy: 0.6910\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6612 - accuracy: 0.7227 - val_loss: 0.6674 - val_accuracy: 0.6954\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6585 - accuracy: 0.7248 - val_loss: 0.6515 - val_accuracy: 0.7036\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6572 - accuracy: 0.7243 - val_loss: 0.6715 - val_accuracy: 0.6912\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6591 - accuracy: 0.7240 - val_loss: 0.6670 - val_accuracy: 0.6943\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6576 - accuracy: 0.7246 - val_loss: 0.6630 - val_accuracy: 0.6968\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6562 - accuracy: 0.7247 - val_loss: 0.6711 - val_accuracy: 0.6908\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.6568 - accuracy: 0.7258 - val_loss: 0.6615 - val_accuracy: 0.6995\n",
      "Early stopped after 32 epochs.\n",
      "1689/1689 [==============================] - 1s 769us/step - loss: 0.6515 - accuracy: 0.7036\n",
      "Validation accuracy: 0.703580379486084\n",
      "\n",
      "Training model with 1 hidden layers, 64 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7843 - accuracy: 0.6541 - val_loss: 0.7420 - val_accuracy: 0.6768\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7303 - accuracy: 0.6864 - val_loss: 0.6929 - val_accuracy: 0.6856\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7206 - accuracy: 0.6913 - val_loss: 0.7039 - val_accuracy: 0.6852\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7152 - accuracy: 0.6962 - val_loss: 0.7090 - val_accuracy: 0.6874\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7116 - accuracy: 0.6968 - val_loss: 0.6792 - val_accuracy: 0.6988\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7103 - accuracy: 0.6983 - val_loss: 0.6815 - val_accuracy: 0.7017\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7084 - accuracy: 0.6990 - val_loss: 0.7257 - val_accuracy: 0.6720\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7055 - accuracy: 0.6997 - val_loss: 0.7049 - val_accuracy: 0.6874\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7034 - accuracy: 0.7010 - val_loss: 0.6876 - val_accuracy: 0.6995\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 9s 1ms/step - loss: 0.7024 - accuracy: 0.7012 - val_loss: 0.7440 - val_accuracy: 0.6676\n",
      "Early stopped after 10 epochs.\n",
      "1689/1689 [==============================] - 1s 763us/step - loss: 0.6792 - accuracy: 0.6988\n",
      "Validation accuracy: 0.6988435387611389\n",
      "\n",
      "Training model with 1 hidden layers, 128 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.9138 - accuracy: 0.5676 - val_loss: 0.8746 - val_accuracy: 0.6198\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8425 - accuracy: 0.6206 - val_loss: 0.8427 - val_accuracy: 0.6370\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7944 - accuracy: 0.6580 - val_loss: 0.8063 - val_accuracy: 0.6531\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7563 - accuracy: 0.6839 - val_loss: 0.7809 - val_accuracy: 0.6562\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7281 - accuracy: 0.6977 - val_loss: 0.7601 - val_accuracy: 0.6632\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7055 - accuracy: 0.7084 - val_loss: 0.7453 - val_accuracy: 0.6657\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6879 - accuracy: 0.7159 - val_loss: 0.7309 - val_accuracy: 0.6715\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6727 - accuracy: 0.7214 - val_loss: 0.7157 - val_accuracy: 0.6777\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6597 - accuracy: 0.7267 - val_loss: 0.7104 - val_accuracy: 0.6794\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6479 - accuracy: 0.7319 - val_loss: 0.7008 - val_accuracy: 0.6821\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6378 - accuracy: 0.7354 - val_loss: 0.6960 - val_accuracy: 0.6838\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6291 - accuracy: 0.7397 - val_loss: 0.6898 - val_accuracy: 0.6854\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6215 - accuracy: 0.7429 - val_loss: 0.6832 - val_accuracy: 0.6895\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6157 - accuracy: 0.7441 - val_loss: 0.6849 - val_accuracy: 0.6873\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6113 - accuracy: 0.7465 - val_loss: 0.6781 - val_accuracy: 0.6901\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6070 - accuracy: 0.7477 - val_loss: 0.6821 - val_accuracy: 0.6876\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6018 - accuracy: 0.7500 - val_loss: 0.6745 - val_accuracy: 0.6911\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5974 - accuracy: 0.7516 - val_loss: 0.6664 - val_accuracy: 0.6945\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5921 - accuracy: 0.7539 - val_loss: 0.6730 - val_accuracy: 0.6915\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5881 - accuracy: 0.7558 - val_loss: 0.6650 - val_accuracy: 0.6949\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5851 - accuracy: 0.7558 - val_loss: 0.6616 - val_accuracy: 0.6968\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5823 - accuracy: 0.7574 - val_loss: 0.6554 - val_accuracy: 0.6982\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5800 - accuracy: 0.7581 - val_loss: 0.6577 - val_accuracy: 0.6975\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5796 - accuracy: 0.7582 - val_loss: 0.6474 - val_accuracy: 0.7012\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5757 - accuracy: 0.7595 - val_loss: 0.6514 - val_accuracy: 0.6995\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5744 - accuracy: 0.7601 - val_loss: 0.6480 - val_accuracy: 0.7012\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5714 - accuracy: 0.7614 - val_loss: 0.6466 - val_accuracy: 0.7018\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5712 - accuracy: 0.7616 - val_loss: 0.6449 - val_accuracy: 0.7015\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5691 - accuracy: 0.7626 - val_loss: 0.6502 - val_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5651 - accuracy: 0.7637 - val_loss: 0.6466 - val_accuracy: 0.7010\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5644 - accuracy: 0.7639 - val_loss: 0.6433 - val_accuracy: 0.7024\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5627 - accuracy: 0.7639 - val_loss: 0.6438 - val_accuracy: 0.7030\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5628 - accuracy: 0.7643 - val_loss: 0.6398 - val_accuracy: 0.7038\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5611 - accuracy: 0.7645 - val_loss: 0.6383 - val_accuracy: 0.7049\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5600 - accuracy: 0.7657 - val_loss: 0.6459 - val_accuracy: 0.7009\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5577 - accuracy: 0.7667 - val_loss: 0.6345 - val_accuracy: 0.7061\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5567 - accuracy: 0.7667 - val_loss: 0.6376 - val_accuracy: 0.7042\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5552 - accuracy: 0.7673 - val_loss: 0.6367 - val_accuracy: 0.7045\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5543 - accuracy: 0.7673 - val_loss: 0.6342 - val_accuracy: 0.7056\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5541 - accuracy: 0.7675 - val_loss: 0.6336 - val_accuracy: 0.7054\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5522 - accuracy: 0.7678 - val_loss: 0.6273 - val_accuracy: 0.7087\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5510 - accuracy: 0.7685 - val_loss: 0.6309 - val_accuracy: 0.7057\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5501 - accuracy: 0.7686 - val_loss: 0.6315 - val_accuracy: 0.7070\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5499 - accuracy: 0.7692 - val_loss: 0.6334 - val_accuracy: 0.7057\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5491 - accuracy: 0.7693 - val_loss: 0.6325 - val_accuracy: 0.7068\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5474 - accuracy: 0.7700 - val_loss: 0.6298 - val_accuracy: 0.7066\n",
      "Early stopped after 46 epochs.\n",
      "1689/1689 [==============================] - 1s 758us/step - loss: 0.6273 - accuracy: 0.7087\n",
      "Validation accuracy: 0.7086871862411499\n",
      "\n",
      "Training model with 1 hidden layers, 128 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7340 - accuracy: 0.6820 - val_loss: 0.6943 - val_accuracy: 0.6835\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6068 - accuracy: 0.7458 - val_loss: 0.6577 - val_accuracy: 0.6956\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5693 - accuracy: 0.7606 - val_loss: 0.6394 - val_accuracy: 0.7040\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5480 - accuracy: 0.7690 - val_loss: 0.6295 - val_accuracy: 0.7077\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5379 - accuracy: 0.7727 - val_loss: 0.6213 - val_accuracy: 0.7124\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5289 - accuracy: 0.7757 - val_loss: 0.6136 - val_accuracy: 0.7129\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5220 - accuracy: 0.7781 - val_loss: 0.6251 - val_accuracy: 0.7085\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5184 - accuracy: 0.7790 - val_loss: 0.6055 - val_accuracy: 0.7161\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5148 - accuracy: 0.7806 - val_loss: 0.6156 - val_accuracy: 0.7114\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5130 - accuracy: 0.7817 - val_loss: 0.5972 - val_accuracy: 0.7212\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5097 - accuracy: 0.7819 - val_loss: 0.5980 - val_accuracy: 0.7188\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5070 - accuracy: 0.7832 - val_loss: 0.6001 - val_accuracy: 0.7187\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5043 - accuracy: 0.7839 - val_loss: 0.6058 - val_accuracy: 0.7161\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5015 - accuracy: 0.7855 - val_loss: 0.5905 - val_accuracy: 0.7225\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4976 - accuracy: 0.7873 - val_loss: 0.5880 - val_accuracy: 0.7245\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4963 - accuracy: 0.7877 - val_loss: 0.6162 - val_accuracy: 0.7155\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4948 - accuracy: 0.7880 - val_loss: 0.5822 - val_accuracy: 0.7268\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4920 - accuracy: 0.7886 - val_loss: 0.5953 - val_accuracy: 0.7219\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4900 - accuracy: 0.7897 - val_loss: 0.6075 - val_accuracy: 0.7133\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4875 - accuracy: 0.7906 - val_loss: 0.5726 - val_accuracy: 0.7301\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4875 - accuracy: 0.7898 - val_loss: 0.5879 - val_accuracy: 0.7250\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4861 - accuracy: 0.7912 - val_loss: 0.5970 - val_accuracy: 0.7210\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4837 - accuracy: 0.7913 - val_loss: 0.5850 - val_accuracy: 0.7257\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4837 - accuracy: 0.7920 - val_loss: 0.5811 - val_accuracy: 0.7270\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.4821 - accuracy: 0.7927 - val_loss: 0.5843 - val_accuracy: 0.7276\n",
      "Early stopped after 25 epochs.\n",
      "1689/1689 [==============================] - 1s 793us/step - loss: 0.5726 - accuracy: 0.7301\n",
      "Validation accuracy: 0.7301322817802429\n",
      "\n",
      "Training model with 1 hidden layers, 128 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6330 - accuracy: 0.7288 - val_loss: 0.6691 - val_accuracy: 0.6934\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5638 - accuracy: 0.7632 - val_loss: 0.6495 - val_accuracy: 0.7066\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5491 - accuracy: 0.7691 - val_loss: 0.6186 - val_accuracy: 0.7147\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5403 - accuracy: 0.7733 - val_loss: 0.6149 - val_accuracy: 0.7182\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5346 - accuracy: 0.7758 - val_loss: 0.6076 - val_accuracy: 0.7168\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5281 - accuracy: 0.7784 - val_loss: 0.5949 - val_accuracy: 0.7255\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5262 - accuracy: 0.7796 - val_loss: 0.5999 - val_accuracy: 0.7250\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5240 - accuracy: 0.7795 - val_loss: 0.6532 - val_accuracy: 0.7091\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5209 - accuracy: 0.7805 - val_loss: 0.6052 - val_accuracy: 0.7191\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5211 - accuracy: 0.7809 - val_loss: 0.6208 - val_accuracy: 0.7182\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5193 - accuracy: 0.7816 - val_loss: 0.6159 - val_accuracy: 0.7139\n",
      "Early stopped after 11 epochs.\n",
      "1689/1689 [==============================] - 1s 793us/step - loss: 0.5949 - accuracy: 0.7255\n",
      "Validation accuracy: 0.7255065441131592\n",
      "\n",
      "Training model with 1 hidden layers, 128 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.9387 - accuracy: 0.5479 - val_loss: 0.8869 - val_accuracy: 0.6100\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8759 - accuracy: 0.5980 - val_loss: 0.8524 - val_accuracy: 0.6298\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8380 - accuracy: 0.6246 - val_loss: 0.8257 - val_accuracy: 0.6378\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.8079 - accuracy: 0.6450 - val_loss: 0.7987 - val_accuracy: 0.6488\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7826 - accuracy: 0.6621 - val_loss: 0.7958 - val_accuracy: 0.6460\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7631 - accuracy: 0.6742 - val_loss: 0.7704 - val_accuracy: 0.6550\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7476 - accuracy: 0.6829 - val_loss: 0.7546 - val_accuracy: 0.6643\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7344 - accuracy: 0.6902 - val_loss: 0.7455 - val_accuracy: 0.6674\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7227 - accuracy: 0.6963 - val_loss: 0.7359 - val_accuracy: 0.6692\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7145 - accuracy: 0.6999 - val_loss: 0.7360 - val_accuracy: 0.6677\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.7054 - accuracy: 0.7043 - val_loss: 0.7234 - val_accuracy: 0.6745\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6987 - accuracy: 0.7081 - val_loss: 0.7161 - val_accuracy: 0.6785\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6929 - accuracy: 0.7109 - val_loss: 0.7100 - val_accuracy: 0.6820\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6873 - accuracy: 0.7122 - val_loss: 0.7188 - val_accuracy: 0.6750\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6823 - accuracy: 0.7148 - val_loss: 0.7123 - val_accuracy: 0.6774\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6773 - accuracy: 0.7172 - val_loss: 0.7057 - val_accuracy: 0.6806\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6731 - accuracy: 0.7187 - val_loss: 0.7014 - val_accuracy: 0.6820\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6689 - accuracy: 0.7215 - val_loss: 0.6999 - val_accuracy: 0.6829\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6646 - accuracy: 0.7233 - val_loss: 0.6981 - val_accuracy: 0.6838\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6607 - accuracy: 0.7245 - val_loss: 0.6968 - val_accuracy: 0.6839\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6572 - accuracy: 0.7260 - val_loss: 0.6864 - val_accuracy: 0.6878\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6546 - accuracy: 0.7267 - val_loss: 0.6849 - val_accuracy: 0.6898\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6521 - accuracy: 0.7279 - val_loss: 0.6861 - val_accuracy: 0.6887\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6501 - accuracy: 0.7298 - val_loss: 0.6915 - val_accuracy: 0.6855\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6462 - accuracy: 0.7310 - val_loss: 0.6847 - val_accuracy: 0.6872\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6441 - accuracy: 0.7318 - val_loss: 0.6813 - val_accuracy: 0.6898\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6422 - accuracy: 0.7315 - val_loss: 0.6766 - val_accuracy: 0.6919\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6393 - accuracy: 0.7339 - val_loss: 0.6825 - val_accuracy: 0.6878\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6382 - accuracy: 0.7341 - val_loss: 0.6780 - val_accuracy: 0.6903\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6356 - accuracy: 0.7352 - val_loss: 0.6681 - val_accuracy: 0.6961\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6325 - accuracy: 0.7368 - val_loss: 0.6750 - val_accuracy: 0.6916\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6306 - accuracy: 0.7380 - val_loss: 0.6705 - val_accuracy: 0.6931\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6286 - accuracy: 0.7385 - val_loss: 0.6619 - val_accuracy: 0.6974\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6271 - accuracy: 0.7388 - val_loss: 0.6653 - val_accuracy: 0.6964\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6250 - accuracy: 0.7394 - val_loss: 0.6659 - val_accuracy: 0.6958\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6254 - accuracy: 0.7402 - val_loss: 0.6629 - val_accuracy: 0.6963\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6246 - accuracy: 0.7397 - val_loss: 0.6647 - val_accuracy: 0.6941\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6217 - accuracy: 0.7408 - val_loss: 0.6628 - val_accuracy: 0.6967\n",
      "Early stopped after 38 epochs.\n",
      "1689/1689 [==============================] - 1s 813us/step - loss: 0.6619 - accuracy: 0.6974\n",
      "Validation accuracy: 0.6974188089370728\n",
      "\n",
      "Training model with 1 hidden layers, 128 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.8051 - accuracy: 0.6443 - val_loss: 0.7376 - val_accuracy: 0.6694\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6905 - accuracy: 0.7099 - val_loss: 0.7055 - val_accuracy: 0.6785\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6526 - accuracy: 0.7268 - val_loss: 0.6810 - val_accuracy: 0.6858\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6365 - accuracy: 0.7328 - val_loss: 0.6596 - val_accuracy: 0.6973\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6232 - accuracy: 0.7382 - val_loss: 0.6623 - val_accuracy: 0.6919\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6169 - accuracy: 0.7419 - val_loss: 0.6536 - val_accuracy: 0.6979\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6090 - accuracy: 0.7449 - val_loss: 0.6497 - val_accuracy: 0.7012\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6030 - accuracy: 0.7467 - val_loss: 0.6485 - val_accuracy: 0.7015\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5977 - accuracy: 0.7510 - val_loss: 0.6455 - val_accuracy: 0.7004\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5926 - accuracy: 0.7527 - val_loss: 0.6371 - val_accuracy: 0.7054\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5887 - accuracy: 0.7546 - val_loss: 0.6302 - val_accuracy: 0.7093\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5873 - accuracy: 0.7552 - val_loss: 0.6345 - val_accuracy: 0.7073\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5852 - accuracy: 0.7553 - val_loss: 0.6312 - val_accuracy: 0.7065\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5827 - accuracy: 0.7568 - val_loss: 0.6368 - val_accuracy: 0.7039\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5813 - accuracy: 0.7580 - val_loss: 0.6338 - val_accuracy: 0.7063\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.5793 - accuracy: 0.7580 - val_loss: 0.6434 - val_accuracy: 0.7019\n",
      "Early stopped after 16 epochs.\n",
      "1689/1689 [==============================] - 1s 807us/step - loss: 0.6302 - accuracy: 0.7093\n",
      "Validation accuracy: 0.7092978358268738\n",
      "\n",
      "Training model with 1 hidden layers, 128 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7414 - accuracy: 0.6792 - val_loss: 0.7238 - val_accuracy: 0.6871\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6820 - accuracy: 0.7118 - val_loss: 0.6737 - val_accuracy: 0.6981\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6700 - accuracy: 0.7183 - val_loss: 0.6834 - val_accuracy: 0.6943\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6632 - accuracy: 0.7215 - val_loss: 0.6812 - val_accuracy: 0.6888\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6571 - accuracy: 0.7235 - val_loss: 0.6757 - val_accuracy: 0.6960\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6531 - accuracy: 0.7249 - val_loss: 0.6761 - val_accuracy: 0.6962\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6538 - accuracy: 0.7237 - val_loss: 0.6579 - val_accuracy: 0.7054\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6525 - accuracy: 0.7255 - val_loss: 0.6729 - val_accuracy: 0.6982\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6502 - accuracy: 0.7272 - val_loss: 0.7011 - val_accuracy: 0.6750\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6502 - accuracy: 0.7287 - val_loss: 0.6401 - val_accuracy: 0.7059\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6488 - accuracy: 0.7282 - val_loss: 0.6766 - val_accuracy: 0.6981\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6471 - accuracy: 0.7303 - val_loss: 0.6456 - val_accuracy: 0.7090\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6456 - accuracy: 0.7295 - val_loss: 0.6493 - val_accuracy: 0.7132\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6443 - accuracy: 0.7317 - val_loss: 0.6400 - val_accuracy: 0.7110\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6430 - accuracy: 0.7308 - val_loss: 0.6831 - val_accuracy: 0.6935\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 10s 1ms/step - loss: 0.6428 - accuracy: 0.7308 - val_loss: 0.7084 - val_accuracy: 0.6791\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6419 - accuracy: 0.7316 - val_loss: 0.6338 - val_accuracy: 0.7160\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6422 - accuracy: 0.7313 - val_loss: 0.6726 - val_accuracy: 0.7040\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6450 - accuracy: 0.7302 - val_loss: 0.6762 - val_accuracy: 0.7006\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6416 - accuracy: 0.7321 - val_loss: 0.6855 - val_accuracy: 0.6985\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6436 - accuracy: 0.7318 - val_loss: 0.6399 - val_accuracy: 0.7159\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6379 - accuracy: 0.7344 - val_loss: 0.6502 - val_accuracy: 0.7042\n",
      "Early stopped after 22 epochs.\n",
      "1689/1689 [==============================] - 1s 811us/step - loss: 0.6338 - accuracy: 0.7160\n",
      "Validation accuracy: 0.7159774303436279\n",
      "\n",
      "Training model with 1 hidden layers, 256 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8890 - accuracy: 0.5859 - val_loss: 0.8546 - val_accuracy: 0.6286\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7923 - accuracy: 0.6596 - val_loss: 0.7875 - val_accuracy: 0.6606\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7308 - accuracy: 0.6974 - val_loss: 0.7741 - val_accuracy: 0.6569\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6938 - accuracy: 0.7135 - val_loss: 0.7351 - val_accuracy: 0.6728\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6669 - accuracy: 0.7226 - val_loss: 0.7075 - val_accuracy: 0.6828\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6490 - accuracy: 0.7291 - val_loss: 0.7008 - val_accuracy: 0.6831\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6346 - accuracy: 0.7354 - val_loss: 0.6909 - val_accuracy: 0.6862\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6217 - accuracy: 0.7397 - val_loss: 0.6879 - val_accuracy: 0.6859\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6108 - accuracy: 0.7449 - val_loss: 0.6718 - val_accuracy: 0.6936\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6012 - accuracy: 0.7480 - val_loss: 0.6840 - val_accuracy: 0.6860\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5921 - accuracy: 0.7523 - val_loss: 0.6718 - val_accuracy: 0.6900\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5837 - accuracy: 0.7550 - val_loss: 0.6658 - val_accuracy: 0.6932\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5779 - accuracy: 0.7576 - val_loss: 0.6507 - val_accuracy: 0.6993\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5709 - accuracy: 0.7609 - val_loss: 0.6580 - val_accuracy: 0.6965\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5662 - accuracy: 0.7619 - val_loss: 0.6480 - val_accuracy: 0.7015\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5600 - accuracy: 0.7652 - val_loss: 0.6386 - val_accuracy: 0.7037\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5565 - accuracy: 0.7656 - val_loss: 0.6400 - val_accuracy: 0.7026\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5516 - accuracy: 0.7680 - val_loss: 0.6373 - val_accuracy: 0.7042\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5472 - accuracy: 0.7697 - val_loss: 0.6318 - val_accuracy: 0.7058\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5447 - accuracy: 0.7710 - val_loss: 0.6333 - val_accuracy: 0.7065\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5408 - accuracy: 0.7728 - val_loss: 0.6333 - val_accuracy: 0.7057\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5363 - accuracy: 0.7742 - val_loss: 0.6297 - val_accuracy: 0.7067\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5339 - accuracy: 0.7751 - val_loss: 0.6315 - val_accuracy: 0.7072\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5311 - accuracy: 0.7755 - val_loss: 0.6203 - val_accuracy: 0.7124\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5274 - accuracy: 0.7769 - val_loss: 0.6234 - val_accuracy: 0.7093\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5259 - accuracy: 0.7775 - val_loss: 0.6136 - val_accuracy: 0.7148\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5223 - accuracy: 0.7786 - val_loss: 0.6172 - val_accuracy: 0.7132\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5196 - accuracy: 0.7797 - val_loss: 0.6208 - val_accuracy: 0.7121\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5170 - accuracy: 0.7811 - val_loss: 0.6152 - val_accuracy: 0.7146\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5149 - accuracy: 0.7817 - val_loss: 0.6164 - val_accuracy: 0.7136\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5123 - accuracy: 0.7826 - val_loss: 0.6103 - val_accuracy: 0.7152\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5105 - accuracy: 0.7840 - val_loss: 0.6094 - val_accuracy: 0.7154\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5087 - accuracy: 0.7836 - val_loss: 0.6051 - val_accuracy: 0.7178\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5068 - accuracy: 0.7836 - val_loss: 0.5985 - val_accuracy: 0.7203\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5037 - accuracy: 0.7850 - val_loss: 0.6028 - val_accuracy: 0.7176\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5020 - accuracy: 0.7855 - val_loss: 0.6014 - val_accuracy: 0.7182\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5008 - accuracy: 0.7861 - val_loss: 0.5954 - val_accuracy: 0.7219\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5004 - accuracy: 0.7860 - val_loss: 0.6090 - val_accuracy: 0.7163\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4989 - accuracy: 0.7855 - val_loss: 0.5939 - val_accuracy: 0.7220\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4975 - accuracy: 0.7871 - val_loss: 0.5986 - val_accuracy: 0.7198\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4967 - accuracy: 0.7873 - val_loss: 0.5983 - val_accuracy: 0.7204\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4940 - accuracy: 0.7881 - val_loss: 0.6055 - val_accuracy: 0.7168\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4923 - accuracy: 0.7884 - val_loss: 0.5894 - val_accuracy: 0.7241\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4914 - accuracy: 0.7895 - val_loss: 0.5934 - val_accuracy: 0.7224\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4906 - accuracy: 0.7893 - val_loss: 0.5958 - val_accuracy: 0.7211\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4904 - accuracy: 0.7898 - val_loss: 0.5959 - val_accuracy: 0.7207\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4889 - accuracy: 0.7903 - val_loss: 0.5867 - val_accuracy: 0.7252\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4871 - accuracy: 0.7901 - val_loss: 0.5916 - val_accuracy: 0.7234\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4876 - accuracy: 0.7904 - val_loss: 0.5922 - val_accuracy: 0.7235\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4866 - accuracy: 0.7907 - val_loss: 0.5885 - val_accuracy: 0.7243\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4843 - accuracy: 0.7907 - val_loss: 0.5908 - val_accuracy: 0.7250\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4842 - accuracy: 0.7913 - val_loss: 0.5908 - val_accuracy: 0.7240\n",
      "Early stopped after 52 epochs.\n",
      "1689/1689 [==============================] - 1s 808us/step - loss: 0.5867 - accuracy: 0.7252\n",
      "Validation accuracy: 0.7252289652824402\n",
      "\n",
      "Training model with 1 hidden layers, 256 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6856 - accuracy: 0.7074 - val_loss: 0.6752 - val_accuracy: 0.6912\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5566 - accuracy: 0.7639 - val_loss: 0.6287 - val_accuracy: 0.7063\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5198 - accuracy: 0.7779 - val_loss: 0.6272 - val_accuracy: 0.7068\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4999 - accuracy: 0.7844 - val_loss: 0.6016 - val_accuracy: 0.7171\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4890 - accuracy: 0.7892 - val_loss: 0.5857 - val_accuracy: 0.7233\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4802 - accuracy: 0.7919 - val_loss: 0.5882 - val_accuracy: 0.7247\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4729 - accuracy: 0.7950 - val_loss: 0.5799 - val_accuracy: 0.7272\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4695 - accuracy: 0.7958 - val_loss: 0.5997 - val_accuracy: 0.7234\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4639 - accuracy: 0.7980 - val_loss: 0.5832 - val_accuracy: 0.7284\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4596 - accuracy: 0.7994 - val_loss: 0.5710 - val_accuracy: 0.7281\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4565 - accuracy: 0.8005 - val_loss: 0.5855 - val_accuracy: 0.7276\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4529 - accuracy: 0.8010 - val_loss: 0.5675 - val_accuracy: 0.7310\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4522 - accuracy: 0.8024 - val_loss: 0.5638 - val_accuracy: 0.7315\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4494 - accuracy: 0.8034 - val_loss: 0.5729 - val_accuracy: 0.7330\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4475 - accuracy: 0.8044 - val_loss: 0.5669 - val_accuracy: 0.7351\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4443 - accuracy: 0.8052 - val_loss: 0.5581 - val_accuracy: 0.7356\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4422 - accuracy: 0.8061 - val_loss: 0.5763 - val_accuracy: 0.7341\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4412 - accuracy: 0.8071 - val_loss: 0.5668 - val_accuracy: 0.7324\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4397 - accuracy: 0.8068 - val_loss: 0.5567 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4386 - accuracy: 0.8078 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4370 - accuracy: 0.8078 - val_loss: 0.5501 - val_accuracy: 0.7418\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4375 - accuracy: 0.8075 - val_loss: 0.5557 - val_accuracy: 0.7399\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4360 - accuracy: 0.8075 - val_loss: 0.5434 - val_accuracy: 0.7412\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4355 - accuracy: 0.8088 - val_loss: 0.5408 - val_accuracy: 0.7430\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4347 - accuracy: 0.8082 - val_loss: 0.5584 - val_accuracy: 0.7386\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4330 - accuracy: 0.8090 - val_loss: 0.5582 - val_accuracy: 0.7375\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4326 - accuracy: 0.8086 - val_loss: 0.5587 - val_accuracy: 0.7392\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4320 - accuracy: 0.8093 - val_loss: 0.5584 - val_accuracy: 0.7397\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4320 - accuracy: 0.8093 - val_loss: 0.5671 - val_accuracy: 0.7323\n",
      "Early stopped after 29 epochs.\n",
      "1689/1689 [==============================] - 1s 820us/step - loss: 0.5408 - accuracy: 0.7430\n",
      "Validation accuracy: 0.7429734468460083\n",
      "\n",
      "Training model with 1 hidden layers, 256 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6202 - accuracy: 0.7356 - val_loss: 0.6796 - val_accuracy: 0.6957\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5545 - accuracy: 0.7662 - val_loss: 0.6282 - val_accuracy: 0.7142\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5354 - accuracy: 0.7749 - val_loss: 0.6048 - val_accuracy: 0.7233\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5279 - accuracy: 0.7784 - val_loss: 0.6636 - val_accuracy: 0.6936\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5222 - accuracy: 0.7806 - val_loss: 0.6431 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5171 - accuracy: 0.7823 - val_loss: 0.6140 - val_accuracy: 0.7272\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5153 - accuracy: 0.7825 - val_loss: 0.5770 - val_accuracy: 0.7272\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5136 - accuracy: 0.7827 - val_loss: 0.6199 - val_accuracy: 0.7197\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5083 - accuracy: 0.7855 - val_loss: 0.5819 - val_accuracy: 0.7307\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5095 - accuracy: 0.7866 - val_loss: 0.6380 - val_accuracy: 0.7145\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5052 - accuracy: 0.7876 - val_loss: 0.6152 - val_accuracy: 0.7254\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5052 - accuracy: 0.7865 - val_loss: 0.6041 - val_accuracy: 0.7226\n",
      "Early stopped after 12 epochs.\n",
      "1689/1689 [==============================] - 1s 805us/step - loss: 0.5770 - accuracy: 0.7272\n",
      "Validation accuracy: 0.7272273302078247\n",
      "\n",
      "Training model with 1 hidden layers, 256 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9127 - accuracy: 0.5674 - val_loss: 0.8673 - val_accuracy: 0.6219\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8424 - accuracy: 0.6220 - val_loss: 0.8326 - val_accuracy: 0.6352\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7940 - accuracy: 0.6588 - val_loss: 0.8053 - val_accuracy: 0.6454\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7543 - accuracy: 0.6837 - val_loss: 0.7640 - val_accuracy: 0.6632\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7268 - accuracy: 0.6970 - val_loss: 0.7562 - val_accuracy: 0.6620\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7057 - accuracy: 0.7066 - val_loss: 0.7397 - val_accuracy: 0.6689\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6872 - accuracy: 0.7156 - val_loss: 0.7271 - val_accuracy: 0.6736\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6728 - accuracy: 0.7209 - val_loss: 0.7122 - val_accuracy: 0.6808\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6597 - accuracy: 0.7268 - val_loss: 0.7065 - val_accuracy: 0.6814\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6485 - accuracy: 0.7313 - val_loss: 0.6955 - val_accuracy: 0.6848\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6396 - accuracy: 0.7349 - val_loss: 0.6984 - val_accuracy: 0.6829\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6323 - accuracy: 0.7371 - val_loss: 0.6909 - val_accuracy: 0.6846\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6258 - accuracy: 0.7401 - val_loss: 0.6810 - val_accuracy: 0.6891\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6175 - accuracy: 0.7428 - val_loss: 0.6811 - val_accuracy: 0.6902\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6138 - accuracy: 0.7448 - val_loss: 0.6717 - val_accuracy: 0.6924\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6088 - accuracy: 0.7470 - val_loss: 0.6719 - val_accuracy: 0.6932\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6051 - accuracy: 0.7481 - val_loss: 0.6701 - val_accuracy: 0.6931\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6013 - accuracy: 0.7503 - val_loss: 0.6634 - val_accuracy: 0.6958\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5968 - accuracy: 0.7512 - val_loss: 0.6610 - val_accuracy: 0.6954\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5941 - accuracy: 0.7517 - val_loss: 0.6598 - val_accuracy: 0.6960\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5927 - accuracy: 0.7524 - val_loss: 0.6660 - val_accuracy: 0.6948\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5888 - accuracy: 0.7544 - val_loss: 0.6608 - val_accuracy: 0.6956\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5870 - accuracy: 0.7547 - val_loss: 0.6537 - val_accuracy: 0.6990\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5828 - accuracy: 0.7559 - val_loss: 0.6508 - val_accuracy: 0.6977\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5805 - accuracy: 0.7576 - val_loss: 0.6491 - val_accuracy: 0.7006\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5793 - accuracy: 0.7577 - val_loss: 0.6529 - val_accuracy: 0.6978\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5777 - accuracy: 0.7583 - val_loss: 0.6446 - val_accuracy: 0.7026\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5744 - accuracy: 0.7601 - val_loss: 0.6431 - val_accuracy: 0.7023\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.5720 - accuracy: 0.7601 - val_loss: 0.6425 - val_accuracy: 0.7022\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5722 - accuracy: 0.7600 - val_loss: 0.6506 - val_accuracy: 0.6990\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5708 - accuracy: 0.7605 - val_loss: 0.6472 - val_accuracy: 0.6998\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5679 - accuracy: 0.7613 - val_loss: 0.6431 - val_accuracy: 0.7020\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5659 - accuracy: 0.7624 - val_loss: 0.6393 - val_accuracy: 0.7038\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5634 - accuracy: 0.7637 - val_loss: 0.6400 - val_accuracy: 0.7032\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5636 - accuracy: 0.7633 - val_loss: 0.6395 - val_accuracy: 0.7028\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5620 - accuracy: 0.7638 - val_loss: 0.6342 - val_accuracy: 0.7050\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5595 - accuracy: 0.7650 - val_loss: 0.6278 - val_accuracy: 0.7076\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5583 - accuracy: 0.7651 - val_loss: 0.6347 - val_accuracy: 0.7048\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5577 - accuracy: 0.7653 - val_loss: 0.6281 - val_accuracy: 0.7073\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5555 - accuracy: 0.7663 - val_loss: 0.6366 - val_accuracy: 0.7050\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5553 - accuracy: 0.7663 - val_loss: 0.6352 - val_accuracy: 0.7043\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5560 - accuracy: 0.7669 - val_loss: 0.6291 - val_accuracy: 0.7070\n",
      "Early stopped after 42 epochs.\n",
      "1689/1689 [==============================] - 1s 824us/step - loss: 0.6278 - accuracy: 0.7076\n",
      "Validation accuracy: 0.7075955271720886\n",
      "\n",
      "Training model with 1 hidden layers, 256 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7585 - accuracy: 0.6718 - val_loss: 0.6996 - val_accuracy: 0.6846\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6340 - accuracy: 0.7366 - val_loss: 0.6768 - val_accuracy: 0.6865\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5962 - accuracy: 0.7503 - val_loss: 0.6580 - val_accuracy: 0.6964\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5766 - accuracy: 0.7582 - val_loss: 0.6524 - val_accuracy: 0.7009\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5632 - accuracy: 0.7648 - val_loss: 0.6197 - val_accuracy: 0.7135\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5538 - accuracy: 0.7671 - val_loss: 0.6366 - val_accuracy: 0.7062\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5469 - accuracy: 0.7696 - val_loss: 0.6097 - val_accuracy: 0.7171\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5406 - accuracy: 0.7728 - val_loss: 0.6219 - val_accuracy: 0.7130\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5342 - accuracy: 0.7748 - val_loss: 0.6047 - val_accuracy: 0.7174\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5303 - accuracy: 0.7765 - val_loss: 0.6002 - val_accuracy: 0.7212\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5265 - accuracy: 0.7776 - val_loss: 0.6078 - val_accuracy: 0.7190\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5253 - accuracy: 0.7788 - val_loss: 0.5981 - val_accuracy: 0.7206\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5195 - accuracy: 0.7806 - val_loss: 0.6010 - val_accuracy: 0.7202\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5185 - accuracy: 0.7814 - val_loss: 0.6028 - val_accuracy: 0.7194\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5147 - accuracy: 0.7822 - val_loss: 0.6006 - val_accuracy: 0.7230\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5129 - accuracy: 0.7821 - val_loss: 0.5968 - val_accuracy: 0.7229\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5111 - accuracy: 0.7833 - val_loss: 0.5898 - val_accuracy: 0.7252\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5099 - accuracy: 0.7844 - val_loss: 0.6013 - val_accuracy: 0.7215\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5073 - accuracy: 0.7851 - val_loss: 0.5823 - val_accuracy: 0.7274\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5036 - accuracy: 0.7862 - val_loss: 0.5928 - val_accuracy: 0.7228\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5038 - accuracy: 0.7858 - val_loss: 0.5876 - val_accuracy: 0.7243\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5038 - accuracy: 0.7870 - val_loss: 0.5850 - val_accuracy: 0.7252\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5013 - accuracy: 0.7876 - val_loss: 0.5949 - val_accuracy: 0.7240\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5000 - accuracy: 0.7879 - val_loss: 0.5800 - val_accuracy: 0.7277\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4995 - accuracy: 0.7876 - val_loss: 0.5781 - val_accuracy: 0.7287\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4970 - accuracy: 0.7882 - val_loss: 0.5861 - val_accuracy: 0.7260\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4964 - accuracy: 0.7887 - val_loss: 0.5862 - val_accuracy: 0.7255\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4961 - accuracy: 0.7884 - val_loss: 0.5853 - val_accuracy: 0.7274\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4944 - accuracy: 0.7898 - val_loss: 0.5791 - val_accuracy: 0.7290\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4913 - accuracy: 0.7902 - val_loss: 0.5857 - val_accuracy: 0.7266\n",
      "Early stopped after 30 epochs.\n",
      "1689/1689 [==============================] - 1s 800us/step - loss: 0.5781 - accuracy: 0.7287\n",
      "Validation accuracy: 0.7287260890007019\n",
      "\n",
      "Training model with 1 hidden layers, 256 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7277 - accuracy: 0.6862 - val_loss: 0.6796 - val_accuracy: 0.6931\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6646 - accuracy: 0.7206 - val_loss: 0.7050 - val_accuracy: 0.6781\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6548 - accuracy: 0.7260 - val_loss: 0.6919 - val_accuracy: 0.6867\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6483 - accuracy: 0.7292 - val_loss: 0.6636 - val_accuracy: 0.7022\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6433 - accuracy: 0.7314 - val_loss: 0.6760 - val_accuracy: 0.6960\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6407 - accuracy: 0.7341 - val_loss: 0.6965 - val_accuracy: 0.6923\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6370 - accuracy: 0.7353 - val_loss: 0.6713 - val_accuracy: 0.6986\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6347 - accuracy: 0.7354 - val_loss: 0.6436 - val_accuracy: 0.7116\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6332 - accuracy: 0.7362 - val_loss: 0.6472 - val_accuracy: 0.7080\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6351 - accuracy: 0.7374 - val_loss: 0.6783 - val_accuracy: 0.6981\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6312 - accuracy: 0.7396 - val_loss: 0.6383 - val_accuracy: 0.7140\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6297 - accuracy: 0.7389 - val_loss: 0.6765 - val_accuracy: 0.7074\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6292 - accuracy: 0.7387 - val_loss: 0.6463 - val_accuracy: 0.7075\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6290 - accuracy: 0.7377 - val_loss: 0.6559 - val_accuracy: 0.7070\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6283 - accuracy: 0.7408 - val_loss: 0.6516 - val_accuracy: 0.7047\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6274 - accuracy: 0.7393 - val_loss: 0.6455 - val_accuracy: 0.7146\n",
      "Early stopped after 16 epochs.\n",
      "1689/1689 [==============================] - 1s 815us/step - loss: 0.6383 - accuracy: 0.7140\n",
      "Validation accuracy: 0.7140160799026489\n",
      "\n",
      "Training model with 2 hidden layers, 64 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8823 - accuracy: 0.5894 - val_loss: 0.8252 - val_accuracy: 0.6195\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7551 - accuracy: 0.6690 - val_loss: 0.7630 - val_accuracy: 0.6437\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6811 - accuracy: 0.7077 - val_loss: 0.7218 - val_accuracy: 0.6582\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6282 - accuracy: 0.7316 - val_loss: 0.6920 - val_accuracy: 0.6727\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5909 - accuracy: 0.7475 - val_loss: 0.6615 - val_accuracy: 0.6895\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5628 - accuracy: 0.7590 - val_loss: 0.6499 - val_accuracy: 0.6951\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5430 - accuracy: 0.7675 - val_loss: 0.6272 - val_accuracy: 0.7049\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5265 - accuracy: 0.7733 - val_loss: 0.6194 - val_accuracy: 0.7093\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5141 - accuracy: 0.7773 - val_loss: 0.6185 - val_accuracy: 0.7103\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5044 - accuracy: 0.7810 - val_loss: 0.6013 - val_accuracy: 0.7182\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4960 - accuracy: 0.7847 - val_loss: 0.6027 - val_accuracy: 0.7180\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4882 - accuracy: 0.7875 - val_loss: 0.5928 - val_accuracy: 0.7214\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4819 - accuracy: 0.7904 - val_loss: 0.5840 - val_accuracy: 0.7241\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4768 - accuracy: 0.7914 - val_loss: 0.5806 - val_accuracy: 0.7265\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4718 - accuracy: 0.7938 - val_loss: 0.5814 - val_accuracy: 0.7283\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4678 - accuracy: 0.7951 - val_loss: 0.5758 - val_accuracy: 0.7296\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4640 - accuracy: 0.7965 - val_loss: 0.5698 - val_accuracy: 0.7315\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4605 - accuracy: 0.7973 - val_loss: 0.5671 - val_accuracy: 0.7336\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4579 - accuracy: 0.7984 - val_loss: 0.5685 - val_accuracy: 0.7338\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4554 - accuracy: 0.8000 - val_loss: 0.5680 - val_accuracy: 0.7340\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4517 - accuracy: 0.8008 - val_loss: 0.5622 - val_accuracy: 0.7369\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4488 - accuracy: 0.8018 - val_loss: 0.5540 - val_accuracy: 0.7402\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4472 - accuracy: 0.8021 - val_loss: 0.5607 - val_accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4448 - accuracy: 0.8029 - val_loss: 0.5564 - val_accuracy: 0.7391\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4428 - accuracy: 0.8043 - val_loss: 0.5548 - val_accuracy: 0.7403\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4397 - accuracy: 0.8048 - val_loss: 0.5505 - val_accuracy: 0.7410\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4386 - accuracy: 0.8051 - val_loss: 0.5465 - val_accuracy: 0.7436\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4363 - accuracy: 0.8053 - val_loss: 0.5457 - val_accuracy: 0.7433\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4364 - accuracy: 0.8060 - val_loss: 0.5413 - val_accuracy: 0.7455\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4344 - accuracy: 0.8067 - val_loss: 0.5446 - val_accuracy: 0.7442\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4327 - accuracy: 0.8073 - val_loss: 0.5383 - val_accuracy: 0.7463\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4301 - accuracy: 0.8082 - val_loss: 0.5410 - val_accuracy: 0.7466\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4301 - accuracy: 0.8081 - val_loss: 0.5382 - val_accuracy: 0.7466\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4287 - accuracy: 0.8093 - val_loss: 0.5343 - val_accuracy: 0.7491\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4276 - accuracy: 0.8099 - val_loss: 0.5368 - val_accuracy: 0.7493\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4260 - accuracy: 0.8096 - val_loss: 0.5340 - val_accuracy: 0.7511\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4239 - accuracy: 0.8101 - val_loss: 0.5347 - val_accuracy: 0.7501\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4244 - accuracy: 0.8103 - val_loss: 0.5309 - val_accuracy: 0.7503\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4240 - accuracy: 0.8102 - val_loss: 0.5309 - val_accuracy: 0.7512\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4217 - accuracy: 0.8118 - val_loss: 0.5299 - val_accuracy: 0.7519\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4202 - accuracy: 0.8118 - val_loss: 0.5280 - val_accuracy: 0.7534\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4201 - accuracy: 0.8118 - val_loss: 0.5286 - val_accuracy: 0.7528\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4182 - accuracy: 0.8133 - val_loss: 0.5236 - val_accuracy: 0.7537\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4179 - accuracy: 0.8123 - val_loss: 0.5242 - val_accuracy: 0.7543\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4176 - accuracy: 0.8135 - val_loss: 0.5279 - val_accuracy: 0.7532\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4161 - accuracy: 0.8134 - val_loss: 0.5248 - val_accuracy: 0.7556\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4148 - accuracy: 0.8141 - val_loss: 0.5213 - val_accuracy: 0.7569\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4144 - accuracy: 0.8144 - val_loss: 0.5199 - val_accuracy: 0.7565\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4145 - accuracy: 0.8141 - val_loss: 0.5198 - val_accuracy: 0.7574\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4137 - accuracy: 0.8149 - val_loss: 0.5201 - val_accuracy: 0.7571\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4124 - accuracy: 0.8153 - val_loss: 0.5171 - val_accuracy: 0.7569\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4131 - accuracy: 0.8148 - val_loss: 0.5181 - val_accuracy: 0.7592\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4109 - accuracy: 0.8156 - val_loss: 0.5185 - val_accuracy: 0.7578\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4101 - accuracy: 0.8161 - val_loss: 0.5178 - val_accuracy: 0.7582\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4102 - accuracy: 0.8156 - val_loss: 0.5162 - val_accuracy: 0.7589\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4091 - accuracy: 0.8163 - val_loss: 0.5123 - val_accuracy: 0.7607\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4088 - accuracy: 0.8161 - val_loss: 0.5137 - val_accuracy: 0.7601\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4086 - accuracy: 0.8169 - val_loss: 0.5122 - val_accuracy: 0.7605\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4071 - accuracy: 0.8172 - val_loss: 0.5102 - val_accuracy: 0.7610\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4067 - accuracy: 0.8173 - val_loss: 0.5152 - val_accuracy: 0.7605\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4071 - accuracy: 0.8164 - val_loss: 0.5116 - val_accuracy: 0.7622\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4057 - accuracy: 0.8178 - val_loss: 0.5108 - val_accuracy: 0.7626\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4040 - accuracy: 0.8173 - val_loss: 0.5125 - val_accuracy: 0.7636\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4046 - accuracy: 0.8183 - val_loss: 0.5128 - val_accuracy: 0.7623\n",
      "Early stopped after 64 epochs.\n",
      "1689/1689 [==============================] - 1s 825us/step - loss: 0.5102 - accuracy: 0.7610\n",
      "Validation accuracy: 0.7609954476356506\n",
      "\n",
      "Training model with 2 hidden layers, 64 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6283 - accuracy: 0.7253 - val_loss: 0.6276 - val_accuracy: 0.7020\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4868 - accuracy: 0.7850 - val_loss: 0.5809 - val_accuracy: 0.7222\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4606 - accuracy: 0.7948 - val_loss: 0.5579 - val_accuracy: 0.7329\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4474 - accuracy: 0.7995 - val_loss: 0.5488 - val_accuracy: 0.7375\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4391 - accuracy: 0.8027 - val_loss: 0.5427 - val_accuracy: 0.7440\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4313 - accuracy: 0.8065 - val_loss: 0.5337 - val_accuracy: 0.7459\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4262 - accuracy: 0.8087 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4233 - accuracy: 0.8096 - val_loss: 0.5306 - val_accuracy: 0.7506\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4199 - accuracy: 0.8111 - val_loss: 0.5282 - val_accuracy: 0.7525\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4171 - accuracy: 0.8121 - val_loss: 0.5243 - val_accuracy: 0.7543\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4144 - accuracy: 0.8133 - val_loss: 0.5207 - val_accuracy: 0.7566\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4126 - accuracy: 0.8137 - val_loss: 0.5172 - val_accuracy: 0.7576\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4113 - accuracy: 0.8151 - val_loss: 0.5158 - val_accuracy: 0.7596\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4097 - accuracy: 0.8153 - val_loss: 0.5102 - val_accuracy: 0.7623\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4070 - accuracy: 0.8162 - val_loss: 0.5098 - val_accuracy: 0.7614\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4067 - accuracy: 0.8164 - val_loss: 0.5070 - val_accuracy: 0.7633\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4052 - accuracy: 0.8168 - val_loss: 0.5017 - val_accuracy: 0.7618\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4023 - accuracy: 0.8184 - val_loss: 0.4993 - val_accuracy: 0.7651\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4022 - accuracy: 0.8186 - val_loss: 0.4929 - val_accuracy: 0.7657\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4017 - accuracy: 0.8188 - val_loss: 0.5017 - val_accuracy: 0.7668\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4011 - accuracy: 0.8190 - val_loss: 0.5010 - val_accuracy: 0.7658\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4001 - accuracy: 0.8195 - val_loss: 0.4955 - val_accuracy: 0.7694\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.3991 - accuracy: 0.8200 - val_loss: 0.4947 - val_accuracy: 0.7687\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.3985 - accuracy: 0.8198 - val_loss: 0.4938 - val_accuracy: 0.7677\n",
      "Early stopped after 24 epochs.\n",
      "1689/1689 [==============================] - 2s 894us/step - loss: 0.4929 - accuracy: 0.7657\n",
      "Validation accuracy: 0.7657137513160706\n",
      "\n",
      "Training model with 2 hidden layers, 64 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5998 - accuracy: 0.7375 - val_loss: 0.6492 - val_accuracy: 0.6901\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5331 - accuracy: 0.7654 - val_loss: 0.6009 - val_accuracy: 0.7003\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5205 - accuracy: 0.7688 - val_loss: 0.5796 - val_accuracy: 0.7181\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5112 - accuracy: 0.7727 - val_loss: 0.5846 - val_accuracy: 0.7090\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5059 - accuracy: 0.7735 - val_loss: 0.5849 - val_accuracy: 0.7169\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5026 - accuracy: 0.7753 - val_loss: 0.5871 - val_accuracy: 0.7194\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4980 - accuracy: 0.7765 - val_loss: 0.5731 - val_accuracy: 0.7259\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4975 - accuracy: 0.7777 - val_loss: 0.6206 - val_accuracy: 0.6956\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4950 - accuracy: 0.7786 - val_loss: 0.5799 - val_accuracy: 0.7193\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4944 - accuracy: 0.7776 - val_loss: 0.5451 - val_accuracy: 0.7306\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4921 - accuracy: 0.7788 - val_loss: 0.5760 - val_accuracy: 0.7173\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.4942 - accuracy: 0.7800 - val_loss: 0.5967 - val_accuracy: 0.7141\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4911 - accuracy: 0.7793 - val_loss: 0.5587 - val_accuracy: 0.7254\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4912 - accuracy: 0.7804 - val_loss: 0.5512 - val_accuracy: 0.7295\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.4889 - accuracy: 0.7821 - val_loss: 0.5816 - val_accuracy: 0.7199\n",
      "Early stopped after 15 epochs.\n",
      "1689/1689 [==============================] - 1s 843us/step - loss: 0.5451 - accuracy: 0.7306\n",
      "Validation accuracy: 0.7305578589439392\n",
      "\n",
      "Training model with 2 hidden layers, 64 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.9795 - accuracy: 0.5142 - val_loss: 0.9010 - val_accuracy: 0.5819\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8962 - accuracy: 0.5828 - val_loss: 0.8575 - val_accuracy: 0.5966\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8456 - accuracy: 0.6174 - val_loss: 0.8225 - val_accuracy: 0.6044\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8035 - accuracy: 0.6430 - val_loss: 0.7950 - val_accuracy: 0.6141\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7731 - accuracy: 0.6616 - val_loss: 0.7741 - val_accuracy: 0.6213\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7488 - accuracy: 0.6747 - val_loss: 0.7537 - val_accuracy: 0.6319\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7274 - accuracy: 0.6855 - val_loss: 0.7498 - val_accuracy: 0.6316\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7066 - accuracy: 0.6950 - val_loss: 0.7282 - val_accuracy: 0.6412\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6905 - accuracy: 0.7022 - val_loss: 0.7226 - val_accuracy: 0.6449\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6781 - accuracy: 0.7072 - val_loss: 0.7057 - val_accuracy: 0.6532\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6670 - accuracy: 0.7122 - val_loss: 0.6935 - val_accuracy: 0.6604\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6568 - accuracy: 0.7176 - val_loss: 0.6892 - val_accuracy: 0.6611\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6498 - accuracy: 0.7197 - val_loss: 0.6936 - val_accuracy: 0.6583\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6431 - accuracy: 0.7232 - val_loss: 0.6887 - val_accuracy: 0.6615\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6372 - accuracy: 0.7255 - val_loss: 0.6806 - val_accuracy: 0.6643\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6344 - accuracy: 0.7273 - val_loss: 0.6713 - val_accuracy: 0.6696\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6281 - accuracy: 0.7298 - val_loss: 0.6720 - val_accuracy: 0.6703\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6244 - accuracy: 0.7311 - val_loss: 0.6652 - val_accuracy: 0.6748\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6187 - accuracy: 0.7340 - val_loss: 0.6645 - val_accuracy: 0.6766\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6153 - accuracy: 0.7351 - val_loss: 0.6597 - val_accuracy: 0.6786\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6138 - accuracy: 0.7353 - val_loss: 0.6622 - val_accuracy: 0.6783\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6098 - accuracy: 0.7373 - val_loss: 0.6552 - val_accuracy: 0.6811\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6063 - accuracy: 0.7380 - val_loss: 0.6542 - val_accuracy: 0.6823\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6054 - accuracy: 0.7395 - val_loss: 0.6554 - val_accuracy: 0.6818\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6033 - accuracy: 0.7403 - val_loss: 0.6468 - val_accuracy: 0.6849\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5989 - accuracy: 0.7417 - val_loss: 0.6478 - val_accuracy: 0.6851\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5971 - accuracy: 0.7438 - val_loss: 0.6441 - val_accuracy: 0.6858\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5972 - accuracy: 0.7432 - val_loss: 0.6471 - val_accuracy: 0.6856\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5952 - accuracy: 0.7432 - val_loss: 0.6438 - val_accuracy: 0.6867\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5921 - accuracy: 0.7447 - val_loss: 0.6448 - val_accuracy: 0.6852\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5904 - accuracy: 0.7456 - val_loss: 0.6376 - val_accuracy: 0.6893\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5897 - accuracy: 0.7464 - val_loss: 0.6434 - val_accuracy: 0.6867\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5884 - accuracy: 0.7458 - val_loss: 0.6354 - val_accuracy: 0.6893\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5879 - accuracy: 0.7465 - val_loss: 0.6365 - val_accuracy: 0.6884\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5863 - accuracy: 0.7472 - val_loss: 0.6347 - val_accuracy: 0.6900\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5841 - accuracy: 0.7486 - val_loss: 0.6355 - val_accuracy: 0.6899\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5822 - accuracy: 0.7484 - val_loss: 0.6328 - val_accuracy: 0.6909\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5826 - accuracy: 0.7482 - val_loss: 0.6339 - val_accuracy: 0.6917\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5827 - accuracy: 0.7495 - val_loss: 0.6304 - val_accuracy: 0.6921\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5797 - accuracy: 0.7500 - val_loss: 0.6328 - val_accuracy: 0.6922\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5796 - accuracy: 0.7501 - val_loss: 0.6294 - val_accuracy: 0.6933\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5788 - accuracy: 0.7500 - val_loss: 0.6319 - val_accuracy: 0.6920\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5774 - accuracy: 0.7517 - val_loss: 0.6285 - val_accuracy: 0.6935\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5768 - accuracy: 0.7509 - val_loss: 0.6277 - val_accuracy: 0.6950\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5770 - accuracy: 0.7509 - val_loss: 0.6287 - val_accuracy: 0.6937\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5738 - accuracy: 0.7521 - val_loss: 0.6297 - val_accuracy: 0.6931\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5744 - accuracy: 0.7527 - val_loss: 0.6279 - val_accuracy: 0.6942\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5735 - accuracy: 0.7526 - val_loss: 0.6276 - val_accuracy: 0.6940\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5706 - accuracy: 0.7536 - val_loss: 0.6257 - val_accuracy: 0.6952\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5719 - accuracy: 0.7540 - val_loss: 0.6275 - val_accuracy: 0.6958\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5712 - accuracy: 0.7533 - val_loss: 0.6251 - val_accuracy: 0.6964\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5700 - accuracy: 0.7542 - val_loss: 0.6225 - val_accuracy: 0.6972\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5688 - accuracy: 0.7557 - val_loss: 0.6203 - val_accuracy: 0.6985\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5682 - accuracy: 0.7547 - val_loss: 0.6180 - val_accuracy: 0.6985\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5671 - accuracy: 0.7551 - val_loss: 0.6219 - val_accuracy: 0.6973\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5674 - accuracy: 0.7546 - val_loss: 0.6203 - val_accuracy: 0.6980\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5672 - accuracy: 0.7553 - val_loss: 0.6174 - val_accuracy: 0.6988\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5665 - accuracy: 0.7545 - val_loss: 0.6248 - val_accuracy: 0.6961\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5658 - accuracy: 0.7563 - val_loss: 0.6203 - val_accuracy: 0.6982\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5648 - accuracy: 0.7570 - val_loss: 0.6192 - val_accuracy: 0.6987\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5629 - accuracy: 0.7563 - val_loss: 0.6183 - val_accuracy: 0.6990\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5633 - accuracy: 0.7569 - val_loss: 0.6162 - val_accuracy: 0.7000\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5612 - accuracy: 0.7575 - val_loss: 0.6194 - val_accuracy: 0.6989\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5630 - accuracy: 0.7574 - val_loss: 0.6147 - val_accuracy: 0.7002\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5623 - accuracy: 0.7564 - val_loss: 0.6171 - val_accuracy: 0.7010\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5615 - accuracy: 0.7574 - val_loss: 0.6181 - val_accuracy: 0.6996\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5619 - accuracy: 0.7581 - val_loss: 0.6164 - val_accuracy: 0.6995\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5608 - accuracy: 0.7572 - val_loss: 0.6160 - val_accuracy: 0.6986\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5591 - accuracy: 0.7576 - val_loss: 0.6147 - val_accuracy: 0.7009\n",
      "Early stopped after 69 epochs.\n",
      "1689/1689 [==============================] - 1s 845us/step - loss: 0.6147 - accuracy: 0.7002\n",
      "Validation accuracy: 0.7001757621765137\n",
      "\n",
      "Training model with 2 hidden layers, 64 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8048 - accuracy: 0.6367 - val_loss: 0.7113 - val_accuracy: 0.6528\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6618 - accuracy: 0.7157 - val_loss: 0.6886 - val_accuracy: 0.6674\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6336 - accuracy: 0.7280 - val_loss: 0.6586 - val_accuracy: 0.6806\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6236 - accuracy: 0.7323 - val_loss: 0.6575 - val_accuracy: 0.6815\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6154 - accuracy: 0.7349 - val_loss: 0.6524 - val_accuracy: 0.6861\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6065 - accuracy: 0.7375 - val_loss: 0.6380 - val_accuracy: 0.6912\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.6041 - accuracy: 0.7390 - val_loss: 0.6607 - val_accuracy: 0.6785\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.6012 - accuracy: 0.7399 - val_loss: 0.6504 - val_accuracy: 0.6852\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5968 - accuracy: 0.7418 - val_loss: 0.6517 - val_accuracy: 0.6865\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.5971 - accuracy: 0.7421 - val_loss: 0.6486 - val_accuracy: 0.6842\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.5943 - accuracy: 0.7428 - val_loss: 0.6385 - val_accuracy: 0.6868\n",
      "Early stopped after 11 epochs.\n",
      "1689/1689 [==============================] - 1s 842us/step - loss: 0.6380 - accuracy: 0.6912\n",
      "Validation accuracy: 0.6912202835083008\n",
      "\n",
      "Training model with 2 hidden layers, 64 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.8117 - accuracy: 0.6338 - val_loss: 0.8458 - val_accuracy: 0.5545\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7591 - accuracy: 0.6623 - val_loss: 0.8111 - val_accuracy: 0.5821\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7534 - accuracy: 0.6646 - val_loss: 0.8136 - val_accuracy: 0.5707\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7475 - accuracy: 0.6663 - val_loss: 0.7910 - val_accuracy: 0.5889\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7420 - accuracy: 0.6703 - val_loss: 0.7980 - val_accuracy: 0.5895\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7403 - accuracy: 0.6712 - val_loss: 0.8095 - val_accuracy: 0.5918\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7360 - accuracy: 0.6734 - val_loss: 0.7479 - val_accuracy: 0.6224\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7373 - accuracy: 0.6710 - val_loss: 0.7671 - val_accuracy: 0.5999\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7357 - accuracy: 0.6729 - val_loss: 0.7391 - val_accuracy: 0.5983\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7328 - accuracy: 0.6703 - val_loss: 0.8125 - val_accuracy: 0.5660\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7360 - accuracy: 0.6685 - val_loss: 0.7356 - val_accuracy: 0.6032\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7330 - accuracy: 0.6699 - val_loss: 0.7576 - val_accuracy: 0.5890\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7290 - accuracy: 0.6693 - val_loss: 0.7697 - val_accuracy: 0.5986\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7295 - accuracy: 0.6704 - val_loss: 0.7236 - val_accuracy: 0.6076\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7310 - accuracy: 0.6685 - val_loss: 0.7168 - val_accuracy: 0.6041\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7302 - accuracy: 0.6692 - val_loss: 0.7944 - val_accuracy: 0.5727\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7309 - accuracy: 0.6720 - val_loss: 0.7522 - val_accuracy: 0.6168\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7338 - accuracy: 0.6727 - val_loss: 0.7162 - val_accuracy: 0.6303\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7293 - accuracy: 0.6720 - val_loss: 0.7503 - val_accuracy: 0.5884\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7306 - accuracy: 0.6728 - val_loss: 0.7323 - val_accuracy: 0.6234\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7290 - accuracy: 0.6725 - val_loss: 0.7396 - val_accuracy: 0.6017\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 11s 1ms/step - loss: 0.7313 - accuracy: 0.6702 - val_loss: 0.7408 - val_accuracy: 0.6121\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 12s 1ms/step - loss: 0.7314 - accuracy: 0.6706 - val_loss: 0.7268 - val_accuracy: 0.6159\n",
      "Early stopped after 23 epochs.\n",
      "1689/1689 [==============================] - 1s 849us/step - loss: 0.7162 - accuracy: 0.6303\n",
      "Validation accuracy: 0.6303265690803528\n",
      "\n",
      "Training model with 2 hidden layers, 128 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.8192 - accuracy: 0.6294 - val_loss: 0.7542 - val_accuracy: 0.6504\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.6462 - accuracy: 0.7262 - val_loss: 0.6814 - val_accuracy: 0.6820\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5630 - accuracy: 0.7616 - val_loss: 0.6454 - val_accuracy: 0.6966\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5190 - accuracy: 0.7773 - val_loss: 0.6156 - val_accuracy: 0.7102\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4922 - accuracy: 0.7872 - val_loss: 0.6040 - val_accuracy: 0.7144\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4727 - accuracy: 0.7933 - val_loss: 0.5780 - val_accuracy: 0.7239\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4572 - accuracy: 0.7987 - val_loss: 0.5835 - val_accuracy: 0.7225\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4449 - accuracy: 0.8024 - val_loss: 0.5655 - val_accuracy: 0.7299\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4356 - accuracy: 0.8052 - val_loss: 0.5612 - val_accuracy: 0.7322\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4279 - accuracy: 0.8078 - val_loss: 0.5502 - val_accuracy: 0.7374\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4208 - accuracy: 0.8104 - val_loss: 0.5489 - val_accuracy: 0.7389\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4155 - accuracy: 0.8123 - val_loss: 0.5395 - val_accuracy: 0.7435\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5354 - val_accuracy: 0.7454\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4058 - accuracy: 0.8155 - val_loss: 0.5260 - val_accuracy: 0.7501\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4015 - accuracy: 0.8175 - val_loss: 0.5202 - val_accuracy: 0.7527\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3989 - accuracy: 0.8189 - val_loss: 0.5190 - val_accuracy: 0.7551\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3956 - accuracy: 0.8200 - val_loss: 0.5155 - val_accuracy: 0.7572\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3924 - accuracy: 0.8211 - val_loss: 0.5126 - val_accuracy: 0.7572\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3892 - accuracy: 0.8221 - val_loss: 0.5124 - val_accuracy: 0.7578\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3872 - accuracy: 0.8234 - val_loss: 0.5079 - val_accuracy: 0.7611\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3839 - accuracy: 0.8249 - val_loss: 0.5020 - val_accuracy: 0.7629\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3820 - accuracy: 0.8257 - val_loss: 0.5034 - val_accuracy: 0.7640\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3797 - accuracy: 0.8267 - val_loss: 0.4978 - val_accuracy: 0.7659\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3779 - accuracy: 0.8269 - val_loss: 0.4935 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3761 - accuracy: 0.8272 - val_loss: 0.4932 - val_accuracy: 0.7690\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3740 - accuracy: 0.8284 - val_loss: 0.4891 - val_accuracy: 0.7715\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3726 - accuracy: 0.8302 - val_loss: 0.4879 - val_accuracy: 0.7717\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3700 - accuracy: 0.8307 - val_loss: 0.4848 - val_accuracy: 0.7739\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3686 - accuracy: 0.8327 - val_loss: 0.4833 - val_accuracy: 0.7761\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3671 - accuracy: 0.8325 - val_loss: 0.4801 - val_accuracy: 0.7766\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3658 - accuracy: 0.8325 - val_loss: 0.4783 - val_accuracy: 0.7785\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3636 - accuracy: 0.8344 - val_loss: 0.4748 - val_accuracy: 0.7809\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3628 - accuracy: 0.8346 - val_loss: 0.4711 - val_accuracy: 0.7838\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3614 - accuracy: 0.8346 - val_loss: 0.4691 - val_accuracy: 0.7817\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3600 - accuracy: 0.8362 - val_loss: 0.4684 - val_accuracy: 0.7835\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3583 - accuracy: 0.8368 - val_loss: 0.4673 - val_accuracy: 0.7863\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3570 - accuracy: 0.8377 - val_loss: 0.4684 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3551 - accuracy: 0.8377 - val_loss: 0.4631 - val_accuracy: 0.7867\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3540 - accuracy: 0.8387 - val_loss: 0.4599 - val_accuracy: 0.7900\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3538 - accuracy: 0.8387 - val_loss: 0.4557 - val_accuracy: 0.7916\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3519 - accuracy: 0.8396 - val_loss: 0.4568 - val_accuracy: 0.7923\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3512 - accuracy: 0.8399 - val_loss: 0.4509 - val_accuracy: 0.7931\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3498 - accuracy: 0.8414 - val_loss: 0.4479 - val_accuracy: 0.7938\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3484 - accuracy: 0.8416 - val_loss: 0.4471 - val_accuracy: 0.7954\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3477 - accuracy: 0.8414 - val_loss: 0.4467 - val_accuracy: 0.8002\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3462 - accuracy: 0.8429 - val_loss: 0.4439 - val_accuracy: 0.7992\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3455 - accuracy: 0.8427 - val_loss: 0.4423 - val_accuracy: 0.7999\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3444 - accuracy: 0.8443 - val_loss: 0.4407 - val_accuracy: 0.8006\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3430 - accuracy: 0.8438 - val_loss: 0.4411 - val_accuracy: 0.8020\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3428 - accuracy: 0.8446 - val_loss: 0.4405 - val_accuracy: 0.8020\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3418 - accuracy: 0.8448 - val_loss: 0.4388 - val_accuracy: 0.8028\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3404 - accuracy: 0.8457 - val_loss: 0.4341 - val_accuracy: 0.8053\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3403 - accuracy: 0.8466 - val_loss: 0.4328 - val_accuracy: 0.8054\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3387 - accuracy: 0.8472 - val_loss: 0.4338 - val_accuracy: 0.8069\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3385 - accuracy: 0.8471 - val_loss: 0.4286 - val_accuracy: 0.8080\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3373 - accuracy: 0.8476 - val_loss: 0.4303 - val_accuracy: 0.8095\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3362 - accuracy: 0.8476 - val_loss: 0.4258 - val_accuracy: 0.8115\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3357 - accuracy: 0.8489 - val_loss: 0.4252 - val_accuracy: 0.8108\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3345 - accuracy: 0.8487 - val_loss: 0.4252 - val_accuracy: 0.8115\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3344 - accuracy: 0.8492 - val_loss: 0.4247 - val_accuracy: 0.8137\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3341 - accuracy: 0.8497 - val_loss: 0.4221 - val_accuracy: 0.8145\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3326 - accuracy: 0.8502 - val_loss: 0.4210 - val_accuracy: 0.8163\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3317 - accuracy: 0.8504 - val_loss: 0.4172 - val_accuracy: 0.8160\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3302 - accuracy: 0.8517 - val_loss: 0.4193 - val_accuracy: 0.8177\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3305 - accuracy: 0.8516 - val_loss: 0.4161 - val_accuracy: 0.8161\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3294 - accuracy: 0.8515 - val_loss: 0.4147 - val_accuracy: 0.8177\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3281 - accuracy: 0.8525 - val_loss: 0.4125 - val_accuracy: 0.8193\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3280 - accuracy: 0.8524 - val_loss: 0.4116 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3276 - accuracy: 0.8528 - val_loss: 0.4112 - val_accuracy: 0.8199\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3268 - accuracy: 0.8535 - val_loss: 0.4103 - val_accuracy: 0.8206\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3252 - accuracy: 0.8540 - val_loss: 0.4068 - val_accuracy: 0.8206\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3248 - accuracy: 0.8545 - val_loss: 0.4067 - val_accuracy: 0.8241\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3240 - accuracy: 0.8547 - val_loss: 0.4062 - val_accuracy: 0.8236\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3229 - accuracy: 0.8548 - val_loss: 0.4017 - val_accuracy: 0.8232\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3235 - accuracy: 0.8542 - val_loss: 0.4064 - val_accuracy: 0.8244\n",
      "Epoch 76/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3216 - accuracy: 0.8552 - val_loss: 0.4024 - val_accuracy: 0.8253\n",
      "Epoch 77/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3220 - accuracy: 0.8565 - val_loss: 0.3998 - val_accuracy: 0.8255\n",
      "Epoch 78/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3215 - accuracy: 0.8560 - val_loss: 0.4017 - val_accuracy: 0.8259\n",
      "Epoch 79/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3208 - accuracy: 0.8572 - val_loss: 0.3997 - val_accuracy: 0.8267\n",
      "Epoch 80/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3215 - accuracy: 0.8557 - val_loss: 0.3973 - val_accuracy: 0.8276\n",
      "Epoch 81/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3203 - accuracy: 0.8565 - val_loss: 0.3966 - val_accuracy: 0.8258\n",
      "Epoch 82/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3190 - accuracy: 0.8578 - val_loss: 0.3980 - val_accuracy: 0.8280\n",
      "Epoch 83/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3192 - accuracy: 0.8576 - val_loss: 0.3968 - val_accuracy: 0.8293\n",
      "Epoch 84/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3179 - accuracy: 0.8578 - val_loss: 0.3922 - val_accuracy: 0.8310\n",
      "Epoch 85/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3166 - accuracy: 0.8589 - val_loss: 0.3935 - val_accuracy: 0.8305\n",
      "Epoch 86/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3173 - accuracy: 0.8579 - val_loss: 0.3924 - val_accuracy: 0.8318\n",
      "Epoch 87/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3170 - accuracy: 0.8584 - val_loss: 0.3898 - val_accuracy: 0.8304\n",
      "Epoch 88/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3158 - accuracy: 0.8589 - val_loss: 0.3911 - val_accuracy: 0.8312\n",
      "Epoch 89/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3159 - accuracy: 0.8592 - val_loss: 0.3920 - val_accuracy: 0.8325\n",
      "Epoch 90/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3155 - accuracy: 0.8581 - val_loss: 0.3877 - val_accuracy: 0.8341\n",
      "Epoch 91/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3139 - accuracy: 0.8601 - val_loss: 0.3899 - val_accuracy: 0.8354\n",
      "Epoch 92/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3145 - accuracy: 0.8605 - val_loss: 0.3874 - val_accuracy: 0.8358\n",
      "Epoch 93/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3142 - accuracy: 0.8598 - val_loss: 0.3837 - val_accuracy: 0.8358\n",
      "Epoch 94/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3135 - accuracy: 0.8600 - val_loss: 0.3875 - val_accuracy: 0.8355\n",
      "Epoch 95/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3123 - accuracy: 0.8612 - val_loss: 0.3817 - val_accuracy: 0.8365\n",
      "Epoch 96/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3130 - accuracy: 0.8598 - val_loss: 0.3840 - val_accuracy: 0.8358\n",
      "Epoch 97/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3130 - accuracy: 0.8609 - val_loss: 0.3836 - val_accuracy: 0.8370\n",
      "Epoch 98/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3122 - accuracy: 0.8605 - val_loss: 0.3834 - val_accuracy: 0.8382\n",
      "Epoch 99/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3113 - accuracy: 0.8611 - val_loss: 0.3807 - val_accuracy: 0.8389\n",
      "Epoch 100/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3096 - accuracy: 0.8622 - val_loss: 0.3812 - val_accuracy: 0.8383\n",
      "Early stopped after 100 epochs.\n",
      "1689/1689 [==============================] - 1s 856us/step - loss: 0.3812 - accuracy: 0.8383\n",
      "Validation accuracy: 0.8382644057273865\n",
      "\n",
      "Training model with 2 hidden layers, 128 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 14s 1ms/step - loss: 0.5579 - accuracy: 0.7570 - val_loss: 0.5797 - val_accuracy: 0.7282\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4274 - accuracy: 0.8089 - val_loss: 0.5281 - val_accuracy: 0.7498\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3985 - accuracy: 0.8205 - val_loss: 0.4952 - val_accuracy: 0.7685\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3822 - accuracy: 0.8282 - val_loss: 0.4885 - val_accuracy: 0.7754\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3707 - accuracy: 0.8342 - val_loss: 0.4710 - val_accuracy: 0.7836\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3626 - accuracy: 0.8378 - val_loss: 0.4582 - val_accuracy: 0.7935\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3557 - accuracy: 0.8405 - val_loss: 0.4559 - val_accuracy: 0.7975\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3510 - accuracy: 0.8439 - val_loss: 0.4526 - val_accuracy: 0.8011\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3467 - accuracy: 0.8454 - val_loss: 0.4391 - val_accuracy: 0.8106\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3418 - accuracy: 0.8485 - val_loss: 0.4265 - val_accuracy: 0.8149\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3382 - accuracy: 0.8497 - val_loss: 0.4141 - val_accuracy: 0.8184\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3350 - accuracy: 0.8514 - val_loss: 0.4220 - val_accuracy: 0.8172\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3332 - accuracy: 0.8526 - val_loss: 0.4115 - val_accuracy: 0.8222\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3306 - accuracy: 0.8541 - val_loss: 0.4089 - val_accuracy: 0.8262\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3275 - accuracy: 0.8551 - val_loss: 0.3987 - val_accuracy: 0.8233\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3258 - accuracy: 0.8562 - val_loss: 0.4004 - val_accuracy: 0.8313\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3234 - accuracy: 0.8578 - val_loss: 0.3946 - val_accuracy: 0.8325\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3230 - accuracy: 0.8577 - val_loss: 0.3898 - val_accuracy: 0.8332\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3208 - accuracy: 0.8594 - val_loss: 0.3828 - val_accuracy: 0.8343\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3190 - accuracy: 0.8603 - val_loss: 0.3830 - val_accuracy: 0.8363\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3162 - accuracy: 0.8614 - val_loss: 0.3884 - val_accuracy: 0.8385\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3155 - accuracy: 0.8620 - val_loss: 0.3809 - val_accuracy: 0.8390\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3140 - accuracy: 0.8624 - val_loss: 0.3787 - val_accuracy: 0.8424\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3115 - accuracy: 0.8638 - val_loss: 0.3696 - val_accuracy: 0.8434\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3109 - accuracy: 0.8637 - val_loss: 0.3735 - val_accuracy: 0.8444\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3118 - accuracy: 0.8638 - val_loss: 0.3714 - val_accuracy: 0.8435\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3095 - accuracy: 0.8648 - val_loss: 0.3712 - val_accuracy: 0.8432\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3089 - accuracy: 0.8656 - val_loss: 0.3701 - val_accuracy: 0.8456\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3073 - accuracy: 0.8664 - val_loss: 0.3728 - val_accuracy: 0.8449\n",
      "Early stopped after 29 epochs.\n",
      "1689/1689 [==============================] - 2s 900us/step - loss: 0.3696 - accuracy: 0.8434\n",
      "Validation accuracy: 0.8434082865715027\n",
      "\n",
      "Training model with 2 hidden layers, 128 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5814 - accuracy: 0.7441 - val_loss: 0.6047 - val_accuracy: 0.7050\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5127 - accuracy: 0.7745 - val_loss: 0.5947 - val_accuracy: 0.7092\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5015 - accuracy: 0.7786 - val_loss: 0.5832 - val_accuracy: 0.7171\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4904 - accuracy: 0.7833 - val_loss: 0.5698 - val_accuracy: 0.7286\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4855 - accuracy: 0.7852 - val_loss: 0.5809 - val_accuracy: 0.7218\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4856 - accuracy: 0.7845 - val_loss: 0.5708 - val_accuracy: 0.7209\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4792 - accuracy: 0.7877 - val_loss: 0.5462 - val_accuracy: 0.7354\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4773 - accuracy: 0.7887 - val_loss: 0.5698 - val_accuracy: 0.7149\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4776 - accuracy: 0.7892 - val_loss: 0.5344 - val_accuracy: 0.7452\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4726 - accuracy: 0.7912 - val_loss: 0.5462 - val_accuracy: 0.7303\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4713 - accuracy: 0.7925 - val_loss: 0.5232 - val_accuracy: 0.7416\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4712 - accuracy: 0.7916 - val_loss: 0.5353 - val_accuracy: 0.7278\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4701 - accuracy: 0.7930 - val_loss: 0.5539 - val_accuracy: 0.7328\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4689 - accuracy: 0.7938 - val_loss: 0.5552 - val_accuracy: 0.7313\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4661 - accuracy: 0.7947 - val_loss: 0.5256 - val_accuracy: 0.7428\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4652 - accuracy: 0.7954 - val_loss: 0.5709 - val_accuracy: 0.7168\n",
      "Early stopped after 16 epochs.\n",
      "1689/1689 [==============================] - 2s 880us/step - loss: 0.5232 - accuracy: 0.7416\n",
      "Validation accuracy: 0.7415671944618225\n",
      "\n",
      "Training model with 2 hidden layers, 128 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 14s 1ms/step - loss: 0.9277 - accuracy: 0.5548 - val_loss: 0.8385 - val_accuracy: 0.6283\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.8098 - accuracy: 0.6390 - val_loss: 0.7831 - val_accuracy: 0.6337\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7291 - accuracy: 0.6858 - val_loss: 0.7216 - val_accuracy: 0.6665\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.6707 - accuracy: 0.7157 - val_loss: 0.6935 - val_accuracy: 0.6812\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.6274 - accuracy: 0.7351 - val_loss: 0.6769 - val_accuracy: 0.6884\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5971 - accuracy: 0.7480 - val_loss: 0.6410 - val_accuracy: 0.7030\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5748 - accuracy: 0.7574 - val_loss: 0.6328 - val_accuracy: 0.7068\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5547 - accuracy: 0.7645 - val_loss: 0.6202 - val_accuracy: 0.7113\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5403 - accuracy: 0.7704 - val_loss: 0.6149 - val_accuracy: 0.7128\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5297 - accuracy: 0.7735 - val_loss: 0.6076 - val_accuracy: 0.7156\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5207 - accuracy: 0.7768 - val_loss: 0.6052 - val_accuracy: 0.7171\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5137 - accuracy: 0.7793 - val_loss: 0.5967 - val_accuracy: 0.7202\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5055 - accuracy: 0.7819 - val_loss: 0.5901 - val_accuracy: 0.7229\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4998 - accuracy: 0.7847 - val_loss: 0.5860 - val_accuracy: 0.7242\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4952 - accuracy: 0.7857 - val_loss: 0.5879 - val_accuracy: 0.7238\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4903 - accuracy: 0.7882 - val_loss: 0.5790 - val_accuracy: 0.7257\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4862 - accuracy: 0.7887 - val_loss: 0.5743 - val_accuracy: 0.7281\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4832 - accuracy: 0.7895 - val_loss: 0.5762 - val_accuracy: 0.7290\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4791 - accuracy: 0.7914 - val_loss: 0.5734 - val_accuracy: 0.7289\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4785 - accuracy: 0.7922 - val_loss: 0.5726 - val_accuracy: 0.7289\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4747 - accuracy: 0.7938 - val_loss: 0.5696 - val_accuracy: 0.7316\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4725 - accuracy: 0.7942 - val_loss: 0.5665 - val_accuracy: 0.7326\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4704 - accuracy: 0.7946 - val_loss: 0.5656 - val_accuracy: 0.7322\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4686 - accuracy: 0.7952 - val_loss: 0.5623 - val_accuracy: 0.7339\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4669 - accuracy: 0.7948 - val_loss: 0.5635 - val_accuracy: 0.7344\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4640 - accuracy: 0.7970 - val_loss: 0.5626 - val_accuracy: 0.7347\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4622 - accuracy: 0.7977 - val_loss: 0.5573 - val_accuracy: 0.7368\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4619 - accuracy: 0.7980 - val_loss: 0.5578 - val_accuracy: 0.7357\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4599 - accuracy: 0.7985 - val_loss: 0.5579 - val_accuracy: 0.7367\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4582 - accuracy: 0.7986 - val_loss: 0.5505 - val_accuracy: 0.7385\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4563 - accuracy: 0.7993 - val_loss: 0.5570 - val_accuracy: 0.7367\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4562 - accuracy: 0.7993 - val_loss: 0.5506 - val_accuracy: 0.7393\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4555 - accuracy: 0.8001 - val_loss: 0.5516 - val_accuracy: 0.7376\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4525 - accuracy: 0.7999 - val_loss: 0.5541 - val_accuracy: 0.7377\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4519 - accuracy: 0.8005 - val_loss: 0.5489 - val_accuracy: 0.7397\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4513 - accuracy: 0.8006 - val_loss: 0.5477 - val_accuracy: 0.7403\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4504 - accuracy: 0.8018 - val_loss: 0.5494 - val_accuracy: 0.7399\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4492 - accuracy: 0.8012 - val_loss: 0.5466 - val_accuracy: 0.7401\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4487 - accuracy: 0.8017 - val_loss: 0.5466 - val_accuracy: 0.7407\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4471 - accuracy: 0.8018 - val_loss: 0.5412 - val_accuracy: 0.7419\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4464 - accuracy: 0.8028 - val_loss: 0.5441 - val_accuracy: 0.7412\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4471 - accuracy: 0.8031 - val_loss: 0.5435 - val_accuracy: 0.7423\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4466 - accuracy: 0.8027 - val_loss: 0.5438 - val_accuracy: 0.7418\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4456 - accuracy: 0.8031 - val_loss: 0.5408 - val_accuracy: 0.7427\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4440 - accuracy: 0.8035 - val_loss: 0.5428 - val_accuracy: 0.7427\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4442 - accuracy: 0.8040 - val_loss: 0.5429 - val_accuracy: 0.7434\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4429 - accuracy: 0.8037 - val_loss: 0.5391 - val_accuracy: 0.7445\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4412 - accuracy: 0.8045 - val_loss: 0.5385 - val_accuracy: 0.7443\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4421 - accuracy: 0.8050 - val_loss: 0.5394 - val_accuracy: 0.7446\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4408 - accuracy: 0.8046 - val_loss: 0.5343 - val_accuracy: 0.7457\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4411 - accuracy: 0.8049 - val_loss: 0.5397 - val_accuracy: 0.7438\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4407 - accuracy: 0.8048 - val_loss: 0.5335 - val_accuracy: 0.7462\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4393 - accuracy: 0.8053 - val_loss: 0.5372 - val_accuracy: 0.7447\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4393 - accuracy: 0.8061 - val_loss: 0.5337 - val_accuracy: 0.7458\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4382 - accuracy: 0.8057 - val_loss: 0.5343 - val_accuracy: 0.7465\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4384 - accuracy: 0.8059 - val_loss: 0.5378 - val_accuracy: 0.7454\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4379 - accuracy: 0.8053 - val_loss: 0.5351 - val_accuracy: 0.7467\n",
      "Early stopped after 57 epochs.\n",
      "1689/1689 [==============================] - 2s 879us/step - loss: 0.5335 - accuracy: 0.7462\n",
      "Validation accuracy: 0.7462114691734314\n",
      "\n",
      "Training model with 2 hidden layers, 128 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 14s 1ms/step - loss: 0.6895 - accuracy: 0.6966 - val_loss: 0.6316 - val_accuracy: 0.7022\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5424 - accuracy: 0.7666 - val_loss: 0.6059 - val_accuracy: 0.7131\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5133 - accuracy: 0.7781 - val_loss: 0.5896 - val_accuracy: 0.7240\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4999 - accuracy: 0.7829 - val_loss: 0.5765 - val_accuracy: 0.7277\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4937 - accuracy: 0.7853 - val_loss: 0.5786 - val_accuracy: 0.7260\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4850 - accuracy: 0.7878 - val_loss: 0.5735 - val_accuracy: 0.7318\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4810 - accuracy: 0.7896 - val_loss: 0.5616 - val_accuracy: 0.7351\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4764 - accuracy: 0.7911 - val_loss: 0.5594 - val_accuracy: 0.7372\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4756 - accuracy: 0.7917 - val_loss: 0.5610 - val_accuracy: 0.7352\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4724 - accuracy: 0.7932 - val_loss: 0.5561 - val_accuracy: 0.7375\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4696 - accuracy: 0.7938 - val_loss: 0.5535 - val_accuracy: 0.7400\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4683 - accuracy: 0.7940 - val_loss: 0.5590 - val_accuracy: 0.7374\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4660 - accuracy: 0.7951 - val_loss: 0.5644 - val_accuracy: 0.7377\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4654 - accuracy: 0.7956 - val_loss: 0.5444 - val_accuracy: 0.7439\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4634 - accuracy: 0.7959 - val_loss: 0.5505 - val_accuracy: 0.7402\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4596 - accuracy: 0.7975 - val_loss: 0.5444 - val_accuracy: 0.7432\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4602 - accuracy: 0.7963 - val_loss: 0.5425 - val_accuracy: 0.7450\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4603 - accuracy: 0.7966 - val_loss: 0.5383 - val_accuracy: 0.7456\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4597 - accuracy: 0.7971 - val_loss: 0.5511 - val_accuracy: 0.7415\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4570 - accuracy: 0.7979 - val_loss: 0.5417 - val_accuracy: 0.7440\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4568 - accuracy: 0.7983 - val_loss: 0.5516 - val_accuracy: 0.7406\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4562 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7445\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4539 - accuracy: 0.7993 - val_loss: 0.5359 - val_accuracy: 0.7476\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4534 - accuracy: 0.7999 - val_loss: 0.5313 - val_accuracy: 0.7492\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4536 - accuracy: 0.7990 - val_loss: 0.5537 - val_accuracy: 0.7425\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4530 - accuracy: 0.7987 - val_loss: 0.5355 - val_accuracy: 0.7484\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4501 - accuracy: 0.8014 - val_loss: 0.5346 - val_accuracy: 0.7490\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4511 - accuracy: 0.8012 - val_loss: 0.5388 - val_accuracy: 0.7455\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4492 - accuracy: 0.8013 - val_loss: 0.5324 - val_accuracy: 0.7493\n",
      "Early stopped after 29 epochs.\n",
      "1689/1689 [==============================] - 2s 884us/step - loss: 0.5313 - accuracy: 0.7492\n",
      "Validation accuracy: 0.7492460012435913\n",
      "\n",
      "Training model with 2 hidden layers, 128 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 14s 1ms/step - loss: 0.7946 - accuracy: 0.6464 - val_loss: 0.7934 - val_accuracy: 0.5602\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7402 - accuracy: 0.6728 - val_loss: 0.7623 - val_accuracy: 0.6029\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7308 - accuracy: 0.6762 - val_loss: 0.8071 - val_accuracy: 0.5405\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7293 - accuracy: 0.6776 - val_loss: 0.7632 - val_accuracy: 0.6004\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7183 - accuracy: 0.6822 - val_loss: 0.7537 - val_accuracy: 0.5941\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7122 - accuracy: 0.6838 - val_loss: 0.7266 - val_accuracy: 0.6213\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7137 - accuracy: 0.6844 - val_loss: 0.7205 - val_accuracy: 0.6127\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7105 - accuracy: 0.6846 - val_loss: 0.7588 - val_accuracy: 0.5908\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7099 - accuracy: 0.6842 - val_loss: 0.7183 - val_accuracy: 0.6104\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7073 - accuracy: 0.6834 - val_loss: 0.7402 - val_accuracy: 0.6098\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7112 - accuracy: 0.6862 - val_loss: 0.7069 - val_accuracy: 0.6297\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7078 - accuracy: 0.6860 - val_loss: 0.7065 - val_accuracy: 0.6177\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7101 - accuracy: 0.6851 - val_loss: 0.7273 - val_accuracy: 0.6205\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7073 - accuracy: 0.6857 - val_loss: 0.7007 - val_accuracy: 0.6404\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7084 - accuracy: 0.6842 - val_loss: 0.6995 - val_accuracy: 0.6359\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7017 - accuracy: 0.6865 - val_loss: 0.7279 - val_accuracy: 0.6363\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7050 - accuracy: 0.6833 - val_loss: 0.7158 - val_accuracy: 0.6136\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7005 - accuracy: 0.6844 - val_loss: 0.7183 - val_accuracy: 0.6215\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7042 - accuracy: 0.6821 - val_loss: 0.7152 - val_accuracy: 0.6320\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7010 - accuracy: 0.6821 - val_loss: 0.7099 - val_accuracy: 0.6298\n",
      "Early stopped after 20 epochs.\n",
      "1689/1689 [==============================] - 2s 884us/step - loss: 0.6995 - accuracy: 0.6359\n",
      "Validation accuracy: 0.6359330415725708\n",
      "\n",
      "Training model with 2 hidden layers, 256 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7362 - accuracy: 0.6796 - val_loss: 0.6902 - val_accuracy: 0.6779\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.5499 - accuracy: 0.7682 - val_loss: 0.6488 - val_accuracy: 0.6977\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4862 - accuracy: 0.7909 - val_loss: 0.6082 - val_accuracy: 0.7174\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4530 - accuracy: 0.8019 - val_loss: 0.5734 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4316 - accuracy: 0.8086 - val_loss: 0.5737 - val_accuracy: 0.7310\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4159 - accuracy: 0.8137 - val_loss: 0.5494 - val_accuracy: 0.7393\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4046 - accuracy: 0.8177 - val_loss: 0.5403 - val_accuracy: 0.7450\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3948 - accuracy: 0.8213 - val_loss: 0.5264 - val_accuracy: 0.7512\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3862 - accuracy: 0.8252 - val_loss: 0.5118 - val_accuracy: 0.7557\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3794 - accuracy: 0.8275 - val_loss: 0.5060 - val_accuracy: 0.7620\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3746 - accuracy: 0.8301 - val_loss: 0.4959 - val_accuracy: 0.7685\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3694 - accuracy: 0.8319 - val_loss: 0.4929 - val_accuracy: 0.7721\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3640 - accuracy: 0.8344 - val_loss: 0.4905 - val_accuracy: 0.7751\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3606 - accuracy: 0.8366 - val_loss: 0.4762 - val_accuracy: 0.7785\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 28s 3ms/step - loss: 0.3556 - accuracy: 0.8386 - val_loss: 0.4720 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 29s 3ms/step - loss: 0.3511 - accuracy: 0.8400 - val_loss: 0.4679 - val_accuracy: 0.7867\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3477 - accuracy: 0.8416 - val_loss: 0.4575 - val_accuracy: 0.7909\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3441 - accuracy: 0.8438 - val_loss: 0.4607 - val_accuracy: 0.7940\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3408 - accuracy: 0.8454 - val_loss: 0.4532 - val_accuracy: 0.7951\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3370 - accuracy: 0.8474 - val_loss: 0.4453 - val_accuracy: 0.7973\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3347 - accuracy: 0.8487 - val_loss: 0.4389 - val_accuracy: 0.8009\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3317 - accuracy: 0.8499 - val_loss: 0.4333 - val_accuracy: 0.8062\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3295 - accuracy: 0.8510 - val_loss: 0.4301 - val_accuracy: 0.8069\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3256 - accuracy: 0.8534 - val_loss: 0.4204 - val_accuracy: 0.8106\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3228 - accuracy: 0.8544 - val_loss: 0.4198 - val_accuracy: 0.8139\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3203 - accuracy: 0.8562 - val_loss: 0.4164 - val_accuracy: 0.8171\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3177 - accuracy: 0.8572 - val_loss: 0.4166 - val_accuracy: 0.8183\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3154 - accuracy: 0.8584 - val_loss: 0.4063 - val_accuracy: 0.8216\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3133 - accuracy: 0.8590 - val_loss: 0.4045 - val_accuracy: 0.8243\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3104 - accuracy: 0.8612 - val_loss: 0.3950 - val_accuracy: 0.8266\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3087 - accuracy: 0.8610 - val_loss: 0.3964 - val_accuracy: 0.8281\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3064 - accuracy: 0.8630 - val_loss: 0.3902 - val_accuracy: 0.8290\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3039 - accuracy: 0.8645 - val_loss: 0.3878 - val_accuracy: 0.8305\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3018 - accuracy: 0.8650 - val_loss: 0.3859 - val_accuracy: 0.8369\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2998 - accuracy: 0.8663 - val_loss: 0.3836 - val_accuracy: 0.8365\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2978 - accuracy: 0.8679 - val_loss: 0.3740 - val_accuracy: 0.8385\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2953 - accuracy: 0.8687 - val_loss: 0.3738 - val_accuracy: 0.8409\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2937 - accuracy: 0.8696 - val_loss: 0.3685 - val_accuracy: 0.8412\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 21s 2ms/step - loss: 0.2912 - accuracy: 0.8709 - val_loss: 0.3696 - val_accuracy: 0.8433\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 21s 2ms/step - loss: 0.2895 - accuracy: 0.8714 - val_loss: 0.3624 - val_accuracy: 0.8455\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2878 - accuracy: 0.8727 - val_loss: 0.3591 - val_accuracy: 0.8471\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2864 - accuracy: 0.8736 - val_loss: 0.3576 - val_accuracy: 0.8488\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 29s 3ms/step - loss: 0.2837 - accuracy: 0.8750 - val_loss: 0.3514 - val_accuracy: 0.8514\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2830 - accuracy: 0.8752 - val_loss: 0.3504 - val_accuracy: 0.8520\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2804 - accuracy: 0.8765 - val_loss: 0.3455 - val_accuracy: 0.8545\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2801 - accuracy: 0.8760 - val_loss: 0.3445 - val_accuracy: 0.8550\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2777 - accuracy: 0.8778 - val_loss: 0.3410 - val_accuracy: 0.8563\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2763 - accuracy: 0.8782 - val_loss: 0.3380 - val_accuracy: 0.8574\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2746 - accuracy: 0.8786 - val_loss: 0.3336 - val_accuracy: 0.8616\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2728 - accuracy: 0.8801 - val_loss: 0.3309 - val_accuracy: 0.8619\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.2714 - accuracy: 0.8809 - val_loss: 0.3299 - val_accuracy: 0.8634\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 57s 6ms/step - loss: 0.2712 - accuracy: 0.8809 - val_loss: 0.3280 - val_accuracy: 0.8641\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2690 - accuracy: 0.8810 - val_loss: 0.3255 - val_accuracy: 0.8669\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2673 - accuracy: 0.8833 - val_loss: 0.3212 - val_accuracy: 0.8654\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.2669 - accuracy: 0.8834 - val_loss: 0.3180 - val_accuracy: 0.8674\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2651 - accuracy: 0.8837 - val_loss: 0.3191 - val_accuracy: 0.8712\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2639 - accuracy: 0.8844 - val_loss: 0.3163 - val_accuracy: 0.8734\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2624 - accuracy: 0.8856 - val_loss: 0.3172 - val_accuracy: 0.8728\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2613 - accuracy: 0.8862 - val_loss: 0.3123 - val_accuracy: 0.8732\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2600 - accuracy: 0.8865 - val_loss: 0.3086 - val_accuracy: 0.8742\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2588 - accuracy: 0.8872 - val_loss: 0.3082 - val_accuracy: 0.8762\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2588 - accuracy: 0.8870 - val_loss: 0.3068 - val_accuracy: 0.8753\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2572 - accuracy: 0.8879 - val_loss: 0.3056 - val_accuracy: 0.8759\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2561 - accuracy: 0.8889 - val_loss: 0.3025 - val_accuracy: 0.8801\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2547 - accuracy: 0.8886 - val_loss: 0.2991 - val_accuracy: 0.8800\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2535 - accuracy: 0.8904 - val_loss: 0.2984 - val_accuracy: 0.8788\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2523 - accuracy: 0.8904 - val_loss: 0.2948 - val_accuracy: 0.8817\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2519 - accuracy: 0.8903 - val_loss: 0.2957 - val_accuracy: 0.8805\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2513 - accuracy: 0.8909 - val_loss: 0.2932 - val_accuracy: 0.8800\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2501 - accuracy: 0.8916 - val_loss: 0.2900 - val_accuracy: 0.8840\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2494 - accuracy: 0.8917 - val_loss: 0.2907 - val_accuracy: 0.8823\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2483 - accuracy: 0.8922 - val_loss: 0.2887 - val_accuracy: 0.8866\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2477 - accuracy: 0.8931 - val_loss: 0.2867 - val_accuracy: 0.8861\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2453 - accuracy: 0.8938 - val_loss: 0.2855 - val_accuracy: 0.8852\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2446 - accuracy: 0.8936 - val_loss: 0.2826 - val_accuracy: 0.8860\n",
      "Epoch 76/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2453 - accuracy: 0.8940 - val_loss: 0.2837 - val_accuracy: 0.8888\n",
      "Epoch 77/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2432 - accuracy: 0.8948 - val_loss: 0.2803 - val_accuracy: 0.8880\n",
      "Epoch 78/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2419 - accuracy: 0.8956 - val_loss: 0.2763 - val_accuracy: 0.8883\n",
      "Epoch 79/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2413 - accuracy: 0.8955 - val_loss: 0.2783 - val_accuracy: 0.8879\n",
      "Epoch 80/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2406 - accuracy: 0.8963 - val_loss: 0.2763 - val_accuracy: 0.8897\n",
      "Epoch 81/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2404 - accuracy: 0.8956 - val_loss: 0.2774 - val_accuracy: 0.8890\n",
      "Epoch 82/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2395 - accuracy: 0.8967 - val_loss: 0.2744 - val_accuracy: 0.8917\n",
      "Epoch 83/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2388 - accuracy: 0.8971 - val_loss: 0.2726 - val_accuracy: 0.8898\n",
      "Epoch 84/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2375 - accuracy: 0.8979 - val_loss: 0.2722 - val_accuracy: 0.8923\n",
      "Epoch 85/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2371 - accuracy: 0.8981 - val_loss: 0.2678 - val_accuracy: 0.8934\n",
      "Epoch 86/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2370 - accuracy: 0.8981 - val_loss: 0.2693 - val_accuracy: 0.8946\n",
      "Epoch 87/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2359 - accuracy: 0.8984 - val_loss: 0.2677 - val_accuracy: 0.8927\n",
      "Epoch 88/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2338 - accuracy: 0.8987 - val_loss: 0.2655 - val_accuracy: 0.8954\n",
      "Epoch 89/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2341 - accuracy: 0.8994 - val_loss: 0.2637 - val_accuracy: 0.8962\n",
      "Epoch 90/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2330 - accuracy: 0.8992 - val_loss: 0.2626 - val_accuracy: 0.8956\n",
      "Epoch 91/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2330 - accuracy: 0.8997 - val_loss: 0.2636 - val_accuracy: 0.8963\n",
      "Epoch 92/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2316 - accuracy: 0.9005 - val_loss: 0.2655 - val_accuracy: 0.8965\n",
      "Epoch 93/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2310 - accuracy: 0.9011 - val_loss: 0.2581 - val_accuracy: 0.8967\n",
      "Epoch 94/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2315 - accuracy: 0.9007 - val_loss: 0.2607 - val_accuracy: 0.8980\n",
      "Epoch 95/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2307 - accuracy: 0.9005 - val_loss: 0.2570 - val_accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2295 - accuracy: 0.9016 - val_loss: 0.2576 - val_accuracy: 0.9007\n",
      "Epoch 97/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2285 - accuracy: 0.9017 - val_loss: 0.2551 - val_accuracy: 0.8995\n",
      "Epoch 98/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2275 - accuracy: 0.9020 - val_loss: 0.2559 - val_accuracy: 0.8999\n",
      "Epoch 99/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2279 - accuracy: 0.9018 - val_loss: 0.2541 - val_accuracy: 0.9005\n",
      "Epoch 100/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2275 - accuracy: 0.9024 - val_loss: 0.2533 - val_accuracy: 0.8996\n",
      "Early stopped after 100 epochs.\n",
      "1689/1689 [==============================] - 2s 967us/step - loss: 0.2533 - accuracy: 0.8996\n",
      "Validation accuracy: 0.8996207118034363\n",
      "\n",
      "Training model with 2 hidden layers, 256 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.4966 - accuracy: 0.7812 - val_loss: 0.5430 - val_accuracy: 0.7437\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3870 - accuracy: 0.8258 - val_loss: 0.4795 - val_accuracy: 0.7763\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3555 - accuracy: 0.8404 - val_loss: 0.4479 - val_accuracy: 0.7989\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3349 - accuracy: 0.8505 - val_loss: 0.4311 - val_accuracy: 0.8081\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3196 - accuracy: 0.8582 - val_loss: 0.4074 - val_accuracy: 0.8201\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3078 - accuracy: 0.8638 - val_loss: 0.3797 - val_accuracy: 0.8394\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2983 - accuracy: 0.8681 - val_loss: 0.3777 - val_accuracy: 0.8349\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2906 - accuracy: 0.8729 - val_loss: 0.3476 - val_accuracy: 0.8498\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2819 - accuracy: 0.8768 - val_loss: 0.3340 - val_accuracy: 0.8593\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2768 - accuracy: 0.8794 - val_loss: 0.3339 - val_accuracy: 0.8579\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2723 - accuracy: 0.8819 - val_loss: 0.3221 - val_accuracy: 0.8614\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2665 - accuracy: 0.8842 - val_loss: 0.3171 - val_accuracy: 0.8674\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2621 - accuracy: 0.8867 - val_loss: 0.3103 - val_accuracy: 0.8738\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2583 - accuracy: 0.8879 - val_loss: 0.2978 - val_accuracy: 0.8754\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2548 - accuracy: 0.8909 - val_loss: 0.2894 - val_accuracy: 0.8775\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2508 - accuracy: 0.8922 - val_loss: 0.2924 - val_accuracy: 0.8788\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2483 - accuracy: 0.8933 - val_loss: 0.2802 - val_accuracy: 0.8849\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2452 - accuracy: 0.8946 - val_loss: 0.2795 - val_accuracy: 0.8852\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2440 - accuracy: 0.8954 - val_loss: 0.2769 - val_accuracy: 0.8837\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2400 - accuracy: 0.8976 - val_loss: 0.2712 - val_accuracy: 0.8876\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2381 - accuracy: 0.8981 - val_loss: 0.2622 - val_accuracy: 0.8897\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2358 - accuracy: 0.8996 - val_loss: 0.2658 - val_accuracy: 0.8886\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2345 - accuracy: 0.9005 - val_loss: 0.2549 - val_accuracy: 0.8954\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2321 - accuracy: 0.9017 - val_loss: 0.2542 - val_accuracy: 0.8964\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2301 - accuracy: 0.9024 - val_loss: 0.2517 - val_accuracy: 0.8981\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2286 - accuracy: 0.9032 - val_loss: 0.2485 - val_accuracy: 0.8993\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2271 - accuracy: 0.9037 - val_loss: 0.2527 - val_accuracy: 0.8948\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2255 - accuracy: 0.9042 - val_loss: 0.2482 - val_accuracy: 0.8999\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2243 - accuracy: 0.9053 - val_loss: 0.2460 - val_accuracy: 0.8974\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2223 - accuracy: 0.9060 - val_loss: 0.2419 - val_accuracy: 0.9014\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2205 - accuracy: 0.9070 - val_loss: 0.2364 - val_accuracy: 0.9057\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2200 - accuracy: 0.9067 - val_loss: 0.2383 - val_accuracy: 0.9041\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2181 - accuracy: 0.9079 - val_loss: 0.2334 - val_accuracy: 0.9059\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2168 - accuracy: 0.9087 - val_loss: 0.2340 - val_accuracy: 0.9057\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2162 - accuracy: 0.9093 - val_loss: 0.2321 - val_accuracy: 0.9063\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2146 - accuracy: 0.9098 - val_loss: 0.2341 - val_accuracy: 0.9039\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2146 - accuracy: 0.9095 - val_loss: 0.2336 - val_accuracy: 0.9061\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2128 - accuracy: 0.9112 - val_loss: 0.2231 - val_accuracy: 0.9108\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2110 - accuracy: 0.9112 - val_loss: 0.2250 - val_accuracy: 0.9091\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2104 - accuracy: 0.9118 - val_loss: 0.2254 - val_accuracy: 0.9085\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2099 - accuracy: 0.9116 - val_loss: 0.2264 - val_accuracy: 0.9060\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2087 - accuracy: 0.9121 - val_loss: 0.2196 - val_accuracy: 0.9118\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2085 - accuracy: 0.9129 - val_loss: 0.2208 - val_accuracy: 0.9139\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2079 - accuracy: 0.9126 - val_loss: 0.2211 - val_accuracy: 0.9091\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2061 - accuracy: 0.9134 - val_loss: 0.2156 - val_accuracy: 0.9136\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2070 - accuracy: 0.9134 - val_loss: 0.2176 - val_accuracy: 0.9142\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2048 - accuracy: 0.9142 - val_loss: 0.2156 - val_accuracy: 0.9113\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2060 - accuracy: 0.9140 - val_loss: 0.2107 - val_accuracy: 0.9145\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2042 - accuracy: 0.9153 - val_loss: 0.2136 - val_accuracy: 0.9147\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2024 - accuracy: 0.9157 - val_loss: 0.2121 - val_accuracy: 0.9151\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2023 - accuracy: 0.9158 - val_loss: 0.2061 - val_accuracy: 0.9168\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2010 - accuracy: 0.9161 - val_loss: 0.2129 - val_accuracy: 0.9132\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.2000 - accuracy: 0.9166 - val_loss: 0.2139 - val_accuracy: 0.9151\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2003 - accuracy: 0.9163 - val_loss: 0.2060 - val_accuracy: 0.9176\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1990 - accuracy: 0.9178 - val_loss: 0.2060 - val_accuracy: 0.9169\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1994 - accuracy: 0.9170 - val_loss: 0.2090 - val_accuracy: 0.9158\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.2006 - accuracy: 0.9166 - val_loss: 0.2080 - val_accuracy: 0.9160\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1986 - accuracy: 0.9168 - val_loss: 0.2084 - val_accuracy: 0.9158\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1974 - accuracy: 0.9180 - val_loss: 0.2022 - val_accuracy: 0.9179\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 21s 2ms/step - loss: 0.1969 - accuracy: 0.9182 - val_loss: 0.2040 - val_accuracy: 0.9199\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1949 - accuracy: 0.9194 - val_loss: 0.2012 - val_accuracy: 0.9187\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 21s 2ms/step - loss: 0.1957 - accuracy: 0.9186 - val_loss: 0.2027 - val_accuracy: 0.9168\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1961 - accuracy: 0.9186 - val_loss: 0.1979 - val_accuracy: 0.9205\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1975 - accuracy: 0.9181 - val_loss: 0.2023 - val_accuracy: 0.9199\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1942 - accuracy: 0.9194 - val_loss: 0.1979 - val_accuracy: 0.9207\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1950 - accuracy: 0.9192 - val_loss: 0.1980 - val_accuracy: 0.9185\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1939 - accuracy: 0.9200 - val_loss: 0.1969 - val_accuracy: 0.9209\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1931 - accuracy: 0.9200 - val_loss: 0.1980 - val_accuracy: 0.9191\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1930 - accuracy: 0.9200 - val_loss: 0.1934 - val_accuracy: 0.9220\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1915 - accuracy: 0.9211 - val_loss: 0.1910 - val_accuracy: 0.9227\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1922 - accuracy: 0.9206 - val_loss: 0.1928 - val_accuracy: 0.9220\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1926 - accuracy: 0.9203 - val_loss: 0.1966 - val_accuracy: 0.9202\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.1925 - accuracy: 0.9208 - val_loss: 0.1917 - val_accuracy: 0.9218\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1905 - accuracy: 0.9210 - val_loss: 0.1929 - val_accuracy: 0.9225\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.1903 - accuracy: 0.9209 - val_loss: 0.1935 - val_accuracy: 0.9245\n",
      "Early stopped after 75 epochs.\n",
      "1689/1689 [==============================] - 2s 974us/step - loss: 0.1910 - accuracy: 0.9227\n",
      "Validation accuracy: 0.9227125644683838\n",
      "\n",
      "Training model with 2 hidden layers, 256 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.5779 - accuracy: 0.7473 - val_loss: 0.5936 - val_accuracy: 0.7085\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.5109 - accuracy: 0.7756 - val_loss: 0.5840 - val_accuracy: 0.7145\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4950 - accuracy: 0.7816 - val_loss: 0.5721 - val_accuracy: 0.7290\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4855 - accuracy: 0.7846 - val_loss: 0.5434 - val_accuracy: 0.7382\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.4814 - accuracy: 0.7874 - val_loss: 0.5496 - val_accuracy: 0.7237\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4774 - accuracy: 0.7884 - val_loss: 0.5908 - val_accuracy: 0.7190\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.4731 - accuracy: 0.7904 - val_loss: 0.5554 - val_accuracy: 0.7291\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4724 - accuracy: 0.7911 - val_loss: 0.5575 - val_accuracy: 0.7252\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4694 - accuracy: 0.7916 - val_loss: 0.5887 - val_accuracy: 0.7239\n",
      "Early stopped after 9 epochs.\n",
      "1689/1689 [==============================] - 2s 991us/step - loss: 0.5434 - accuracy: 0.7382\n",
      "Validation accuracy: 0.738162636756897\n",
      "\n",
      "Training model with 2 hidden layers, 256 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 21s 2ms/step - loss: 0.8593 - accuracy: 0.6023 - val_loss: 0.7858 - val_accuracy: 0.6311\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.6958 - accuracy: 0.7005 - val_loss: 0.6964 - val_accuracy: 0.6760\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.6067 - accuracy: 0.7421 - val_loss: 0.6652 - val_accuracy: 0.6902\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.5524 - accuracy: 0.7649 - val_loss: 0.6304 - val_accuracy: 0.7067\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.5171 - accuracy: 0.7786 - val_loss: 0.6099 - val_accuracy: 0.7150\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4935 - accuracy: 0.7865 - val_loss: 0.6007 - val_accuracy: 0.7179\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4768 - accuracy: 0.7922 - val_loss: 0.5870 - val_accuracy: 0.7232\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4634 - accuracy: 0.7962 - val_loss: 0.5725 - val_accuracy: 0.7281\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4542 - accuracy: 0.7999 - val_loss: 0.5658 - val_accuracy: 0.7311\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4468 - accuracy: 0.8013 - val_loss: 0.5652 - val_accuracy: 0.7319\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4395 - accuracy: 0.8046 - val_loss: 0.5554 - val_accuracy: 0.7358\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4343 - accuracy: 0.8069 - val_loss: 0.5502 - val_accuracy: 0.7380\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4279 - accuracy: 0.8085 - val_loss: 0.5434 - val_accuracy: 0.7417\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4237 - accuracy: 0.8105 - val_loss: 0.5403 - val_accuracy: 0.7426\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4201 - accuracy: 0.8107 - val_loss: 0.5383 - val_accuracy: 0.7458\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4162 - accuracy: 0.8124 - val_loss: 0.5330 - val_accuracy: 0.7475\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4137 - accuracy: 0.8140 - val_loss: 0.5299 - val_accuracy: 0.7499\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4107 - accuracy: 0.8146 - val_loss: 0.5319 - val_accuracy: 0.7502\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4072 - accuracy: 0.8163 - val_loss: 0.5244 - val_accuracy: 0.7518\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4057 - accuracy: 0.8166 - val_loss: 0.5187 - val_accuracy: 0.7543\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4024 - accuracy: 0.8186 - val_loss: 0.5235 - val_accuracy: 0.7549\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4005 - accuracy: 0.8194 - val_loss: 0.5190 - val_accuracy: 0.7572\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3988 - accuracy: 0.8202 - val_loss: 0.5116 - val_accuracy: 0.7595\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3962 - accuracy: 0.8205 - val_loss: 0.5134 - val_accuracy: 0.7598\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3943 - accuracy: 0.8219 - val_loss: 0.5105 - val_accuracy: 0.7635\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3936 - accuracy: 0.8224 - val_loss: 0.5077 - val_accuracy: 0.7642\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3911 - accuracy: 0.8233 - val_loss: 0.5015 - val_accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3896 - accuracy: 0.8231 - val_loss: 0.5030 - val_accuracy: 0.7667\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3877 - accuracy: 0.8252 - val_loss: 0.4987 - val_accuracy: 0.7695\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3874 - accuracy: 0.8245 - val_loss: 0.5010 - val_accuracy: 0.7699\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3857 - accuracy: 0.8255 - val_loss: 0.4947 - val_accuracy: 0.7727\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3843 - accuracy: 0.8264 - val_loss: 0.4955 - val_accuracy: 0.7730\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3831 - accuracy: 0.8266 - val_loss: 0.4940 - val_accuracy: 0.7732\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3822 - accuracy: 0.8281 - val_loss: 0.4921 - val_accuracy: 0.7735\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3817 - accuracy: 0.8272 - val_loss: 0.4911 - val_accuracy: 0.7759\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3792 - accuracy: 0.8287 - val_loss: 0.4896 - val_accuracy: 0.7769\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3795 - accuracy: 0.8286 - val_loss: 0.4833 - val_accuracy: 0.7769\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3773 - accuracy: 0.8303 - val_loss: 0.4856 - val_accuracy: 0.7801\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3777 - accuracy: 0.8300 - val_loss: 0.4833 - val_accuracy: 0.7823\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3752 - accuracy: 0.8309 - val_loss: 0.4836 - val_accuracy: 0.7831\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3749 - accuracy: 0.8311 - val_loss: 0.4783 - val_accuracy: 0.7829\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3740 - accuracy: 0.8312 - val_loss: 0.4764 - val_accuracy: 0.7851\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3719 - accuracy: 0.8322 - val_loss: 0.4791 - val_accuracy: 0.7837\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3718 - accuracy: 0.8332 - val_loss: 0.4777 - val_accuracy: 0.7861\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3712 - accuracy: 0.8330 - val_loss: 0.4745 - val_accuracy: 0.7868\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3706 - accuracy: 0.8326 - val_loss: 0.4703 - val_accuracy: 0.7885\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3693 - accuracy: 0.8339 - val_loss: 0.4701 - val_accuracy: 0.7896\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3691 - accuracy: 0.8336 - val_loss: 0.4685 - val_accuracy: 0.7904\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3674 - accuracy: 0.8344 - val_loss: 0.4705 - val_accuracy: 0.7900\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3671 - accuracy: 0.8346 - val_loss: 0.4662 - val_accuracy: 0.7918\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3659 - accuracy: 0.8358 - val_loss: 0.4651 - val_accuracy: 0.7939\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3656 - accuracy: 0.8355 - val_loss: 0.4642 - val_accuracy: 0.7939\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3663 - accuracy: 0.8358 - val_loss: 0.4617 - val_accuracy: 0.7938\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3641 - accuracy: 0.8364 - val_loss: 0.4596 - val_accuracy: 0.7963\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3634 - accuracy: 0.8370 - val_loss: 0.4601 - val_accuracy: 0.7950\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3628 - accuracy: 0.8369 - val_loss: 0.4586 - val_accuracy: 0.7965\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3624 - accuracy: 0.8375 - val_loss: 0.4589 - val_accuracy: 0.7970\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3618 - accuracy: 0.8377 - val_loss: 0.4572 - val_accuracy: 0.7970\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3616 - accuracy: 0.8376 - val_loss: 0.4551 - val_accuracy: 0.7988\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3609 - accuracy: 0.8376 - val_loss: 0.4541 - val_accuracy: 0.7984\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3597 - accuracy: 0.8383 - val_loss: 0.4527 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3589 - accuracy: 0.8396 - val_loss: 0.4551 - val_accuracy: 0.8007\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3594 - accuracy: 0.8393 - val_loss: 0.4517 - val_accuracy: 0.8020\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3578 - accuracy: 0.8390 - val_loss: 0.4541 - val_accuracy: 0.7999\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3579 - accuracy: 0.8390 - val_loss: 0.4525 - val_accuracy: 0.8037\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3573 - accuracy: 0.8398 - val_loss: 0.4501 - val_accuracy: 0.8041\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3565 - accuracy: 0.8408 - val_loss: 0.4501 - val_accuracy: 0.8016\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3566 - accuracy: 0.8407 - val_loss: 0.4484 - val_accuracy: 0.8041\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3560 - accuracy: 0.8411 - val_loss: 0.4477 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3561 - accuracy: 0.8409 - val_loss: 0.4458 - val_accuracy: 0.8039\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3559 - accuracy: 0.8405 - val_loss: 0.4468 - val_accuracy: 0.8048\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3538 - accuracy: 0.8419 - val_loss: 0.4460 - val_accuracy: 0.8057\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3544 - accuracy: 0.8413 - val_loss: 0.4416 - val_accuracy: 0.8073\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3537 - accuracy: 0.8420 - val_loss: 0.4423 - val_accuracy: 0.8057\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3537 - accuracy: 0.8416 - val_loss: 0.4424 - val_accuracy: 0.8070\n",
      "Epoch 76/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3540 - accuracy: 0.8417 - val_loss: 0.4416 - val_accuracy: 0.8084\n",
      "Epoch 77/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3523 - accuracy: 0.8435 - val_loss: 0.4406 - val_accuracy: 0.8095\n",
      "Epoch 78/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3529 - accuracy: 0.8428 - val_loss: 0.4405 - val_accuracy: 0.8077\n",
      "Epoch 79/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3527 - accuracy: 0.8421 - val_loss: 0.4389 - val_accuracy: 0.8086\n",
      "Epoch 80/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3512 - accuracy: 0.8425 - val_loss: 0.4386 - val_accuracy: 0.8088\n",
      "Epoch 81/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3516 - accuracy: 0.8432 - val_loss: 0.4356 - val_accuracy: 0.8116\n",
      "Epoch 82/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3506 - accuracy: 0.8429 - val_loss: 0.4377 - val_accuracy: 0.8117\n",
      "Epoch 83/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3508 - accuracy: 0.8434 - val_loss: 0.4383 - val_accuracy: 0.8092\n",
      "Epoch 84/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3498 - accuracy: 0.8434 - val_loss: 0.4359 - val_accuracy: 0.8107\n",
      "Epoch 85/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3497 - accuracy: 0.8440 - val_loss: 0.4355 - val_accuracy: 0.8126\n",
      "Epoch 86/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3493 - accuracy: 0.8437 - val_loss: 0.4347 - val_accuracy: 0.8132\n",
      "Epoch 87/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3487 - accuracy: 0.8445 - val_loss: 0.4317 - val_accuracy: 0.8116\n",
      "Epoch 88/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3488 - accuracy: 0.8444 - val_loss: 0.4319 - val_accuracy: 0.8138\n",
      "Epoch 89/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3481 - accuracy: 0.8447 - val_loss: 0.4327 - val_accuracy: 0.8135\n",
      "Epoch 90/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3488 - accuracy: 0.8449 - val_loss: 0.4331 - val_accuracy: 0.8135\n",
      "Epoch 91/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3468 - accuracy: 0.8454 - val_loss: 0.4300 - val_accuracy: 0.8138\n",
      "Epoch 92/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3470 - accuracy: 0.8445 - val_loss: 0.4327 - val_accuracy: 0.8160\n",
      "Epoch 93/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3476 - accuracy: 0.8452 - val_loss: 0.4308 - val_accuracy: 0.8147\n",
      "Epoch 94/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3464 - accuracy: 0.8459 - val_loss: 0.4296 - val_accuracy: 0.8148\n",
      "Epoch 95/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3452 - accuracy: 0.8455 - val_loss: 0.4261 - val_accuracy: 0.8153\n",
      "Epoch 96/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3461 - accuracy: 0.8455 - val_loss: 0.4298 - val_accuracy: 0.8158\n",
      "Epoch 97/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3465 - accuracy: 0.8455 - val_loss: 0.4286 - val_accuracy: 0.8165\n",
      "Epoch 98/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3458 - accuracy: 0.8462 - val_loss: 0.4281 - val_accuracy: 0.8158\n",
      "Epoch 99/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3445 - accuracy: 0.8460 - val_loss: 0.4246 - val_accuracy: 0.8172\n",
      "Epoch 100/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3448 - accuracy: 0.8459 - val_loss: 0.4250 - val_accuracy: 0.8156\n",
      "Early stopped after 100 epochs.\n",
      "1689/1689 [==============================] - 2s 977us/step - loss: 0.4250 - accuracy: 0.8156\n",
      "Validation accuracy: 0.8156351447105408\n",
      "\n",
      "Training model with 2 hidden layers, 256 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.6004 - accuracy: 0.7371 - val_loss: 0.6213 - val_accuracy: 0.7094\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4739 - accuracy: 0.7912 - val_loss: 0.5644 - val_accuracy: 0.7295\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4510 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4389 - accuracy: 0.8044 - val_loss: 0.5437 - val_accuracy: 0.7498\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4299 - accuracy: 0.8088 - val_loss: 0.5245 - val_accuracy: 0.7531\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4229 - accuracy: 0.8106 - val_loss: 0.5248 - val_accuracy: 0.7571\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4182 - accuracy: 0.8130 - val_loss: 0.5129 - val_accuracy: 0.7613\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.4140 - accuracy: 0.8151 - val_loss: 0.5138 - val_accuracy: 0.7643\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4100 - accuracy: 0.8166 - val_loss: 0.5120 - val_accuracy: 0.7685\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4068 - accuracy: 0.8185 - val_loss: 0.5058 - val_accuracy: 0.7713\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4042 - accuracy: 0.8200 - val_loss: 0.4936 - val_accuracy: 0.7779\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.4008 - accuracy: 0.8206 - val_loss: 0.4964 - val_accuracy: 0.7772\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3990 - accuracy: 0.8227 - val_loss: 0.4979 - val_accuracy: 0.7782\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3969 - accuracy: 0.8230 - val_loss: 0.4879 - val_accuracy: 0.7798\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3952 - accuracy: 0.8240 - val_loss: 0.4974 - val_accuracy: 0.7815\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3937 - accuracy: 0.8256 - val_loss: 0.4766 - val_accuracy: 0.7852\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3924 - accuracy: 0.8263 - val_loss: 0.4756 - val_accuracy: 0.7831\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3902 - accuracy: 0.8264 - val_loss: 0.4854 - val_accuracy: 0.7879\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3889 - accuracy: 0.8267 - val_loss: 0.4776 - val_accuracy: 0.7842\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3872 - accuracy: 0.8281 - val_loss: 0.4689 - val_accuracy: 0.7909\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3855 - accuracy: 0.8289 - val_loss: 0.4702 - val_accuracy: 0.7937\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3848 - accuracy: 0.8285 - val_loss: 0.4629 - val_accuracy: 0.7954\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3840 - accuracy: 0.8287 - val_loss: 0.4652 - val_accuracy: 0.7941\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3827 - accuracy: 0.8301 - val_loss: 0.4593 - val_accuracy: 0.7996\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3819 - accuracy: 0.8308 - val_loss: 0.4608 - val_accuracy: 0.8016\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3806 - accuracy: 0.8312 - val_loss: 0.4606 - val_accuracy: 0.7988\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3783 - accuracy: 0.8323 - val_loss: 0.4631 - val_accuracy: 0.7966\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3794 - accuracy: 0.8307 - val_loss: 0.4525 - val_accuracy: 0.8019\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3765 - accuracy: 0.8327 - val_loss: 0.4465 - val_accuracy: 0.7997\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3775 - accuracy: 0.8335 - val_loss: 0.4515 - val_accuracy: 0.8003\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3767 - accuracy: 0.8329 - val_loss: 0.4553 - val_accuracy: 0.7997\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3748 - accuracy: 0.8332 - val_loss: 0.4536 - val_accuracy: 0.8077\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3750 - accuracy: 0.8338 - val_loss: 0.4439 - val_accuracy: 0.8063\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3729 - accuracy: 0.8344 - val_loss: 0.4493 - val_accuracy: 0.8022\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3730 - accuracy: 0.8356 - val_loss: 0.4481 - val_accuracy: 0.8043\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3705 - accuracy: 0.8355 - val_loss: 0.4532 - val_accuracy: 0.8083\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3719 - accuracy: 0.8357 - val_loss: 0.4423 - val_accuracy: 0.8092\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3717 - accuracy: 0.8363 - val_loss: 0.4417 - val_accuracy: 0.8114\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3701 - accuracy: 0.8373 - val_loss: 0.4436 - val_accuracy: 0.8094\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3712 - accuracy: 0.8362 - val_loss: 0.4350 - val_accuracy: 0.8109\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3696 - accuracy: 0.8360 - val_loss: 0.4360 - val_accuracy: 0.8122\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3684 - accuracy: 0.8372 - val_loss: 0.4398 - val_accuracy: 0.8099\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3672 - accuracy: 0.8377 - val_loss: 0.4293 - val_accuracy: 0.8116\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3670 - accuracy: 0.8380 - val_loss: 0.4405 - val_accuracy: 0.8118\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3676 - accuracy: 0.8378 - val_loss: 0.4287 - val_accuracy: 0.8128\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3662 - accuracy: 0.8380 - val_loss: 0.4345 - val_accuracy: 0.8175\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3653 - accuracy: 0.8389 - val_loss: 0.4322 - val_accuracy: 0.8140\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3652 - accuracy: 0.8387 - val_loss: 0.4285 - val_accuracy: 0.8149\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3650 - accuracy: 0.8396 - val_loss: 0.4361 - val_accuracy: 0.8136\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.3647 - accuracy: 0.8383 - val_loss: 0.4364 - val_accuracy: 0.8138\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3639 - accuracy: 0.8391 - val_loss: 0.4341 - val_accuracy: 0.8171\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3634 - accuracy: 0.8399 - val_loss: 0.4289 - val_accuracy: 0.8180\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.3646 - accuracy: 0.8393 - val_loss: 0.4309 - val_accuracy: 0.8126\n",
      "Early stopped after 53 epochs.\n",
      "1689/1689 [==============================] - 2s 983us/step - loss: 0.4285 - accuracy: 0.8149\n",
      "Validation accuracy: 0.8149135112762451\n",
      "\n",
      "Training model with 2 hidden layers, 256 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 20s 2ms/step - loss: 0.7958 - accuracy: 0.6474 - val_loss: 0.7766 - val_accuracy: 0.6020\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7359 - accuracy: 0.6779 - val_loss: 0.7321 - val_accuracy: 0.6140\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7213 - accuracy: 0.6844 - val_loss: 0.7400 - val_accuracy: 0.6074\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7200 - accuracy: 0.6857 - val_loss: 0.7288 - val_accuracy: 0.6283\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7125 - accuracy: 0.6905 - val_loss: 0.7726 - val_accuracy: 0.5850\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7136 - accuracy: 0.6904 - val_loss: 0.7322 - val_accuracy: 0.6112\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7105 - accuracy: 0.6871 - val_loss: 0.7041 - val_accuracy: 0.6289\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7117 - accuracy: 0.6889 - val_loss: 0.7412 - val_accuracy: 0.5990\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7115 - accuracy: 0.6880 - val_loss: 0.7325 - val_accuracy: 0.6210\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7059 - accuracy: 0.6912 - val_loss: 0.7235 - val_accuracy: 0.5977\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7035 - accuracy: 0.6917 - val_loss: 0.7225 - val_accuracy: 0.6302\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.7058 - accuracy: 0.6918 - val_loss: 0.7212 - val_accuracy: 0.6418\n",
      "Early stopped after 12 epochs.\n",
      "1689/1689 [==============================] - 2s 995us/step - loss: 0.7041 - accuracy: 0.6289\n",
      "Validation accuracy: 0.6289388537406921\n",
      "\n",
      "Training model with 3 hidden layers, 64 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.8827 - accuracy: 0.5871 - val_loss: 0.7943 - val_accuracy: 0.6245\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.7252 - accuracy: 0.6826 - val_loss: 0.7321 - val_accuracy: 0.6515\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.6388 - accuracy: 0.7238 - val_loss: 0.6881 - val_accuracy: 0.6744\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5826 - accuracy: 0.7491 - val_loss: 0.6424 - val_accuracy: 0.6958\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5475 - accuracy: 0.7630 - val_loss: 0.6189 - val_accuracy: 0.7080\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5230 - accuracy: 0.7725 - val_loss: 0.6087 - val_accuracy: 0.7117\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5061 - accuracy: 0.7782 - val_loss: 0.5981 - val_accuracy: 0.7177\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4933 - accuracy: 0.7829 - val_loss: 0.5896 - val_accuracy: 0.7214\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4804 - accuracy: 0.7878 - val_loss: 0.5860 - val_accuracy: 0.7234\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4720 - accuracy: 0.7906 - val_loss: 0.5709 - val_accuracy: 0.7299\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4645 - accuracy: 0.7935 - val_loss: 0.5630 - val_accuracy: 0.7318\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4582 - accuracy: 0.7957 - val_loss: 0.5657 - val_accuracy: 0.7323\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4529 - accuracy: 0.7988 - val_loss: 0.5595 - val_accuracy: 0.7351\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4479 - accuracy: 0.7992 - val_loss: 0.5498 - val_accuracy: 0.7388\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4435 - accuracy: 0.8016 - val_loss: 0.5472 - val_accuracy: 0.7404\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4386 - accuracy: 0.8022 - val_loss: 0.5460 - val_accuracy: 0.7406\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4365 - accuracy: 0.8040 - val_loss: 0.5408 - val_accuracy: 0.7439\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4333 - accuracy: 0.8048 - val_loss: 0.5417 - val_accuracy: 0.7444\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4299 - accuracy: 0.8064 - val_loss: 0.5403 - val_accuracy: 0.7454\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4290 - accuracy: 0.8067 - val_loss: 0.5343 - val_accuracy: 0.7478\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4270 - accuracy: 0.8072 - val_loss: 0.5280 - val_accuracy: 0.7497\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 31s 3ms/step - loss: 0.4235 - accuracy: 0.8087 - val_loss: 0.5318 - val_accuracy: 0.7498\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.4220 - accuracy: 0.8102 - val_loss: 0.5265 - val_accuracy: 0.7517\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.4202 - accuracy: 0.8101 - val_loss: 0.5240 - val_accuracy: 0.7527\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 17s 2ms/step - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.5238 - val_accuracy: 0.7547\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4171 - accuracy: 0.8109 - val_loss: 0.5190 - val_accuracy: 0.7557\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 21s 2ms/step - loss: 0.4148 - accuracy: 0.8119 - val_loss: 0.5218 - val_accuracy: 0.7542\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.4143 - accuracy: 0.8126 - val_loss: 0.5158 - val_accuracy: 0.7576\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.4126 - accuracy: 0.8134 - val_loss: 0.5145 - val_accuracy: 0.7582\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 31s 3ms/step - loss: 0.4089 - accuracy: 0.8148 - val_loss: 0.5122 - val_accuracy: 0.7596\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.4093 - accuracy: 0.8152 - val_loss: 0.5065 - val_accuracy: 0.7612\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4078 - accuracy: 0.8150 - val_loss: 0.5075 - val_accuracy: 0.7644\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4069 - accuracy: 0.8157 - val_loss: 0.5043 - val_accuracy: 0.7640\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4050 - accuracy: 0.8166 - val_loss: 0.5025 - val_accuracy: 0.7662\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4049 - accuracy: 0.8164 - val_loss: 0.5048 - val_accuracy: 0.7655\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.4029 - accuracy: 0.8173 - val_loss: 0.5003 - val_accuracy: 0.7663\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 59s 7ms/step - loss: 0.4019 - accuracy: 0.8171 - val_loss: 0.5013 - val_accuracy: 0.7674\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.4009 - accuracy: 0.8183 - val_loss: 0.4951 - val_accuracy: 0.7695\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3998 - accuracy: 0.8182 - val_loss: 0.4988 - val_accuracy: 0.7691\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3985 - accuracy: 0.8195 - val_loss: 0.4952 - val_accuracy: 0.7710\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 41s 4ms/step - loss: 0.3987 - accuracy: 0.8198 - val_loss: 0.4953 - val_accuracy: 0.7732\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3983 - accuracy: 0.8199 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 37s 4ms/step - loss: 0.3961 - accuracy: 0.8204 - val_loss: 0.4916 - val_accuracy: 0.7712\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.3962 - accuracy: 0.8204 - val_loss: 0.4889 - val_accuracy: 0.7733\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3948 - accuracy: 0.8209 - val_loss: 0.4865 - val_accuracy: 0.7739\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3940 - accuracy: 0.8208 - val_loss: 0.4894 - val_accuracy: 0.7732\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3935 - accuracy: 0.8218 - val_loss: 0.4841 - val_accuracy: 0.7773\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 22s 2ms/step - loss: 0.3919 - accuracy: 0.8226 - val_loss: 0.4844 - val_accuracy: 0.7762\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3918 - accuracy: 0.8218 - val_loss: 0.4851 - val_accuracy: 0.7764\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3907 - accuracy: 0.8225 - val_loss: 0.4844 - val_accuracy: 0.7770\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3910 - accuracy: 0.8224 - val_loss: 0.4835 - val_accuracy: 0.7775\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3912 - accuracy: 0.8219 - val_loss: 0.4870 - val_accuracy: 0.7768\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3901 - accuracy: 0.8235 - val_loss: 0.4804 - val_accuracy: 0.7794\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 32s 4ms/step - loss: 0.3904 - accuracy: 0.8235 - val_loss: 0.4792 - val_accuracy: 0.7800\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 33s 4ms/step - loss: 0.3895 - accuracy: 0.8236 - val_loss: 0.4794 - val_accuracy: 0.7797\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3878 - accuracy: 0.8243 - val_loss: 0.4764 - val_accuracy: 0.7818\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3880 - accuracy: 0.8243 - val_loss: 0.4784 - val_accuracy: 0.7808\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3873 - accuracy: 0.8249 - val_loss: 0.4769 - val_accuracy: 0.7804\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3864 - accuracy: 0.8251 - val_loss: 0.4715 - val_accuracy: 0.7833\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3868 - accuracy: 0.8251 - val_loss: 0.4723 - val_accuracy: 0.7848\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3854 - accuracy: 0.8255 - val_loss: 0.4731 - val_accuracy: 0.7826\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3841 - accuracy: 0.8260 - val_loss: 0.4725 - val_accuracy: 0.7844\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3848 - accuracy: 0.8257 - val_loss: 0.4715 - val_accuracy: 0.7863\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3838 - accuracy: 0.8257 - val_loss: 0.4688 - val_accuracy: 0.7852\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3843 - accuracy: 0.8262 - val_loss: 0.4711 - val_accuracy: 0.7855\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3833 - accuracy: 0.8262 - val_loss: 0.4709 - val_accuracy: 0.7845\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3837 - accuracy: 0.8265 - val_loss: 0.4708 - val_accuracy: 0.7861\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.3826 - accuracy: 0.8265 - val_loss: 0.4686 - val_accuracy: 0.7856\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 34s 4ms/step - loss: 0.3831 - accuracy: 0.8271 - val_loss: 0.4691 - val_accuracy: 0.7866\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 32s 4ms/step - loss: 0.3818 - accuracy: 0.8273 - val_loss: 0.4677 - val_accuracy: 0.7859\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 34s 4ms/step - loss: 0.3808 - accuracy: 0.8275 - val_loss: 0.4674 - val_accuracy: 0.7869\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 34s 4ms/step - loss: 0.3826 - accuracy: 0.8270 - val_loss: 0.4636 - val_accuracy: 0.7876\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3817 - accuracy: 0.8267 - val_loss: 0.4681 - val_accuracy: 0.7871\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3806 - accuracy: 0.8280 - val_loss: 0.4658 - val_accuracy: 0.7891\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3815 - accuracy: 0.8272 - val_loss: 0.4624 - val_accuracy: 0.7898\n",
      "Epoch 76/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3803 - accuracy: 0.8283 - val_loss: 0.4643 - val_accuracy: 0.7893\n",
      "Epoch 77/100\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.3790 - accuracy: 0.8287 - val_loss: 0.4632 - val_accuracy: 0.7878\n",
      "Epoch 78/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3794 - accuracy: 0.8287 - val_loss: 0.4615 - val_accuracy: 0.7909\n",
      "Epoch 79/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3786 - accuracy: 0.8287 - val_loss: 0.4601 - val_accuracy: 0.7899\n",
      "Epoch 80/100\n",
      "9002/9002 [==============================] - 31s 3ms/step - loss: 0.3787 - accuracy: 0.8288 - val_loss: 0.4615 - val_accuracy: 0.7896\n",
      "Epoch 81/100\n",
      "9002/9002 [==============================] - 34s 4ms/step - loss: 0.3787 - accuracy: 0.8289 - val_loss: 0.4598 - val_accuracy: 0.7903\n",
      "Epoch 82/100\n",
      "9002/9002 [==============================] - 37s 4ms/step - loss: 0.3783 - accuracy: 0.8293 - val_loss: 0.4600 - val_accuracy: 0.7938\n",
      "Epoch 83/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3773 - accuracy: 0.8299 - val_loss: 0.4589 - val_accuracy: 0.7904\n",
      "Epoch 84/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3773 - accuracy: 0.8295 - val_loss: 0.4593 - val_accuracy: 0.7928\n",
      "Epoch 85/100\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.3769 - accuracy: 0.8291 - val_loss: 0.4584 - val_accuracy: 0.7929\n",
      "Epoch 86/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3766 - accuracy: 0.8296 - val_loss: 0.4561 - val_accuracy: 0.7943\n",
      "Epoch 87/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3756 - accuracy: 0.8303 - val_loss: 0.4597 - val_accuracy: 0.7908\n",
      "Epoch 88/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3756 - accuracy: 0.8309 - val_loss: 0.4545 - val_accuracy: 0.7936\n",
      "Epoch 89/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3764 - accuracy: 0.8304 - val_loss: 0.4548 - val_accuracy: 0.7947\n",
      "Epoch 90/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3753 - accuracy: 0.8306 - val_loss: 0.4568 - val_accuracy: 0.7930\n",
      "Epoch 91/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3751 - accuracy: 0.8301 - val_loss: 0.4537 - val_accuracy: 0.7958\n",
      "Epoch 92/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3750 - accuracy: 0.8301 - val_loss: 0.4589 - val_accuracy: 0.7939\n",
      "Epoch 93/100\n",
      "9002/9002 [==============================] - 38s 4ms/step - loss: 0.3753 - accuracy: 0.8307 - val_loss: 0.4552 - val_accuracy: 0.7949\n",
      "Epoch 94/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3747 - accuracy: 0.8311 - val_loss: 0.4542 - val_accuracy: 0.7950\n",
      "Epoch 95/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3743 - accuracy: 0.8311 - val_loss: 0.4528 - val_accuracy: 0.7979\n",
      "Epoch 96/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3751 - accuracy: 0.8307 - val_loss: 0.4572 - val_accuracy: 0.7941\n",
      "Epoch 97/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3747 - accuracy: 0.8304 - val_loss: 0.4509 - val_accuracy: 0.7973\n",
      "Epoch 98/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3733 - accuracy: 0.8309 - val_loss: 0.4524 - val_accuracy: 0.7984\n",
      "Epoch 99/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3734 - accuracy: 0.8321 - val_loss: 0.4540 - val_accuracy: 0.7960\n",
      "Epoch 100/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3738 - accuracy: 0.8313 - val_loss: 0.4517 - val_accuracy: 0.7976\n",
      "Early stopped after 100 epochs.\n",
      "1689/1689 [==============================] - 4s 2ms/step - loss: 0.4517 - accuracy: 0.7976\n",
      "Validation accuracy: 0.7976130843162537\n",
      "\n",
      "Training model with 3 hidden layers, 64 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 42s 4ms/step - loss: 0.6002 - accuracy: 0.7354 - val_loss: 0.5966 - val_accuracy: 0.7196\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.4679 - accuracy: 0.7929 - val_loss: 0.5526 - val_accuracy: 0.7373\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.4442 - accuracy: 0.8010 - val_loss: 0.5327 - val_accuracy: 0.7487\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.4328 - accuracy: 0.8061 - val_loss: 0.5329 - val_accuracy: 0.7517\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.4268 - accuracy: 0.8085 - val_loss: 0.5341 - val_accuracy: 0.7522\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.4212 - accuracy: 0.8120 - val_loss: 0.5173 - val_accuracy: 0.7598\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.4141 - accuracy: 0.8149 - val_loss: 0.5042 - val_accuracy: 0.7634\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.4124 - accuracy: 0.8147 - val_loss: 0.5004 - val_accuracy: 0.7670\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.4082 - accuracy: 0.8172 - val_loss: 0.5050 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.4070 - accuracy: 0.8184 - val_loss: 0.5003 - val_accuracy: 0.7680\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.4922 - val_accuracy: 0.7726\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.4023 - accuracy: 0.8197 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.4001 - accuracy: 0.8215 - val_loss: 0.4904 - val_accuracy: 0.7781\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3978 - accuracy: 0.8220 - val_loss: 0.4855 - val_accuracy: 0.7785\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3973 - accuracy: 0.8232 - val_loss: 0.4885 - val_accuracy: 0.7805\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3947 - accuracy: 0.8242 - val_loss: 0.4845 - val_accuracy: 0.7832\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3932 - accuracy: 0.8251 - val_loss: 0.4772 - val_accuracy: 0.7863\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3921 - accuracy: 0.8253 - val_loss: 0.4770 - val_accuracy: 0.7866\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3907 - accuracy: 0.8261 - val_loss: 0.4809 - val_accuracy: 0.7828\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3899 - accuracy: 0.8267 - val_loss: 0.4690 - val_accuracy: 0.7875\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3903 - accuracy: 0.8271 - val_loss: 0.4668 - val_accuracy: 0.7892\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3882 - accuracy: 0.8266 - val_loss: 0.4722 - val_accuracy: 0.7887\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3872 - accuracy: 0.8275 - val_loss: 0.4700 - val_accuracy: 0.7893\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3866 - accuracy: 0.8280 - val_loss: 0.4650 - val_accuracy: 0.7939\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3867 - accuracy: 0.8288 - val_loss: 0.4658 - val_accuracy: 0.7927\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 21s 2ms/step - loss: 0.3860 - accuracy: 0.8283 - val_loss: 0.4729 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.3868 - accuracy: 0.8288 - val_loss: 0.4607 - val_accuracy: 0.7895\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.3834 - accuracy: 0.8296 - val_loss: 0.4654 - val_accuracy: 0.7949\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3836 - accuracy: 0.8291 - val_loss: 0.4597 - val_accuracy: 0.7953\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3826 - accuracy: 0.8297 - val_loss: 0.4664 - val_accuracy: 0.7917\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.3808 - accuracy: 0.8304 - val_loss: 0.4573 - val_accuracy: 0.7937\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 44s 5ms/step - loss: 0.3811 - accuracy: 0.8313 - val_loss: 0.4536 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 44s 5ms/step - loss: 0.3816 - accuracy: 0.8307 - val_loss: 0.4603 - val_accuracy: 0.7961\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3813 - accuracy: 0.8305 - val_loss: 0.4535 - val_accuracy: 0.7984\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3791 - accuracy: 0.8313 - val_loss: 0.4578 - val_accuracy: 0.7946\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3795 - accuracy: 0.8318 - val_loss: 0.4604 - val_accuracy: 0.7956\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3791 - accuracy: 0.8314 - val_loss: 0.4514 - val_accuracy: 0.7978\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3776 - accuracy: 0.8318 - val_loss: 0.4563 - val_accuracy: 0.7972\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3784 - accuracy: 0.8325 - val_loss: 0.4501 - val_accuracy: 0.8013\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 42s 5ms/step - loss: 0.3792 - accuracy: 0.8316 - val_loss: 0.4514 - val_accuracy: 0.8021\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 43s 5ms/step - loss: 0.3768 - accuracy: 0.8325 - val_loss: 0.4502 - val_accuracy: 0.8032\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3774 - accuracy: 0.8321 - val_loss: 0.4571 - val_accuracy: 0.7991\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.3766 - accuracy: 0.8325 - val_loss: 0.4521 - val_accuracy: 0.8015\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3754 - accuracy: 0.8338 - val_loss: 0.4498 - val_accuracy: 0.8037\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.3769 - accuracy: 0.8321 - val_loss: 0.4501 - val_accuracy: 0.8029\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3760 - accuracy: 0.8331 - val_loss: 0.4446 - val_accuracy: 0.8048\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3761 - accuracy: 0.8332 - val_loss: 0.4429 - val_accuracy: 0.8046\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3751 - accuracy: 0.8332 - val_loss: 0.4469 - val_accuracy: 0.8045\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3745 - accuracy: 0.8340 - val_loss: 0.4440 - val_accuracy: 0.8053\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3740 - accuracy: 0.8343 - val_loss: 0.4425 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3747 - accuracy: 0.8336 - val_loss: 0.4433 - val_accuracy: 0.8059\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.3746 - accuracy: 0.8342 - val_loss: 0.4462 - val_accuracy: 0.8038\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 37s 4ms/step - loss: 0.3739 - accuracy: 0.8346 - val_loss: 0.4491 - val_accuracy: 0.8019\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3734 - accuracy: 0.8346 - val_loss: 0.4489 - val_accuracy: 0.8001\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.3725 - accuracy: 0.8348 - val_loss: 0.4404 - val_accuracy: 0.8019\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3723 - accuracy: 0.8348 - val_loss: 0.4407 - val_accuracy: 0.8031\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 37s 4ms/step - loss: 0.3731 - accuracy: 0.8347 - val_loss: 0.4418 - val_accuracy: 0.8058\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 37s 4ms/step - loss: 0.3733 - accuracy: 0.8339 - val_loss: 0.4416 - val_accuracy: 0.8033\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3716 - accuracy: 0.8347 - val_loss: 0.4387 - val_accuracy: 0.8102\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.3715 - accuracy: 0.8356 - val_loss: 0.4495 - val_accuracy: 0.8031\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 32s 4ms/step - loss: 0.3725 - accuracy: 0.8352 - val_loss: 0.4414 - val_accuracy: 0.8062\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3727 - accuracy: 0.8352 - val_loss: 0.4444 - val_accuracy: 0.8111\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3706 - accuracy: 0.8359 - val_loss: 0.4380 - val_accuracy: 0.8097\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3703 - accuracy: 0.8358 - val_loss: 0.4310 - val_accuracy: 0.8131\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3708 - accuracy: 0.8350 - val_loss: 0.4372 - val_accuracy: 0.8024\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3709 - accuracy: 0.8358 - val_loss: 0.4377 - val_accuracy: 0.8087\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.3708 - accuracy: 0.8366 - val_loss: 0.4345 - val_accuracy: 0.8096\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3706 - accuracy: 0.8351 - val_loss: 0.4470 - val_accuracy: 0.8069\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.3710 - accuracy: 0.8361 - val_loss: 0.4327 - val_accuracy: 0.8130\n",
      "Early stopped after 69 epochs.\n",
      "1689/1689 [==============================] - 5s 3ms/step - loss: 0.4310 - accuracy: 0.8131\n",
      "Validation accuracy: 0.8130632042884827\n",
      "\n",
      "Training model with 3 hidden layers, 64 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 42s 4ms/step - loss: 0.6456 - accuracy: 0.7178 - val_loss: 0.7159 - val_accuracy: 0.6633\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5801 - accuracy: 0.7483 - val_loss: 0.6809 - val_accuracy: 0.6903\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5678 - accuracy: 0.7569 - val_loss: 0.6165 - val_accuracy: 0.7158\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5628 - accuracy: 0.7574 - val_loss: 0.5960 - val_accuracy: 0.7104\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5564 - accuracy: 0.7582 - val_loss: 0.5912 - val_accuracy: 0.7145\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5509 - accuracy: 0.7630 - val_loss: 0.5975 - val_accuracy: 0.7118\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5457 - accuracy: 0.7623 - val_loss: 0.6261 - val_accuracy: 0.6919\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5482 - accuracy: 0.7615 - val_loss: 0.5935 - val_accuracy: 0.7153\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.5479 - accuracy: 0.7620 - val_loss: 0.6036 - val_accuracy: 0.7186\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.5433 - accuracy: 0.7625 - val_loss: 0.5957 - val_accuracy: 0.7108\n",
      "Early stopped after 10 epochs.\n",
      "1689/1689 [==============================] - 5s 3ms/step - loss: 0.5912 - accuracy: 0.7145\n",
      "Validation accuracy: 0.7144786715507507\n",
      "\n",
      "Training model with 3 hidden layers, 64 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 19s 2ms/step - loss: 0.9993 - accuracy: 0.4955 - val_loss: 0.9101 - val_accuracy: 0.6265\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 37s 4ms/step - loss: 0.9250 - accuracy: 0.5637 - val_loss: 0.8700 - val_accuracy: 0.6307\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 34s 4ms/step - loss: 0.8787 - accuracy: 0.5917 - val_loss: 0.8190 - val_accuracy: 0.6354\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.8291 - accuracy: 0.6234 - val_loss: 0.7776 - val_accuracy: 0.6374\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.7743 - accuracy: 0.6576 - val_loss: 0.7222 - val_accuracy: 0.6586\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 29s 3ms/step - loss: 0.7300 - accuracy: 0.6832 - val_loss: 0.6894 - val_accuracy: 0.6755\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.6980 - accuracy: 0.6987 - val_loss: 0.6863 - val_accuracy: 0.6767\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.6734 - accuracy: 0.7106 - val_loss: 0.6643 - val_accuracy: 0.6895\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.6572 - accuracy: 0.7184 - val_loss: 0.6503 - val_accuracy: 0.6956\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.6418 - accuracy: 0.7258 - val_loss: 0.6494 - val_accuracy: 0.6973\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.6309 - accuracy: 0.7306 - val_loss: 0.6383 - val_accuracy: 0.7014\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 18s 2ms/step - loss: 0.6194 - accuracy: 0.7350 - val_loss: 0.6358 - val_accuracy: 0.7023\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 14s 2ms/step - loss: 0.6132 - accuracy: 0.7387 - val_loss: 0.6303 - val_accuracy: 0.7047\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.6063 - accuracy: 0.7420 - val_loss: 0.6279 - val_accuracy: 0.7059\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.6008 - accuracy: 0.7444 - val_loss: 0.6212 - val_accuracy: 0.7095\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5957 - accuracy: 0.7463 - val_loss: 0.6264 - val_accuracy: 0.7067\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5923 - accuracy: 0.7479 - val_loss: 0.6133 - val_accuracy: 0.7124\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5886 - accuracy: 0.7492 - val_loss: 0.6146 - val_accuracy: 0.7112\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5844 - accuracy: 0.7509 - val_loss: 0.6150 - val_accuracy: 0.7103\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5836 - accuracy: 0.7510 - val_loss: 0.6071 - val_accuracy: 0.7139\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5794 - accuracy: 0.7531 - val_loss: 0.6094 - val_accuracy: 0.7136\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5759 - accuracy: 0.7539 - val_loss: 0.6164 - val_accuracy: 0.7107\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5740 - accuracy: 0.7553 - val_loss: 0.6075 - val_accuracy: 0.7131\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 31s 3ms/step - loss: 0.5728 - accuracy: 0.7561 - val_loss: 0.6053 - val_accuracy: 0.7147\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5714 - accuracy: 0.7560 - val_loss: 0.6092 - val_accuracy: 0.7141\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.5694 - accuracy: 0.7565 - val_loss: 0.6067 - val_accuracy: 0.7147\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5690 - accuracy: 0.7569 - val_loss: 0.6009 - val_accuracy: 0.7172\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 22s 2ms/step - loss: 0.5665 - accuracy: 0.7582 - val_loss: 0.6035 - val_accuracy: 0.7162\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5658 - accuracy: 0.7583 - val_loss: 0.6035 - val_accuracy: 0.7152\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5640 - accuracy: 0.7589 - val_loss: 0.6029 - val_accuracy: 0.7160\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5624 - accuracy: 0.7595 - val_loss: 0.5993 - val_accuracy: 0.7170\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5629 - accuracy: 0.7598 - val_loss: 0.5960 - val_accuracy: 0.7196\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5610 - accuracy: 0.7599 - val_loss: 0.6054 - val_accuracy: 0.7152\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5598 - accuracy: 0.7600 - val_loss: 0.6025 - val_accuracy: 0.7145\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5600 - accuracy: 0.7605 - val_loss: 0.6007 - val_accuracy: 0.7159\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5597 - accuracy: 0.7605 - val_loss: 0.5945 - val_accuracy: 0.7184\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5566 - accuracy: 0.7618 - val_loss: 0.5957 - val_accuracy: 0.7194\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5572 - accuracy: 0.7617 - val_loss: 0.5997 - val_accuracy: 0.7176\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5553 - accuracy: 0.7621 - val_loss: 0.5905 - val_accuracy: 0.7208\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.5562 - accuracy: 0.7622 - val_loss: 0.5920 - val_accuracy: 0.7197\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5553 - accuracy: 0.7625 - val_loss: 0.5991 - val_accuracy: 0.7188\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5556 - accuracy: 0.7624 - val_loss: 0.5928 - val_accuracy: 0.7198\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5521 - accuracy: 0.7633 - val_loss: 0.5924 - val_accuracy: 0.7198\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 41s 5ms/step - loss: 0.5531 - accuracy: 0.7632 - val_loss: 0.5980 - val_accuracy: 0.7169\n",
      "Early stopped after 44 epochs.\n",
      "1689/1689 [==============================] - 5s 3ms/step - loss: 0.5905 - accuracy: 0.7208\n",
      "Validation accuracy: 0.7208437323570251\n",
      "\n",
      "Training model with 3 hidden layers, 64 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 41s 4ms/step - loss: 0.8192 - accuracy: 0.6268 - val_loss: 0.6840 - val_accuracy: 0.6752\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 39s 4ms/step - loss: 0.6644 - accuracy: 0.7139 - val_loss: 0.6521 - val_accuracy: 0.6919\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.6311 - accuracy: 0.7286 - val_loss: 0.6672 - val_accuracy: 0.6883\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.6198 - accuracy: 0.7329 - val_loss: 0.6483 - val_accuracy: 0.6960\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.6100 - accuracy: 0.7361 - val_loss: 0.6484 - val_accuracy: 0.7014\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.6059 - accuracy: 0.7375 - val_loss: 0.6459 - val_accuracy: 0.7001\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.6008 - accuracy: 0.7397 - val_loss: 0.6387 - val_accuracy: 0.7061\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5983 - accuracy: 0.7418 - val_loss: 0.6373 - val_accuracy: 0.7065\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5924 - accuracy: 0.7437 - val_loss: 0.6387 - val_accuracy: 0.7051\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5917 - accuracy: 0.7449 - val_loss: 0.6340 - val_accuracy: 0.7082\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5881 - accuracy: 0.7452 - val_loss: 0.6261 - val_accuracy: 0.7088\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 40s 4ms/step - loss: 0.5850 - accuracy: 0.7464 - val_loss: 0.6290 - val_accuracy: 0.7026\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5831 - accuracy: 0.7469 - val_loss: 0.6396 - val_accuracy: 0.7041\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5831 - accuracy: 0.7481 - val_loss: 0.6367 - val_accuracy: 0.7049\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5788 - accuracy: 0.7499 - val_loss: 0.6306 - val_accuracy: 0.7067\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5771 - accuracy: 0.7498 - val_loss: 0.6249 - val_accuracy: 0.7089\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5777 - accuracy: 0.7491 - val_loss: 0.6339 - val_accuracy: 0.7091\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5785 - accuracy: 0.7495 - val_loss: 0.6353 - val_accuracy: 0.7058\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5754 - accuracy: 0.7510 - val_loss: 0.6293 - val_accuracy: 0.7112\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5730 - accuracy: 0.7516 - val_loss: 0.6387 - val_accuracy: 0.7010\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.5720 - accuracy: 0.7519 - val_loss: 0.6278 - val_accuracy: 0.7133\n",
      "Early stopped after 21 epochs.\n",
      "1689/1689 [==============================] - 2s 920us/step - loss: 0.6249 - accuracy: 0.7089\n",
      "Validation accuracy: 0.7089462280273438\n",
      "\n",
      "Training model with 3 hidden layers, 64 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 14s 1ms/step - loss: 0.9667 - accuracy: 0.5345 - val_loss: 0.9100 - val_accuracy: 0.6893\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9490 - accuracy: 0.5538 - val_loss: 0.9839 - val_accuracy: 0.6250\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9556 - accuracy: 0.5550 - val_loss: 0.8934 - val_accuracy: 0.6964\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9493 - accuracy: 0.5586 - val_loss: 0.8770 - val_accuracy: 0.6926\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9505 - accuracy: 0.5588 - val_loss: 0.9150 - val_accuracy: 0.6698\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9535 - accuracy: 0.5557 - val_loss: 0.9088 - val_accuracy: 0.6864\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9535 - accuracy: 0.5565 - val_loss: 0.9037 - val_accuracy: 0.6904\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9491 - accuracy: 0.5572 - val_loss: 0.8917 - val_accuracy: 0.6937\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 13s 1ms/step - loss: 0.9491 - accuracy: 0.5596 - val_loss: 0.9215 - val_accuracy: 0.7019\n",
      "Early stopped after 9 epochs.\n",
      "1689/1689 [==============================] - 1s 876us/step - loss: 0.8770 - accuracy: 0.6926\n",
      "Validation accuracy: 0.6926079988479614\n",
      "\n",
      "Training model with 3 hidden layers, 128 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.7915 - accuracy: 0.6413 - val_loss: 0.7275 - val_accuracy: 0.6534\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.5871 - accuracy: 0.7478 - val_loss: 0.6392 - val_accuracy: 0.6997\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.5097 - accuracy: 0.7781 - val_loss: 0.6069 - val_accuracy: 0.7162\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4706 - accuracy: 0.7934 - val_loss: 0.5861 - val_accuracy: 0.7257\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4479 - accuracy: 0.8011 - val_loss: 0.5632 - val_accuracy: 0.7340\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4313 - accuracy: 0.8072 - val_loss: 0.5525 - val_accuracy: 0.7394\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4183 - accuracy: 0.8115 - val_loss: 0.5414 - val_accuracy: 0.7435\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4087 - accuracy: 0.8152 - val_loss: 0.5261 - val_accuracy: 0.7507\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4003 - accuracy: 0.8187 - val_loss: 0.5181 - val_accuracy: 0.7572\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3927 - accuracy: 0.8215 - val_loss: 0.5083 - val_accuracy: 0.7607\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3867 - accuracy: 0.8242 - val_loss: 0.5023 - val_accuracy: 0.7662\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3813 - accuracy: 0.8272 - val_loss: 0.4881 - val_accuracy: 0.7700\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3769 - accuracy: 0.8288 - val_loss: 0.4897 - val_accuracy: 0.7755\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3707 - accuracy: 0.8317 - val_loss: 0.4814 - val_accuracy: 0.7798\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3680 - accuracy: 0.8338 - val_loss: 0.4723 - val_accuracy: 0.7854\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3629 - accuracy: 0.8356 - val_loss: 0.4628 - val_accuracy: 0.7900\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3591 - accuracy: 0.8386 - val_loss: 0.4586 - val_accuracy: 0.7918\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3561 - accuracy: 0.8388 - val_loss: 0.4559 - val_accuracy: 0.7951\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3522 - accuracy: 0.8405 - val_loss: 0.4495 - val_accuracy: 0.7989\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3486 - accuracy: 0.8432 - val_loss: 0.4422 - val_accuracy: 0.8015\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3452 - accuracy: 0.8437 - val_loss: 0.4354 - val_accuracy: 0.8050\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3441 - accuracy: 0.8450 - val_loss: 0.4332 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3407 - accuracy: 0.8464 - val_loss: 0.4250 - val_accuracy: 0.8110\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3389 - accuracy: 0.8475 - val_loss: 0.4234 - val_accuracy: 0.8129\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3354 - accuracy: 0.8493 - val_loss: 0.4184 - val_accuracy: 0.8149\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3336 - accuracy: 0.8505 - val_loss: 0.4128 - val_accuracy: 0.8189\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 24s 3ms/step - loss: 0.3308 - accuracy: 0.8519 - val_loss: 0.4120 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 24s 3ms/step - loss: 0.3295 - accuracy: 0.8522 - val_loss: 0.4051 - val_accuracy: 0.8247\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 23s 3ms/step - loss: 0.3273 - accuracy: 0.8532 - val_loss: 0.4037 - val_accuracy: 0.8252\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 17s 2ms/step - loss: 0.3254 - accuracy: 0.8547 - val_loss: 0.4005 - val_accuracy: 0.8268\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3214 - accuracy: 0.8560 - val_loss: 0.3940 - val_accuracy: 0.8298\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3212 - accuracy: 0.8572 - val_loss: 0.3927 - val_accuracy: 0.8314\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3189 - accuracy: 0.8578 - val_loss: 0.3892 - val_accuracy: 0.8313\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3175 - accuracy: 0.8582 - val_loss: 0.3839 - val_accuracy: 0.8359\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3163 - accuracy: 0.8589 - val_loss: 0.3839 - val_accuracy: 0.8343\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3137 - accuracy: 0.8608 - val_loss: 0.3777 - val_accuracy: 0.8379\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3137 - accuracy: 0.8603 - val_loss: 0.3757 - val_accuracy: 0.8379\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3100 - accuracy: 0.8615 - val_loss: 0.3722 - val_accuracy: 0.8420\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3101 - accuracy: 0.8618 - val_loss: 0.3690 - val_accuracy: 0.8409\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3072 - accuracy: 0.8636 - val_loss: 0.3658 - val_accuracy: 0.8432\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3066 - accuracy: 0.8630 - val_loss: 0.3645 - val_accuracy: 0.8435\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3052 - accuracy: 0.8642 - val_loss: 0.3613 - val_accuracy: 0.8448\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3044 - accuracy: 0.8655 - val_loss: 0.3588 - val_accuracy: 0.8459\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3027 - accuracy: 0.8657 - val_loss: 0.3543 - val_accuracy: 0.8494\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3032 - accuracy: 0.8658 - val_loss: 0.3534 - val_accuracy: 0.8499\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3013 - accuracy: 0.8663 - val_loss: 0.3514 - val_accuracy: 0.8498\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3002 - accuracy: 0.8670 - val_loss: 0.3510 - val_accuracy: 0.8510\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2986 - accuracy: 0.8673 - val_loss: 0.3458 - val_accuracy: 0.8518\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2970 - accuracy: 0.8681 - val_loss: 0.3439 - val_accuracy: 0.8530\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2962 - accuracy: 0.8689 - val_loss: 0.3438 - val_accuracy: 0.8541\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2959 - accuracy: 0.8692 - val_loss: 0.3415 - val_accuracy: 0.8541\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2955 - accuracy: 0.8690 - val_loss: 0.3386 - val_accuracy: 0.8545\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2936 - accuracy: 0.8708 - val_loss: 0.3366 - val_accuracy: 0.8568\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2924 - accuracy: 0.8704 - val_loss: 0.3369 - val_accuracy: 0.8568\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2920 - accuracy: 0.8713 - val_loss: 0.3329 - val_accuracy: 0.8568\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2906 - accuracy: 0.8722 - val_loss: 0.3316 - val_accuracy: 0.8583\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2889 - accuracy: 0.8723 - val_loss: 0.3270 - val_accuracy: 0.8603\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2892 - accuracy: 0.8720 - val_loss: 0.3291 - val_accuracy: 0.8612\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2874 - accuracy: 0.8730 - val_loss: 0.3269 - val_accuracy: 0.8626\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2871 - accuracy: 0.8733 - val_loss: 0.3218 - val_accuracy: 0.8643\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2867 - accuracy: 0.8735 - val_loss: 0.3221 - val_accuracy: 0.8643\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2857 - accuracy: 0.8742 - val_loss: 0.3211 - val_accuracy: 0.8649\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2837 - accuracy: 0.8752 - val_loss: 0.3183 - val_accuracy: 0.8671\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2851 - accuracy: 0.8745 - val_loss: 0.3212 - val_accuracy: 0.8662\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2833 - accuracy: 0.8757 - val_loss: 0.3157 - val_accuracy: 0.8669\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2826 - accuracy: 0.8764 - val_loss: 0.3152 - val_accuracy: 0.8666\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2822 - accuracy: 0.8764 - val_loss: 0.3123 - val_accuracy: 0.8695\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2818 - accuracy: 0.8766 - val_loss: 0.3120 - val_accuracy: 0.8694\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2810 - accuracy: 0.8770 - val_loss: 0.3078 - val_accuracy: 0.8711\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2803 - accuracy: 0.8775 - val_loss: 0.3093 - val_accuracy: 0.8728\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2810 - accuracy: 0.8771 - val_loss: 0.3093 - val_accuracy: 0.8713\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2788 - accuracy: 0.8785 - val_loss: 0.3067 - val_accuracy: 0.8732\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2778 - accuracy: 0.8785 - val_loss: 0.3038 - val_accuracy: 0.8724\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2767 - accuracy: 0.8788 - val_loss: 0.3037 - val_accuracy: 0.8749\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2772 - accuracy: 0.8786 - val_loss: 0.3026 - val_accuracy: 0.8733\n",
      "Epoch 76/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2761 - accuracy: 0.8794 - val_loss: 0.3036 - val_accuracy: 0.8758\n",
      "Epoch 77/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2774 - accuracy: 0.8793 - val_loss: 0.3005 - val_accuracy: 0.8750\n",
      "Epoch 78/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2771 - accuracy: 0.8794 - val_loss: 0.2998 - val_accuracy: 0.8743\n",
      "Epoch 79/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2758 - accuracy: 0.8798 - val_loss: 0.3016 - val_accuracy: 0.8755\n",
      "Epoch 80/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2750 - accuracy: 0.8799 - val_loss: 0.2994 - val_accuracy: 0.8776\n",
      "Epoch 81/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2740 - accuracy: 0.8797 - val_loss: 0.2987 - val_accuracy: 0.8773\n",
      "Epoch 82/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2736 - accuracy: 0.8800 - val_loss: 0.2971 - val_accuracy: 0.8797\n",
      "Epoch 83/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2725 - accuracy: 0.8812 - val_loss: 0.2964 - val_accuracy: 0.8793\n",
      "Epoch 84/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2732 - accuracy: 0.8812 - val_loss: 0.2920 - val_accuracy: 0.8805\n",
      "Epoch 85/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2714 - accuracy: 0.8822 - val_loss: 0.2920 - val_accuracy: 0.8806\n",
      "Epoch 86/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2718 - accuracy: 0.8817 - val_loss: 0.2929 - val_accuracy: 0.8791\n",
      "Epoch 87/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2716 - accuracy: 0.8815 - val_loss: 0.2949 - val_accuracy: 0.8815\n",
      "Epoch 88/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2711 - accuracy: 0.8824 - val_loss: 0.2945 - val_accuracy: 0.8798\n",
      "Epoch 89/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2705 - accuracy: 0.8825 - val_loss: 0.2912 - val_accuracy: 0.8791\n",
      "Epoch 90/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2689 - accuracy: 0.8827 - val_loss: 0.2882 - val_accuracy: 0.8809\n",
      "Epoch 91/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2689 - accuracy: 0.8829 - val_loss: 0.2893 - val_accuracy: 0.8831\n",
      "Epoch 92/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2697 - accuracy: 0.8828 - val_loss: 0.2887 - val_accuracy: 0.8832\n",
      "Epoch 93/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2682 - accuracy: 0.8838 - val_loss: 0.2846 - val_accuracy: 0.8833\n",
      "Epoch 94/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2679 - accuracy: 0.8838 - val_loss: 0.2868 - val_accuracy: 0.8832\n",
      "Epoch 95/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2683 - accuracy: 0.8838 - val_loss: 0.2859 - val_accuracy: 0.8844\n",
      "Epoch 96/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2675 - accuracy: 0.8836 - val_loss: 0.2818 - val_accuracy: 0.8860\n",
      "Epoch 97/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2673 - accuracy: 0.8842 - val_loss: 0.2829 - val_accuracy: 0.8862\n",
      "Epoch 98/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2659 - accuracy: 0.8849 - val_loss: 0.2812 - val_accuracy: 0.8858\n",
      "Epoch 99/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2678 - accuracy: 0.8843 - val_loss: 0.2783 - val_accuracy: 0.8880\n",
      "Epoch 100/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2641 - accuracy: 0.8857 - val_loss: 0.2797 - val_accuracy: 0.8859\n",
      "Early stopped after 100 epochs.\n",
      "1689/1689 [==============================] - 2s 924us/step - loss: 0.2797 - accuracy: 0.8859\n",
      "Validation accuracy: 0.885909914970398\n",
      "\n",
      "Training model with 3 hidden layers, 128 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5206 - accuracy: 0.7700 - val_loss: 0.5582 - val_accuracy: 0.7401\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4116 - accuracy: 0.8154 - val_loss: 0.5164 - val_accuracy: 0.7608\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3844 - accuracy: 0.8279 - val_loss: 0.4746 - val_accuracy: 0.7830\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3686 - accuracy: 0.8348 - val_loss: 0.4462 - val_accuracy: 0.7950\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3566 - accuracy: 0.8408 - val_loss: 0.4349 - val_accuracy: 0.8069\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3477 - accuracy: 0.8452 - val_loss: 0.4217 - val_accuracy: 0.8149\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3387 - accuracy: 0.8490 - val_loss: 0.4114 - val_accuracy: 0.8187\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3331 - accuracy: 0.8527 - val_loss: 0.3930 - val_accuracy: 0.8277\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3274 - accuracy: 0.8542 - val_loss: 0.3917 - val_accuracy: 0.8367\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3243 - accuracy: 0.8562 - val_loss: 0.3748 - val_accuracy: 0.8388\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3192 - accuracy: 0.8588 - val_loss: 0.3647 - val_accuracy: 0.8423\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3164 - accuracy: 0.8598 - val_loss: 0.3600 - val_accuracy: 0.8490\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3126 - accuracy: 0.8615 - val_loss: 0.3520 - val_accuracy: 0.8493\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3106 - accuracy: 0.8628 - val_loss: 0.3559 - val_accuracy: 0.8535\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3066 - accuracy: 0.8650 - val_loss: 0.3445 - val_accuracy: 0.8531\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.3047 - accuracy: 0.8658 - val_loss: 0.3348 - val_accuracy: 0.8588\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3028 - accuracy: 0.8669 - val_loss: 0.3447 - val_accuracy: 0.8564\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.3015 - accuracy: 0.8676 - val_loss: 0.3429 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2995 - accuracy: 0.8685 - val_loss: 0.3380 - val_accuracy: 0.8589\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2974 - accuracy: 0.8695 - val_loss: 0.3288 - val_accuracy: 0.8616\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2953 - accuracy: 0.8706 - val_loss: 0.3282 - val_accuracy: 0.8649\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2947 - accuracy: 0.8713 - val_loss: 0.3264 - val_accuracy: 0.8662\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2934 - accuracy: 0.8711 - val_loss: 0.3236 - val_accuracy: 0.8647\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2917 - accuracy: 0.8725 - val_loss: 0.3227 - val_accuracy: 0.8649\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2918 - accuracy: 0.8726 - val_loss: 0.3262 - val_accuracy: 0.8632\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2903 - accuracy: 0.8733 - val_loss: 0.3119 - val_accuracy: 0.8675\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2874 - accuracy: 0.8736 - val_loss: 0.3128 - val_accuracy: 0.8698\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2864 - accuracy: 0.8748 - val_loss: 0.3052 - val_accuracy: 0.8733\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2857 - accuracy: 0.8752 - val_loss: 0.3058 - val_accuracy: 0.8751\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2847 - accuracy: 0.8759 - val_loss: 0.3080 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2836 - accuracy: 0.8758 - val_loss: 0.3053 - val_accuracy: 0.8762\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2843 - accuracy: 0.8758 - val_loss: 0.3002 - val_accuracy: 0.8744\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2821 - accuracy: 0.8774 - val_loss: 0.2995 - val_accuracy: 0.8785\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2821 - accuracy: 0.8768 - val_loss: 0.3016 - val_accuracy: 0.8737\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2801 - accuracy: 0.8775 - val_loss: 0.3038 - val_accuracy: 0.8723\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2810 - accuracy: 0.8766 - val_loss: 0.3035 - val_accuracy: 0.8775\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2777 - accuracy: 0.8793 - val_loss: 0.3034 - val_accuracy: 0.8790\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2785 - accuracy: 0.8786 - val_loss: 0.2984 - val_accuracy: 0.8803\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2775 - accuracy: 0.8793 - val_loss: 0.2922 - val_accuracy: 0.8800\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2768 - accuracy: 0.8801 - val_loss: 0.2914 - val_accuracy: 0.8756\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2757 - accuracy: 0.8797 - val_loss: 0.2968 - val_accuracy: 0.8792\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2758 - accuracy: 0.8805 - val_loss: 0.2856 - val_accuracy: 0.8820\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2753 - accuracy: 0.8804 - val_loss: 0.2860 - val_accuracy: 0.8815\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2741 - accuracy: 0.8813 - val_loss: 0.2876 - val_accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2747 - accuracy: 0.8810 - val_loss: 0.2879 - val_accuracy: 0.8805\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2740 - accuracy: 0.8819 - val_loss: 0.2849 - val_accuracy: 0.8847\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2715 - accuracy: 0.8825 - val_loss: 0.2868 - val_accuracy: 0.8856\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2722 - accuracy: 0.8821 - val_loss: 0.2757 - val_accuracy: 0.8876\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.2713 - accuracy: 0.8827 - val_loss: 0.2802 - val_accuracy: 0.8854\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2711 - accuracy: 0.8822 - val_loss: 0.2845 - val_accuracy: 0.8848\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2710 - accuracy: 0.8822 - val_loss: 0.2798 - val_accuracy: 0.8870\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2708 - accuracy: 0.8824 - val_loss: 0.2841 - val_accuracy: 0.8808\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.2705 - accuracy: 0.8830 - val_loss: 0.2770 - val_accuracy: 0.8859\n",
      "Early stopped after 53 epochs.\n",
      "1689/1689 [==============================] - 2s 937us/step - loss: 0.2757 - accuracy: 0.8876\n",
      "Validation accuracy: 0.8875566720962524\n",
      "\n",
      "Training model with 3 hidden layers, 128 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.6218 - accuracy: 0.7317 - val_loss: 0.6475 - val_accuracy: 0.6884\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.5599 - accuracy: 0.7565 - val_loss: 0.6165 - val_accuracy: 0.7133\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.5479 - accuracy: 0.7624 - val_loss: 0.6171 - val_accuracy: 0.7060\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.5383 - accuracy: 0.7661 - val_loss: 0.5926 - val_accuracy: 0.7134\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.5395 - accuracy: 0.7671 - val_loss: 0.6024 - val_accuracy: 0.7130\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5352 - accuracy: 0.7677 - val_loss: 0.6064 - val_accuracy: 0.7092\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5376 - accuracy: 0.7659 - val_loss: 0.5788 - val_accuracy: 0.7242\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5311 - accuracy: 0.7694 - val_loss: 0.5589 - val_accuracy: 0.7235\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.5313 - accuracy: 0.7707 - val_loss: 0.6161 - val_accuracy: 0.6977\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5310 - accuracy: 0.7702 - val_loss: 0.6343 - val_accuracy: 0.6906\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5289 - accuracy: 0.7697 - val_loss: 0.5920 - val_accuracy: 0.7189\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5342 - accuracy: 0.7666 - val_loss: 0.6107 - val_accuracy: 0.6980\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5344 - accuracy: 0.7688 - val_loss: 0.5934 - val_accuracy: 0.7214\n",
      "Early stopped after 13 epochs.\n",
      "1689/1689 [==============================] - 2s 951us/step - loss: 0.5589 - accuracy: 0.7235\n",
      "Validation accuracy: 0.7234711647033691\n",
      "\n",
      "Training model with 3 hidden layers, 128 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.9508 - accuracy: 0.5370 - val_loss: 0.8582 - val_accuracy: 0.6043\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.8130 - accuracy: 0.6336 - val_loss: 0.7872 - val_accuracy: 0.6088\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.6913 - accuracy: 0.7012 - val_loss: 0.7148 - val_accuracy: 0.6555\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.6162 - accuracy: 0.7359 - val_loss: 0.6702 - val_accuracy: 0.6850\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5772 - accuracy: 0.7519 - val_loss: 0.6446 - val_accuracy: 0.6995\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5503 - accuracy: 0.7633 - val_loss: 0.6373 - val_accuracy: 0.7029\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5312 - accuracy: 0.7702 - val_loss: 0.6225 - val_accuracy: 0.7085\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5189 - accuracy: 0.7755 - val_loss: 0.6017 - val_accuracy: 0.7184\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5054 - accuracy: 0.7800 - val_loss: 0.5994 - val_accuracy: 0.7199\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4983 - accuracy: 0.7828 - val_loss: 0.5897 - val_accuracy: 0.7235\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4910 - accuracy: 0.7855 - val_loss: 0.5843 - val_accuracy: 0.7258\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4863 - accuracy: 0.7870 - val_loss: 0.5895 - val_accuracy: 0.7261\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4803 - accuracy: 0.7890 - val_loss: 0.5793 - val_accuracy: 0.7281\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4767 - accuracy: 0.7906 - val_loss: 0.5807 - val_accuracy: 0.7285\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4720 - accuracy: 0.7915 - val_loss: 0.5692 - val_accuracy: 0.7341\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4701 - accuracy: 0.7921 - val_loss: 0.5703 - val_accuracy: 0.7315\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4671 - accuracy: 0.7938 - val_loss: 0.5655 - val_accuracy: 0.7353\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4636 - accuracy: 0.7960 - val_loss: 0.5591 - val_accuracy: 0.7374\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4604 - accuracy: 0.7971 - val_loss: 0.5584 - val_accuracy: 0.7376\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4601 - accuracy: 0.7961 - val_loss: 0.5556 - val_accuracy: 0.7385\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4578 - accuracy: 0.7972 - val_loss: 0.5533 - val_accuracy: 0.7407\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4571 - accuracy: 0.7978 - val_loss: 0.5524 - val_accuracy: 0.7408\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4532 - accuracy: 0.7984 - val_loss: 0.5472 - val_accuracy: 0.7444\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4535 - accuracy: 0.7988 - val_loss: 0.5485 - val_accuracy: 0.7432\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4512 - accuracy: 0.7998 - val_loss: 0.5532 - val_accuracy: 0.7424\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4504 - accuracy: 0.8008 - val_loss: 0.5396 - val_accuracy: 0.7458\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4478 - accuracy: 0.8011 - val_loss: 0.5446 - val_accuracy: 0.7432\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4494 - accuracy: 0.8012 - val_loss: 0.5410 - val_accuracy: 0.7448\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4468 - accuracy: 0.8008 - val_loss: 0.5432 - val_accuracy: 0.7438\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4466 - accuracy: 0.8014 - val_loss: 0.5419 - val_accuracy: 0.7469\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4455 - accuracy: 0.8019 - val_loss: 0.5372 - val_accuracy: 0.7455\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4433 - accuracy: 0.8029 - val_loss: 0.5346 - val_accuracy: 0.7506\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4437 - accuracy: 0.8026 - val_loss: 0.5359 - val_accuracy: 0.7472\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4421 - accuracy: 0.8028 - val_loss: 0.5336 - val_accuracy: 0.7482\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4423 - accuracy: 0.8030 - val_loss: 0.5391 - val_accuracy: 0.7478\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4413 - accuracy: 0.8040 - val_loss: 0.5317 - val_accuracy: 0.7495\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4413 - accuracy: 0.8032 - val_loss: 0.5342 - val_accuracy: 0.7491\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4408 - accuracy: 0.8035 - val_loss: 0.5332 - val_accuracy: 0.7506\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4385 - accuracy: 0.8042 - val_loss: 0.5314 - val_accuracy: 0.7493\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4386 - accuracy: 0.8048 - val_loss: 0.5291 - val_accuracy: 0.7514\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4370 - accuracy: 0.8050 - val_loss: 0.5254 - val_accuracy: 0.7532\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4356 - accuracy: 0.8056 - val_loss: 0.5244 - val_accuracy: 0.7540\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4351 - accuracy: 0.8063 - val_loss: 0.5255 - val_accuracy: 0.7528\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4348 - accuracy: 0.8059 - val_loss: 0.5260 - val_accuracy: 0.7548\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4355 - accuracy: 0.8056 - val_loss: 0.5296 - val_accuracy: 0.7515\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4347 - accuracy: 0.8063 - val_loss: 0.5222 - val_accuracy: 0.7527\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4355 - accuracy: 0.8051 - val_loss: 0.5258 - val_accuracy: 0.7541\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4334 - accuracy: 0.8064 - val_loss: 0.5257 - val_accuracy: 0.7539\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4326 - accuracy: 0.8066 - val_loss: 0.5206 - val_accuracy: 0.7541\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4328 - accuracy: 0.8064 - val_loss: 0.5190 - val_accuracy: 0.7570\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4333 - accuracy: 0.8067 - val_loss: 0.5146 - val_accuracy: 0.7571\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4312 - accuracy: 0.8075 - val_loss: 0.5219 - val_accuracy: 0.7559\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4318 - accuracy: 0.8070 - val_loss: 0.5226 - val_accuracy: 0.7556\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4318 - accuracy: 0.8067 - val_loss: 0.5177 - val_accuracy: 0.7560\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4303 - accuracy: 0.8078 - val_loss: 0.5199 - val_accuracy: 0.7550\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4299 - accuracy: 0.8076 - val_loss: 0.5202 - val_accuracy: 0.7556\n",
      "Early stopped after 56 epochs.\n",
      "1689/1689 [==============================] - 2s 904us/step - loss: 0.5146 - accuracy: 0.7571\n",
      "Validation accuracy: 0.757054328918457\n",
      "\n",
      "Training model with 3 hidden layers, 128 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.6838 - accuracy: 0.6967 - val_loss: 0.6104 - val_accuracy: 0.7105\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.5381 - accuracy: 0.7662 - val_loss: 0.6098 - val_accuracy: 0.7142\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5137 - accuracy: 0.7756 - val_loss: 0.5864 - val_accuracy: 0.7235\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.5023 - accuracy: 0.7795 - val_loss: 0.5838 - val_accuracy: 0.7251\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4942 - accuracy: 0.7819 - val_loss: 0.5710 - val_accuracy: 0.7268\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4872 - accuracy: 0.7854 - val_loss: 0.5806 - val_accuracy: 0.7272\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4829 - accuracy: 0.7859 - val_loss: 0.5578 - val_accuracy: 0.7343\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4785 - accuracy: 0.7882 - val_loss: 0.5555 - val_accuracy: 0.7354\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4743 - accuracy: 0.7900 - val_loss: 0.5614 - val_accuracy: 0.7362\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4713 - accuracy: 0.7911 - val_loss: 0.5480 - val_accuracy: 0.7386\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4705 - accuracy: 0.7911 - val_loss: 0.5403 - val_accuracy: 0.7433\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4663 - accuracy: 0.7933 - val_loss: 0.5449 - val_accuracy: 0.7426\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4660 - accuracy: 0.7925 - val_loss: 0.5367 - val_accuracy: 0.7427\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4642 - accuracy: 0.7933 - val_loss: 0.5374 - val_accuracy: 0.7428\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4620 - accuracy: 0.7929 - val_loss: 0.5419 - val_accuracy: 0.7468\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4593 - accuracy: 0.7955 - val_loss: 0.5398 - val_accuracy: 0.7445\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4605 - accuracy: 0.7948 - val_loss: 0.5376 - val_accuracy: 0.7472\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.4594 - accuracy: 0.7949 - val_loss: 0.5300 - val_accuracy: 0.7519\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4584 - accuracy: 0.7951 - val_loss: 0.5369 - val_accuracy: 0.7439\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4559 - accuracy: 0.7963 - val_loss: 0.5206 - val_accuracy: 0.7568\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4565 - accuracy: 0.7970 - val_loss: 0.5292 - val_accuracy: 0.7490\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4548 - accuracy: 0.7968 - val_loss: 0.5249 - val_accuracy: 0.7541\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4540 - accuracy: 0.7976 - val_loss: 0.5245 - val_accuracy: 0.7512\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4533 - accuracy: 0.7973 - val_loss: 0.5248 - val_accuracy: 0.7532\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.4540 - accuracy: 0.7971 - val_loss: 0.5304 - val_accuracy: 0.7489\n",
      "Early stopped after 25 epochs.\n",
      "1689/1689 [==============================] - 2s 927us/step - loss: 0.5206 - accuracy: 0.7568\n",
      "Validation accuracy: 0.7568322420120239\n",
      "\n",
      "Training model with 3 hidden layers, 128 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.9597 - accuracy: 0.5460 - val_loss: 0.8771 - val_accuracy: 0.5883\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.9131 - accuracy: 0.5988 - val_loss: 0.8841 - val_accuracy: 0.5743\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.9157 - accuracy: 0.6025 - val_loss: 0.8669 - val_accuracy: 0.6040\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.9166 - accuracy: 0.5976 - val_loss: 0.8733 - val_accuracy: 0.5867\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.9146 - accuracy: 0.6005 - val_loss: 0.8400 - val_accuracy: 0.6078\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.9071 - accuracy: 0.6062 - val_loss: 0.8746 - val_accuracy: 0.6314\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.9181 - accuracy: 0.5992 - val_loss: 0.9063 - val_accuracy: 0.6240\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.9157 - accuracy: 0.6019 - val_loss: 0.9016 - val_accuracy: 0.5977\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 15s 2ms/step - loss: 0.9109 - accuracy: 0.6046 - val_loss: 0.8857 - val_accuracy: 0.6048\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 16s 2ms/step - loss: 0.9150 - accuracy: 0.5971 - val_loss: 0.9339 - val_accuracy: 0.6020\n",
      "Early stopped after 10 epochs.\n",
      "1689/1689 [==============================] - 2s 951us/step - loss: 0.8400 - accuracy: 0.6078\n",
      "Validation accuracy: 0.607752799987793\n",
      "\n",
      "Training model with 3 hidden layers, 256 neurons, 0.2 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.6634 - accuracy: 0.7082 - val_loss: 0.6309 - val_accuracy: 0.7031\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4784 - accuracy: 0.7894 - val_loss: 0.5743 - val_accuracy: 0.7286\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4285 - accuracy: 0.8074 - val_loss: 0.5626 - val_accuracy: 0.7353\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4023 - accuracy: 0.8173 - val_loss: 0.5293 - val_accuracy: 0.7501\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3848 - accuracy: 0.8244 - val_loss: 0.5076 - val_accuracy: 0.7621\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3708 - accuracy: 0.8308 - val_loss: 0.4940 - val_accuracy: 0.7720\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3597 - accuracy: 0.8366 - val_loss: 0.4775 - val_accuracy: 0.7844\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3489 - accuracy: 0.8416 - val_loss: 0.4598 - val_accuracy: 0.7919\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3401 - accuracy: 0.8466 - val_loss: 0.4407 - val_accuracy: 0.8038\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3308 - accuracy: 0.8515 - val_loss: 0.4223 - val_accuracy: 0.8121\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3227 - accuracy: 0.8552 - val_loss: 0.4134 - val_accuracy: 0.8177\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3155 - accuracy: 0.8584 - val_loss: 0.4032 - val_accuracy: 0.8228\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3084 - accuracy: 0.8621 - val_loss: 0.3877 - val_accuracy: 0.8302\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3027 - accuracy: 0.8657 - val_loss: 0.3713 - val_accuracy: 0.8378\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2960 - accuracy: 0.8691 - val_loss: 0.3644 - val_accuracy: 0.8426\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2904 - accuracy: 0.8716 - val_loss: 0.3530 - val_accuracy: 0.8483\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2837 - accuracy: 0.8750 - val_loss: 0.3419 - val_accuracy: 0.8515\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2785 - accuracy: 0.8775 - val_loss: 0.3317 - val_accuracy: 0.8602\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2742 - accuracy: 0.8796 - val_loss: 0.3238 - val_accuracy: 0.8638\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2700 - accuracy: 0.8814 - val_loss: 0.3183 - val_accuracy: 0.8664\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2657 - accuracy: 0.8841 - val_loss: 0.3086 - val_accuracy: 0.8718\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2613 - accuracy: 0.8853 - val_loss: 0.2995 - val_accuracy: 0.8776\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2567 - accuracy: 0.8881 - val_loss: 0.2966 - val_accuracy: 0.8780\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2527 - accuracy: 0.8900 - val_loss: 0.2897 - val_accuracy: 0.8814\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2493 - accuracy: 0.8916 - val_loss: 0.2828 - val_accuracy: 0.8853\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2447 - accuracy: 0.8942 - val_loss: 0.2780 - val_accuracy: 0.8891\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2428 - accuracy: 0.8948 - val_loss: 0.2711 - val_accuracy: 0.8904\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2396 - accuracy: 0.8968 - val_loss: 0.2682 - val_accuracy: 0.8935\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2366 - accuracy: 0.8979 - val_loss: 0.2624 - val_accuracy: 0.8956\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2349 - accuracy: 0.8982 - val_loss: 0.2583 - val_accuracy: 0.8976\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2309 - accuracy: 0.9010 - val_loss: 0.2515 - val_accuracy: 0.8998\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2279 - accuracy: 0.9022 - val_loss: 0.2474 - val_accuracy: 0.9023\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2253 - accuracy: 0.9034 - val_loss: 0.2453 - val_accuracy: 0.9043\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2240 - accuracy: 0.9047 - val_loss: 0.2394 - val_accuracy: 0.9066\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2212 - accuracy: 0.9054 - val_loss: 0.2447 - val_accuracy: 0.9032\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2193 - accuracy: 0.9063 - val_loss: 0.2331 - val_accuracy: 0.9084\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2173 - accuracy: 0.9079 - val_loss: 0.2306 - val_accuracy: 0.9099\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2161 - accuracy: 0.9082 - val_loss: 0.2274 - val_accuracy: 0.9104\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2145 - accuracy: 0.9080 - val_loss: 0.2233 - val_accuracy: 0.9116\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2136 - accuracy: 0.9092 - val_loss: 0.2213 - val_accuracy: 0.9124\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2105 - accuracy: 0.9106 - val_loss: 0.2206 - val_accuracy: 0.9159\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2087 - accuracy: 0.9114 - val_loss: 0.2199 - val_accuracy: 0.9140\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2070 - accuracy: 0.9125 - val_loss: 0.2128 - val_accuracy: 0.9162\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2059 - accuracy: 0.9129 - val_loss: 0.2104 - val_accuracy: 0.9172\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2036 - accuracy: 0.9135 - val_loss: 0.2090 - val_accuracy: 0.9178\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2032 - accuracy: 0.9141 - val_loss: 0.2067 - val_accuracy: 0.9204\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2012 - accuracy: 0.9151 - val_loss: 0.2047 - val_accuracy: 0.9192\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.2004 - accuracy: 0.9154 - val_loss: 0.2025 - val_accuracy: 0.9199\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1986 - accuracy: 0.9159 - val_loss: 0.2030 - val_accuracy: 0.9219\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1977 - accuracy: 0.9167 - val_loss: 0.1988 - val_accuracy: 0.9223\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1964 - accuracy: 0.9171 - val_loss: 0.1966 - val_accuracy: 0.9221\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1953 - accuracy: 0.9174 - val_loss: 0.1958 - val_accuracy: 0.9225\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1932 - accuracy: 0.9188 - val_loss: 0.1958 - val_accuracy: 0.9228\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1924 - accuracy: 0.9191 - val_loss: 0.1920 - val_accuracy: 0.9244\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1928 - accuracy: 0.9186 - val_loss: 0.1914 - val_accuracy: 0.9242\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1909 - accuracy: 0.9196 - val_loss: 0.1879 - val_accuracy: 0.9245\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1892 - accuracy: 0.9211 - val_loss: 0.1859 - val_accuracy: 0.9264\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1876 - accuracy: 0.9214 - val_loss: 0.1876 - val_accuracy: 0.9270\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1887 - accuracy: 0.9205 - val_loss: 0.1868 - val_accuracy: 0.9274\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1862 - accuracy: 0.9221 - val_loss: 0.1827 - val_accuracy: 0.9282\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1860 - accuracy: 0.9219 - val_loss: 0.1798 - val_accuracy: 0.9295\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1853 - accuracy: 0.9216 - val_loss: 0.1776 - val_accuracy: 0.9306\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1839 - accuracy: 0.9228 - val_loss: 0.1775 - val_accuracy: 0.9301\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1838 - accuracy: 0.9231 - val_loss: 0.1786 - val_accuracy: 0.9299\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1824 - accuracy: 0.9233 - val_loss: 0.1770 - val_accuracy: 0.9304\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1814 - accuracy: 0.9238 - val_loss: 0.1762 - val_accuracy: 0.9316\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1800 - accuracy: 0.9252 - val_loss: 0.1777 - val_accuracy: 0.9305\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1803 - accuracy: 0.9251 - val_loss: 0.1760 - val_accuracy: 0.9299\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1799 - accuracy: 0.9246 - val_loss: 0.1726 - val_accuracy: 0.9318\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1778 - accuracy: 0.9256 - val_loss: 0.1710 - val_accuracy: 0.9327\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1772 - accuracy: 0.9263 - val_loss: 0.1713 - val_accuracy: 0.9320\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1767 - accuracy: 0.9261 - val_loss: 0.1724 - val_accuracy: 0.9321\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1771 - accuracy: 0.9259 - val_loss: 0.1669 - val_accuracy: 0.9340\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1756 - accuracy: 0.9261 - val_loss: 0.1678 - val_accuracy: 0.9348\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1744 - accuracy: 0.9271 - val_loss: 0.1665 - val_accuracy: 0.9337\n",
      "Epoch 76/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1749 - accuracy: 0.9271 - val_loss: 0.1665 - val_accuracy: 0.9332\n",
      "Epoch 77/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1737 - accuracy: 0.9275 - val_loss: 0.1662 - val_accuracy: 0.9341\n",
      "Epoch 78/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1738 - accuracy: 0.9281 - val_loss: 0.1650 - val_accuracy: 0.9351\n",
      "Epoch 79/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1723 - accuracy: 0.9282 - val_loss: 0.1626 - val_accuracy: 0.9355\n",
      "Epoch 80/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1728 - accuracy: 0.9279 - val_loss: 0.1641 - val_accuracy: 0.9351\n",
      "Epoch 81/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1707 - accuracy: 0.9292 - val_loss: 0.1621 - val_accuracy: 0.9353\n",
      "Epoch 82/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1704 - accuracy: 0.9289 - val_loss: 0.1598 - val_accuracy: 0.9355\n",
      "Epoch 83/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1706 - accuracy: 0.9290 - val_loss: 0.1600 - val_accuracy: 0.9365\n",
      "Epoch 84/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1701 - accuracy: 0.9290 - val_loss: 0.1625 - val_accuracy: 0.9344\n",
      "Epoch 85/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1694 - accuracy: 0.9289 - val_loss: 0.1626 - val_accuracy: 0.9346\n",
      "Epoch 86/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1701 - accuracy: 0.9293 - val_loss: 0.1585 - val_accuracy: 0.9374\n",
      "Epoch 87/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1671 - accuracy: 0.9305 - val_loss: 0.1569 - val_accuracy: 0.9373\n",
      "Epoch 88/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1668 - accuracy: 0.9305 - val_loss: 0.1599 - val_accuracy: 0.9369\n",
      "Epoch 89/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1684 - accuracy: 0.9301 - val_loss: 0.1563 - val_accuracy: 0.9371\n",
      "Epoch 90/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1666 - accuracy: 0.9305 - val_loss: 0.1557 - val_accuracy: 0.9373\n",
      "Epoch 91/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1669 - accuracy: 0.9303 - val_loss: 0.1542 - val_accuracy: 0.9371\n",
      "Epoch 92/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1650 - accuracy: 0.9314 - val_loss: 0.1553 - val_accuracy: 0.9369\n",
      "Epoch 93/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1659 - accuracy: 0.9309 - val_loss: 0.1556 - val_accuracy: 0.9377\n",
      "Epoch 94/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1648 - accuracy: 0.9317 - val_loss: 0.1548 - val_accuracy: 0.9378\n",
      "Epoch 95/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1656 - accuracy: 0.9308 - val_loss: 0.1531 - val_accuracy: 0.9383\n",
      "Epoch 96/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1637 - accuracy: 0.9317 - val_loss: 0.1547 - val_accuracy: 0.9372\n",
      "Epoch 97/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1640 - accuracy: 0.9319 - val_loss: 0.1503 - val_accuracy: 0.9390\n",
      "Epoch 98/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1632 - accuracy: 0.9320 - val_loss: 0.1529 - val_accuracy: 0.9379\n",
      "Epoch 99/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1628 - accuracy: 0.9323 - val_loss: 0.1512 - val_accuracy: 0.9389\n",
      "Epoch 100/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1615 - accuracy: 0.9326 - val_loss: 0.1498 - val_accuracy: 0.9393\n",
      "Early stopped after 100 epochs.\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 0.1498 - accuracy: 0.9393\n",
      "Validation accuracy: 0.9392728209495544\n",
      "\n",
      "Training model with 3 hidden layers, 256 neurons, 0.2 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.4746 - accuracy: 0.7895 - val_loss: 0.4996 - val_accuracy: 0.7638\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3658 - accuracy: 0.8368 - val_loss: 0.4386 - val_accuracy: 0.8040\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3317 - accuracy: 0.8532 - val_loss: 0.3898 - val_accuracy: 0.8273\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3078 - accuracy: 0.8649 - val_loss: 0.3650 - val_accuracy: 0.8410\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2909 - accuracy: 0.8723 - val_loss: 0.3391 - val_accuracy: 0.8489\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2773 - accuracy: 0.8795 - val_loss: 0.3076 - val_accuracy: 0.8666\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2678 - accuracy: 0.8845 - val_loss: 0.3012 - val_accuracy: 0.8731\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2598 - accuracy: 0.8879 - val_loss: 0.2989 - val_accuracy: 0.8739\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2526 - accuracy: 0.8918 - val_loss: 0.2690 - val_accuracy: 0.8860\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2471 - accuracy: 0.8942 - val_loss: 0.2630 - val_accuracy: 0.8901\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2407 - accuracy: 0.8966 - val_loss: 0.2586 - val_accuracy: 0.8927\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2365 - accuracy: 0.8991 - val_loss: 0.2506 - val_accuracy: 0.8958\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2318 - accuracy: 0.9012 - val_loss: 0.2401 - val_accuracy: 0.9010\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2290 - accuracy: 0.9027 - val_loss: 0.2408 - val_accuracy: 0.8999\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2250 - accuracy: 0.9051 - val_loss: 0.2304 - val_accuracy: 0.9031\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2224 - accuracy: 0.9067 - val_loss: 0.2316 - val_accuracy: 0.9043\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2189 - accuracy: 0.9076 - val_loss: 0.2310 - val_accuracy: 0.9045\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2168 - accuracy: 0.9087 - val_loss: 0.2216 - val_accuracy: 0.9079\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2153 - accuracy: 0.9088 - val_loss: 0.2124 - val_accuracy: 0.9113\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2134 - accuracy: 0.9098 - val_loss: 0.2095 - val_accuracy: 0.9118\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2101 - accuracy: 0.9114 - val_loss: 0.2151 - val_accuracy: 0.9105\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2083 - accuracy: 0.9124 - val_loss: 0.2117 - val_accuracy: 0.9138\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2070 - accuracy: 0.9136 - val_loss: 0.2076 - val_accuracy: 0.9169\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2054 - accuracy: 0.9139 - val_loss: 0.2017 - val_accuracy: 0.9172\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.2030 - accuracy: 0.9149 - val_loss: 0.2012 - val_accuracy: 0.9179\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2033 - accuracy: 0.9151 - val_loss: 0.2011 - val_accuracy: 0.9198\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.2012 - accuracy: 0.9157 - val_loss: 0.2025 - val_accuracy: 0.9181\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1991 - accuracy: 0.9167 - val_loss: 0.1963 - val_accuracy: 0.9192\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1977 - accuracy: 0.9168 - val_loss: 0.1933 - val_accuracy: 0.9198\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1964 - accuracy: 0.9176 - val_loss: 0.1907 - val_accuracy: 0.9202\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1966 - accuracy: 0.9177 - val_loss: 0.1924 - val_accuracy: 0.9218\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1961 - accuracy: 0.9179 - val_loss: 0.1884 - val_accuracy: 0.9211\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1943 - accuracy: 0.9186 - val_loss: 0.1913 - val_accuracy: 0.9215\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1936 - accuracy: 0.9190 - val_loss: 0.1852 - val_accuracy: 0.9241\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1915 - accuracy: 0.9196 - val_loss: 0.1903 - val_accuracy: 0.9226\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1907 - accuracy: 0.9200 - val_loss: 0.1881 - val_accuracy: 0.9208\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1906 - accuracy: 0.9203 - val_loss: 0.1835 - val_accuracy: 0.9239\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1898 - accuracy: 0.9212 - val_loss: 0.1792 - val_accuracy: 0.9254\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1887 - accuracy: 0.9209 - val_loss: 0.1815 - val_accuracy: 0.9248\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1882 - accuracy: 0.9212 - val_loss: 0.1843 - val_accuracy: 0.9258\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1873 - accuracy: 0.9218 - val_loss: 0.1804 - val_accuracy: 0.9252\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1871 - accuracy: 0.9225 - val_loss: 0.1771 - val_accuracy: 0.9265\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1852 - accuracy: 0.9230 - val_loss: 0.1721 - val_accuracy: 0.9292\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1851 - accuracy: 0.9233 - val_loss: 0.1786 - val_accuracy: 0.9271\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1855 - accuracy: 0.9232 - val_loss: 0.1773 - val_accuracy: 0.9261\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1849 - accuracy: 0.9233 - val_loss: 0.1757 - val_accuracy: 0.9277\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1838 - accuracy: 0.9234 - val_loss: 0.1744 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1825 - accuracy: 0.9240 - val_loss: 0.1714 - val_accuracy: 0.9255\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1831 - accuracy: 0.9238 - val_loss: 0.1752 - val_accuracy: 0.9269\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1826 - accuracy: 0.9237 - val_loss: 0.1766 - val_accuracy: 0.9266\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1828 - accuracy: 0.9244 - val_loss: 0.1676 - val_accuracy: 0.9269\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1812 - accuracy: 0.9244 - val_loss: 0.1685 - val_accuracy: 0.9304\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1815 - accuracy: 0.9248 - val_loss: 0.1711 - val_accuracy: 0.9287\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.1802 - accuracy: 0.9253 - val_loss: 0.1697 - val_accuracy: 0.9287\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1802 - accuracy: 0.9254 - val_loss: 0.1684 - val_accuracy: 0.9294\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1790 - accuracy: 0.9258 - val_loss: 0.1666 - val_accuracy: 0.9304\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1780 - accuracy: 0.9261 - val_loss: 0.1679 - val_accuracy: 0.9286\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1783 - accuracy: 0.9267 - val_loss: 0.1686 - val_accuracy: 0.9290\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.1792 - accuracy: 0.9259 - val_loss: 0.1728 - val_accuracy: 0.9283\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1790 - accuracy: 0.9264 - val_loss: 0.1715 - val_accuracy: 0.9292\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.1775 - accuracy: 0.9263 - val_loss: 0.1701 - val_accuracy: 0.9272\n",
      "Early stopped after 61 epochs.\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 0.1666 - accuracy: 0.9304\n",
      "Validation accuracy: 0.9303913116455078\n",
      "\n",
      "Training model with 3 hidden layers, 256 neurons, 0.2 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.6384 - accuracy: 0.7222 - val_loss: 0.6945 - val_accuracy: 0.6820\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.5692 - accuracy: 0.7543 - val_loss: 0.5985 - val_accuracy: 0.7124\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.5521 - accuracy: 0.7609 - val_loss: 0.6031 - val_accuracy: 0.7161\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.5523 - accuracy: 0.7607 - val_loss: 0.5996 - val_accuracy: 0.7040\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.5516 - accuracy: 0.7617 - val_loss: 0.6608 - val_accuracy: 0.6803\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.5546 - accuracy: 0.7601 - val_loss: 0.6295 - val_accuracy: 0.7060\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.5442 - accuracy: 0.7636 - val_loss: 0.6124 - val_accuracy: 0.7065\n",
      "Early stopped after 7 epochs.\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 0.5985 - accuracy: 0.7124\n",
      "Validation accuracy: 0.7124433517456055\n",
      "\n",
      "Training model with 3 hidden layers, 256 neurons, 0.5 dropout, and 0.0001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.8709 - accuracy: 0.5936 - val_loss: 0.7694 - val_accuracy: 0.6281\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.6506 - accuracy: 0.7204 - val_loss: 0.6692 - val_accuracy: 0.6839\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.5466 - accuracy: 0.7639 - val_loss: 0.6100 - val_accuracy: 0.7117\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.5001 - accuracy: 0.7813 - val_loss: 0.5923 - val_accuracy: 0.7210\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4727 - accuracy: 0.7916 - val_loss: 0.5702 - val_accuracy: 0.7297\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4525 - accuracy: 0.7985 - val_loss: 0.5545 - val_accuracy: 0.7368\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4399 - accuracy: 0.8028 - val_loss: 0.5502 - val_accuracy: 0.7402\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4314 - accuracy: 0.8059 - val_loss: 0.5421 - val_accuracy: 0.7454\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4227 - accuracy: 0.8089 - val_loss: 0.5376 - val_accuracy: 0.7480\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4157 - accuracy: 0.8116 - val_loss: 0.5269 - val_accuracy: 0.7533\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4100 - accuracy: 0.8141 - val_loss: 0.5231 - val_accuracy: 0.7551\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4055 - accuracy: 0.8159 - val_loss: 0.5136 - val_accuracy: 0.7580\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4013 - accuracy: 0.8179 - val_loss: 0.5091 - val_accuracy: 0.7621\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5103 - val_accuracy: 0.7652\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3938 - accuracy: 0.8209 - val_loss: 0.4998 - val_accuracy: 0.7691\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3906 - accuracy: 0.8225 - val_loss: 0.4959 - val_accuracy: 0.7713\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3878 - accuracy: 0.8232 - val_loss: 0.4859 - val_accuracy: 0.7759\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3847 - accuracy: 0.8247 - val_loss: 0.4873 - val_accuracy: 0.7775\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3819 - accuracy: 0.8265 - val_loss: 0.4823 - val_accuracy: 0.7795\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3797 - accuracy: 0.8278 - val_loss: 0.4771 - val_accuracy: 0.7812\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3770 - accuracy: 0.8288 - val_loss: 0.4737 - val_accuracy: 0.7840\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3751 - accuracy: 0.8303 - val_loss: 0.4712 - val_accuracy: 0.7850\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3736 - accuracy: 0.8312 - val_loss: 0.4654 - val_accuracy: 0.7886\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3719 - accuracy: 0.8322 - val_loss: 0.4605 - val_accuracy: 0.7930\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3697 - accuracy: 0.8323 - val_loss: 0.4584 - val_accuracy: 0.7918\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3690 - accuracy: 0.8339 - val_loss: 0.4545 - val_accuracy: 0.7957\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3670 - accuracy: 0.8338 - val_loss: 0.4560 - val_accuracy: 0.7970\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3649 - accuracy: 0.8354 - val_loss: 0.4507 - val_accuracy: 0.8006\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3633 - accuracy: 0.8357 - val_loss: 0.4470 - val_accuracy: 0.8023\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3633 - accuracy: 0.8365 - val_loss: 0.4458 - val_accuracy: 0.8019\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3618 - accuracy: 0.8371 - val_loss: 0.4430 - val_accuracy: 0.8028\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3608 - accuracy: 0.8374 - val_loss: 0.4444 - val_accuracy: 0.8045\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3590 - accuracy: 0.8388 - val_loss: 0.4379 - val_accuracy: 0.8079\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3574 - accuracy: 0.8392 - val_loss: 0.4343 - val_accuracy: 0.8074\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3570 - accuracy: 0.8398 - val_loss: 0.4365 - val_accuracy: 0.8074\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3550 - accuracy: 0.8402 - val_loss: 0.4385 - val_accuracy: 0.8083\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 28s 3ms/step - loss: 0.3546 - accuracy: 0.8408 - val_loss: 0.4303 - val_accuracy: 0.8116\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 28s 3ms/step - loss: 0.3545 - accuracy: 0.8408 - val_loss: 0.4269 - val_accuracy: 0.8118\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 31s 3ms/step - loss: 0.3524 - accuracy: 0.8413 - val_loss: 0.4249 - val_accuracy: 0.8138\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 28s 3ms/step - loss: 0.3522 - accuracy: 0.8419 - val_loss: 0.4255 - val_accuracy: 0.8149\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 28s 3ms/step - loss: 0.3513 - accuracy: 0.8423 - val_loss: 0.4248 - val_accuracy: 0.8141\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3506 - accuracy: 0.8427 - val_loss: 0.4227 - val_accuracy: 0.8149\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3500 - accuracy: 0.8435 - val_loss: 0.4201 - val_accuracy: 0.8182\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3488 - accuracy: 0.8443 - val_loss: 0.4188 - val_accuracy: 0.8174\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3496 - accuracy: 0.8435 - val_loss: 0.4188 - val_accuracy: 0.8193\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3472 - accuracy: 0.8446 - val_loss: 0.4167 - val_accuracy: 0.8204\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3467 - accuracy: 0.8446 - val_loss: 0.4139 - val_accuracy: 0.8200\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3462 - accuracy: 0.8450 - val_loss: 0.4154 - val_accuracy: 0.8200\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3465 - accuracy: 0.8450 - val_loss: 0.4136 - val_accuracy: 0.8222\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3454 - accuracy: 0.8456 - val_loss: 0.4118 - val_accuracy: 0.8227\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3448 - accuracy: 0.8463 - val_loss: 0.4101 - val_accuracy: 0.8226\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3435 - accuracy: 0.8467 - val_loss: 0.4070 - val_accuracy: 0.8241\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3445 - accuracy: 0.8465 - val_loss: 0.4087 - val_accuracy: 0.8238\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3436 - accuracy: 0.8473 - val_loss: 0.4070 - val_accuracy: 0.8249\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3419 - accuracy: 0.8477 - val_loss: 0.4044 - val_accuracy: 0.8239\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3412 - accuracy: 0.8480 - val_loss: 0.4014 - val_accuracy: 0.8266\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3408 - accuracy: 0.8482 - val_loss: 0.4021 - val_accuracy: 0.8263\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3407 - accuracy: 0.8477 - val_loss: 0.3990 - val_accuracy: 0.8278\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3398 - accuracy: 0.8490 - val_loss: 0.4006 - val_accuracy: 0.8264\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3404 - accuracy: 0.8485 - val_loss: 0.3991 - val_accuracy: 0.8274\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3390 - accuracy: 0.8485 - val_loss: 0.3987 - val_accuracy: 0.8274\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3390 - accuracy: 0.8494 - val_loss: 0.3928 - val_accuracy: 0.8326\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3386 - accuracy: 0.8493 - val_loss: 0.3984 - val_accuracy: 0.8300\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3371 - accuracy: 0.8494 - val_loss: 0.3922 - val_accuracy: 0.8293\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3367 - accuracy: 0.8502 - val_loss: 0.3965 - val_accuracy: 0.8297\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3364 - accuracy: 0.8504 - val_loss: 0.3915 - val_accuracy: 0.8289\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3352 - accuracy: 0.8514 - val_loss: 0.3933 - val_accuracy: 0.8281\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3351 - accuracy: 0.8512 - val_loss: 0.3909 - val_accuracy: 0.8322\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3364 - accuracy: 0.8510 - val_loss: 0.3896 - val_accuracy: 0.8336\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3355 - accuracy: 0.8512 - val_loss: 0.3936 - val_accuracy: 0.8319\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3339 - accuracy: 0.8521 - val_loss: 0.3917 - val_accuracy: 0.8327\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3356 - accuracy: 0.8510 - val_loss: 0.3901 - val_accuracy: 0.8327\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3331 - accuracy: 0.8519 - val_loss: 0.3866 - val_accuracy: 0.8353\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3345 - accuracy: 0.8519 - val_loss: 0.3830 - val_accuracy: 0.8353\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3322 - accuracy: 0.8528 - val_loss: 0.3829 - val_accuracy: 0.8345\n",
      "Epoch 76/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3326 - accuracy: 0.8524 - val_loss: 0.3877 - val_accuracy: 0.8360\n",
      "Epoch 77/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3331 - accuracy: 0.8517 - val_loss: 0.3851 - val_accuracy: 0.8355\n",
      "Epoch 78/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3328 - accuracy: 0.8529 - val_loss: 0.3857 - val_accuracy: 0.8350\n",
      "Epoch 79/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3327 - accuracy: 0.8522 - val_loss: 0.3815 - val_accuracy: 0.8355\n",
      "Epoch 80/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3312 - accuracy: 0.8535 - val_loss: 0.3802 - val_accuracy: 0.8359\n",
      "Epoch 81/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3312 - accuracy: 0.8533 - val_loss: 0.3807 - val_accuracy: 0.8362\n",
      "Epoch 82/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3309 - accuracy: 0.8533 - val_loss: 0.3794 - val_accuracy: 0.8375\n",
      "Epoch 83/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3301 - accuracy: 0.8538 - val_loss: 0.3818 - val_accuracy: 0.8384\n",
      "Epoch 84/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3314 - accuracy: 0.8532 - val_loss: 0.3782 - val_accuracy: 0.8369\n",
      "Epoch 85/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3303 - accuracy: 0.8539 - val_loss: 0.3788 - val_accuracy: 0.8377\n",
      "Epoch 86/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3297 - accuracy: 0.8537 - val_loss: 0.3780 - val_accuracy: 0.8377\n",
      "Epoch 87/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3282 - accuracy: 0.8544 - val_loss: 0.3767 - val_accuracy: 0.8384\n",
      "Epoch 88/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3302 - accuracy: 0.8534 - val_loss: 0.3770 - val_accuracy: 0.8400\n",
      "Epoch 89/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3285 - accuracy: 0.8549 - val_loss: 0.3775 - val_accuracy: 0.8384\n",
      "Epoch 90/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3283 - accuracy: 0.8548 - val_loss: 0.3771 - val_accuracy: 0.8395\n",
      "Epoch 91/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3268 - accuracy: 0.8555 - val_loss: 0.3733 - val_accuracy: 0.8405\n",
      "Epoch 92/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3282 - accuracy: 0.8546 - val_loss: 0.3746 - val_accuracy: 0.8402\n",
      "Epoch 93/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3282 - accuracy: 0.8544 - val_loss: 0.3771 - val_accuracy: 0.8404\n",
      "Epoch 94/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3278 - accuracy: 0.8542 - val_loss: 0.3772 - val_accuracy: 0.8406\n",
      "Epoch 95/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3265 - accuracy: 0.8559 - val_loss: 0.3739 - val_accuracy: 0.8404\n",
      "Epoch 96/100\n",
      "9002/9002 [==============================] - 27s 3ms/step - loss: 0.3281 - accuracy: 0.8546 - val_loss: 0.3736 - val_accuracy: 0.8407\n",
      "Early stopped after 96 epochs.\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 0.3733 - accuracy: 0.8405\n",
      "Validation accuracy: 0.8405218124389648\n",
      "\n",
      "Training model with 3 hidden layers, 256 neurons, 0.5 dropout, and 0.001 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.5965 - accuracy: 0.7370 - val_loss: 0.5812 - val_accuracy: 0.7261\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4763 - accuracy: 0.7892 - val_loss: 0.5416 - val_accuracy: 0.7393\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4547 - accuracy: 0.7977 - val_loss: 0.5468 - val_accuracy: 0.7457\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4422 - accuracy: 0.8032 - val_loss: 0.5376 - val_accuracy: 0.7510\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.4325 - accuracy: 0.8074 - val_loss: 0.5197 - val_accuracy: 0.7554\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4261 - accuracy: 0.8099 - val_loss: 0.5044 - val_accuracy: 0.7636\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4205 - accuracy: 0.8121 - val_loss: 0.5155 - val_accuracy: 0.7621\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4162 - accuracy: 0.8142 - val_loss: 0.5107 - val_accuracy: 0.7697\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4117 - accuracy: 0.8161 - val_loss: 0.5066 - val_accuracy: 0.7738\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4086 - accuracy: 0.8168 - val_loss: 0.4894 - val_accuracy: 0.7757\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4077 - accuracy: 0.8178 - val_loss: 0.4920 - val_accuracy: 0.7742\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4050 - accuracy: 0.8187 - val_loss: 0.4993 - val_accuracy: 0.7763\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.4018 - accuracy: 0.8197 - val_loss: 0.4902 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3992 - accuracy: 0.8212 - val_loss: 0.4811 - val_accuracy: 0.7751\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.4681 - val_accuracy: 0.7830\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3976 - accuracy: 0.8216 - val_loss: 0.4896 - val_accuracy: 0.7812\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3954 - accuracy: 0.8234 - val_loss: 0.4731 - val_accuracy: 0.7896\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3948 - accuracy: 0.8233 - val_loss: 0.4740 - val_accuracy: 0.7874\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3930 - accuracy: 0.8248 - val_loss: 0.4618 - val_accuracy: 0.7935\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3908 - accuracy: 0.8258 - val_loss: 0.4869 - val_accuracy: 0.7895\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3901 - accuracy: 0.8255 - val_loss: 0.4749 - val_accuracy: 0.7926\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3893 - accuracy: 0.8273 - val_loss: 0.4667 - val_accuracy: 0.7912\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3874 - accuracy: 0.8275 - val_loss: 0.4658 - val_accuracy: 0.7967\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3880 - accuracy: 0.8265 - val_loss: 0.4535 - val_accuracy: 0.7975\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3870 - accuracy: 0.8279 - val_loss: 0.4608 - val_accuracy: 0.7955\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3846 - accuracy: 0.8302 - val_loss: 0.4610 - val_accuracy: 0.8010\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3841 - accuracy: 0.8287 - val_loss: 0.4552 - val_accuracy: 0.7992\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 0.3844 - accuracy: 0.8293 - val_loss: 0.4578 - val_accuracy: 0.8032\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 0.3831 - accuracy: 0.8303 - val_loss: 0.4559 - val_accuracy: 0.7998\n",
      "Early stopped after 29 epochs.\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 0.4535 - accuracy: 0.7975\n",
      "Validation accuracy: 0.7975391149520874\n",
      "\n",
      "Training model with 3 hidden layers, 256 neurons, 0.5 dropout, and 0.01 learning rate.\n",
      "Epoch 1/100\n",
      "9002/9002 [==============================] - 26s 3ms/step - loss: 1.0187 - accuracy: 0.4932 - val_loss: 0.9236 - val_accuracy: 0.6838\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 1.0172 - accuracy: 0.4876 - val_loss: 1.0067 - val_accuracy: 0.2618\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 1.0174 - accuracy: 0.4767 - val_loss: 0.9660 - val_accuracy: 0.6819\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 1.0158 - accuracy: 0.4746 - val_loss: 0.9876 - val_accuracy: 0.2778\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 1.0186 - accuracy: 0.4761 - val_loss: 1.0057 - val_accuracy: 0.2748\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 25s 3ms/step - loss: 1.0282 - accuracy: 0.4769 - val_loss: 1.0369 - val_accuracy: 0.2545\n",
      "Early stopped after 6 epochs.\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 0.9236 - accuracy: 0.6838\n",
      "Validation accuracy: 0.683819055557251\n",
      "\n",
      "Best model achieved 0.9392728209495544 accuracy on the validation set after 100 epochs.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the function to create the model\n",
    "def create_model(hidden_layers, neurons, dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))  # Assuming 3 classes for classification\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Assuming input_dim is the dimensionality of your input features\n",
    "input_dim = X_ss_train.shape[1]\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_grid = {\n",
    "    'hidden_layers': [1, 2, 3],\n",
    "    'neurons': [64, 128, 256],\n",
    "    'dropout_rate': [0.2, 0.5],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Track the best model and its performance\n",
    "best_model = None\n",
    "best_epochs = float('inf')\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate over hyperparameter combinations\n",
    "for hidden_layers in param_grid['hidden_layers']:\n",
    "    for neurons in param_grid['neurons']:\n",
    "        for dropout_rate in param_grid['dropout_rate']:\n",
    "            for learning_rate in param_grid['learning_rate']:\n",
    "                print(f\"Training model with {hidden_layers} hidden layers, {neurons} neurons, \"\n",
    "                      f\"{dropout_rate} dropout, and {learning_rate} learning rate.\")\n",
    "                \n",
    "                # Create the model\n",
    "                model = create_model(hidden_layers, neurons, dropout_rate, learning_rate)\n",
    "                \n",
    "                # Set up early stopping\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "                \n",
    "                # Train the model\n",
    "                history = model.fit(X_ss_train, y_ss_train, epochs=100, batch_size=32,\n",
    "                                    validation_data=(X_ss_val, y_ss_val), callbacks=[early_stopping])\n",
    "                \n",
    "                # Get the number of epochs it took for early stopping\n",
    "                epochs = len(history.history['loss'])\n",
    "                print(f\"Early stopped after {epochs} epochs.\")\n",
    "                \n",
    "                # Evaluate on validation set\n",
    "                _, accuracy = model.evaluate(X_ss_val, y_ss_val)\n",
    "                print(f\"Validation accuracy: {accuracy}\\n\")\n",
    "                \n",
    "                # Check if this model is the best so far\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_model = model\n",
    "                    best_epochs = epochs\n",
    "\n",
    "print(f\"Best model achieved {best_accuracy} accuracy on the validation set after {best_epochs} epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845/845 [==============================] - 1s 978us/step - loss: 0.1553 - accuracy: 0.9358\n",
      "Test accuracy: 0.9357560276985168\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_ss_test, y_ss_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
